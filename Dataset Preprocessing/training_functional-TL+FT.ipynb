{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/tf/home/sergio/Tesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(root_path+\"/TinyYOLOv3-Pedestrian-Detection\")\n",
    "\n",
    "from YOLOfunctional import TinyYOLOv3_functional,nms_layer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "#from tensorflow.python.tools import freeze_graph\n",
    "#from skimage.io import imread,imshow\n",
    "#from skimage.transform import resize \n",
    "import time\n",
    "#from tensorflow.compat.v1.image import decode_image\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'bboxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'num_real_boxes':tf.io.FixedLenFeature([], tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_matrix_tf(box_arr1, box_arr2):\n",
    "    \n",
    "    box_arr1 = box_arr1 -tf.tile(box_arr1[:,:2],[1,2])\n",
    "    #print(box_arr1)\n",
    "    x11, y11, x12, y12 = tf.split(box_arr1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = tf.split(box_arr2, 4, axis=1)\n",
    "    xA = tf.maximum(x11, tf.transpose(x21))\n",
    "    yA = tf.maximum(y11, tf.transpose(y21))\n",
    "    xB = tf.minimum(x12, tf.transpose(x22))\n",
    "    yB = tf.minimum(y12, tf.transpose(y22))\n",
    "    interArea = tf.maximum((xB - xA + 1e-9), 0) * tf.maximum((yB - yA + 1e-9), 0)\n",
    "    boxAArea = (x12 - x11 + 1e-9) * (y12 - y11 + 1e-9)\n",
    "    boxBArea = (x22 - x21 + 1e-9) * (y22 - y21 + 1e-9)\n",
    "    iou = interArea / (boxAArea + tf.transpose(boxBArea) - interArea)\n",
    "    return iou,tf.argmax(iou,axis=1)#[:,tf.newaxis]\n",
    "\n",
    "\n",
    "def fill_yolo_output(boxes,grid_size,num_anchors,which_anchor_box,which_anchor_box_index):\n",
    "    #print(boxes.shape)\n",
    "    #noobj_mask = tf.ones((1,grid_size*grid_size*num_anchors))\n",
    "    #print(noobj_mask.shape)\n",
    "    \n",
    "    x_min,y_min,x_max,y_max =tf.split(boxes,4,axis=1)\n",
    "\n",
    "    #Transforma las coordenadas de (xmin,ymin,xmax,ymax) --> (xcenter,ycenter,width,height)\n",
    "    width = x_max-x_min\n",
    "    height = y_max-y_min\n",
    "    x_global =x_min + tf.math.divide(x_max - x_min,2)\n",
    "    y_global =y_min + tf.math.divide(y_max - y_min,2)\n",
    "    \n",
    "    \n",
    "    x_min_anchor,y_min_anchor,x_max_anchor,y_max_anchor =tf.split(which_anchor_box,4,axis=1)\n",
    "    \n",
    "    width_anchor = x_max_anchor-x_min_anchor\n",
    "    height_anchor = y_max_anchor-y_min_anchor\n",
    "    x_global_anchor =x_min_anchor + tf.math.divide(x_max_anchor - x_min_anchor,2)\n",
    "    y_global_anchor =y_min_anchor + tf.math.divide(y_max_anchor - y_min_anchor,2)   \n",
    "\n",
    "    \n",
    "    #print(\"el x original\",x_global)\n",
    "    #print(\"el y original\",y_global)\n",
    "    #print(\"el w original\",width)\n",
    "    #print(\"el h original\",height)\n",
    "    \n",
    "    #porción de la imagen que hay en cada celda\n",
    "    pixel_per_grid = tf.math.divide(1.,grid_size)\n",
    "    #print(pixel_per_grid)\n",
    "    \n",
    "    #Obtenemos la coordenada de la celda donde están los boundingboxes\n",
    "    offset_grid_x = x_global//pixel_per_grid\n",
    "    offset_grid_y = y_global//pixel_per_grid\n",
    "    \n",
    "    #Obtenemos el el centro locacon referencia  al celda encontrada previamente\n",
    "    x_local =tf.math.floormod(x_global,pixel_per_grid)\n",
    "    y_local =tf.math.floormod(y_global,pixel_per_grid)\n",
    "    #print(x_local,y_local)\n",
    "    \n",
    "    #Valores tx e ty del groudtruth\n",
    "    tx = tf.math.log(x_local + 1e-07/(1-x_local))\n",
    "    ty = tf.math.log(y_local+1e-07/(1-y_local))\n",
    "    tw = tf.math.log(tf.math.divide(width+1e-07,width_anchor))\n",
    "    th = tf.math.log(tf.math.divide(height+1e-07,height_anchor))\n",
    "    tobj_mask = tf.ones_like(tx)\n",
    "    tobj = tf.concat([tobj_mask,tobj_mask],axis=0)\n",
    "    \n",
    "    #tnoobj = tf.zeros_like(tx)    \n",
    "    #tobj = tf.ones((grid_size*grid_size*num_anchors,1))\n",
    "    #tnoobj = tf.zeros((grid_size*grid_size*num_anchors,1))\n",
    "    #print(\"Lo que la red debe predecir\",tx.numpy(),ty.numpy(),tw.numpy(),th.numpy())\n",
    "    #x_global = (offset_grid_x * pixel_per_grid) + tf.math.sigmoid(tx)\n",
    "    #y_global = (offset_grid_y * pixel_per_grid) + tf.math.sigmoid(ty)\n",
    "    #w = width_anchor*tf.math.exp(tw)\n",
    "    #h = height_anchor*tf.math.exp(th)\n",
    "    #print(\"obtnemos el x_real\",x_global)\n",
    "    #print(\"obtenemos el y_real\",y_global)\n",
    "    #print(\"obtenemos el w real\",w)\n",
    "    #print(\"obtenemos el h real\",h)\n",
    "    \n",
    "    #anchor_boxes_per_output = num_anchors//2\n",
    "\n",
    "    #Residuo indica cual de los 3 anchor boxes de la coordenada es la que llevara el 1\n",
    "    #Coord representa la coordenada del grid\n",
    "    \n",
    "    residuo = tf.math.floormod(which_anchor_box_index,num_anchors)[:,tf.newaxis]\n",
    "    coord = tf.cast(num_anchors*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    \n",
    "    coord_objectness = tf.cast(2*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    coord_objectness2 = coord_objectness+1\n",
    "    coord_objectess_global = tf.concat([coord_objectness,coord_objectness2],axis=0)\n",
    "    \n",
    "    output_position = residuo+coord\n",
    "    print(\"tipo de aoutput_positivon\",output_position)\n",
    "    \n",
    "    print(output_position)\n",
    "    \n",
    "    dense_shape = grid_size*grid_size*num_anchors\n",
    "    print(dense_shape)\n",
    "    tx_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tx[:,0], dense_shape=[dense_shape]))\n",
    "    ty_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=ty[:,0], dense_shape=[dense_shape]))\n",
    "    tw_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tw[:,0], dense_shape=[dense_shape]))\n",
    "    th_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=th[:,0], dense_shape=[dense_shape]))\n",
    "    obj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tobj_mask[:,0], dense_shape=[dense_shape]))\n",
    "    objectness_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=coord_objectess_global, values=tobj[:,0], dense_shape=[dense_shape]))\n",
    "    #noobj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tnoobj[:,0], dense_shape=[dense_shape]))\n",
    "    #obj_mask =tx_vector=ty_vector=tw_vector=th_vector = tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "    \n",
    "    tx_vector_dense = tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=False, name=\"Dense_tx\")\n",
    "    ty_vector_dense = tf.sparse.to_dense(ty_vector, default_value=0, validate_indices=False, name=\"Dense_ty\")\n",
    "    tw_vector_dense = tf.sparse.to_dense(tw_vector, default_value=0, validate_indices=False, name=\"Dense_tw\")\n",
    "    th_vector_dense = tf.sparse.to_dense(th_vector, default_value=0, validate_indices=False, name=\"Dense_th\")\n",
    "    obj_mask_dense =  tf.sparse.to_dense(obj_mask, default_value=0, validate_indices=False, name=\"Dense_obj\")\n",
    "    #noobj_mask_dense = 1-obj_mask_dense\n",
    "    objectness_vector_dense =  tf.sparse.to_dense(objectness_vector, default_value=0, validate_indices=False)\n",
    "    \n",
    "    #noobj_mask_dense= tf.sparse.to_dense(noobj_mask, default_value=1, validate_indices=False, name=\"Dense_noobj\")\n",
    "    ##print(tx_vector.to_dense)\n",
    "    #print(tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=True, name=None)\n",
    "    #tx_vector=tx_vector[[3,2],]\n",
    "    #tx_vector[output_position[:,0]] = tx\n",
    "    #print(\"coordenada de la salida:\",output_position)\n",
    "    \n",
    "    #return ((tx_vector_dense,ty_vector_dense,obj_mask_dense),(tw_vector_dense,th_vector_dense,obj_mask_dense),(objectness),(objectness))\n",
    "    \n",
    "    return tx_vector_dense,ty_vector_dense,tw_vector_dense,th_vector_dense,obj_mask_dense,objectness_vector_dense\n",
    "\n",
    "def build_targets(image,image_bboxes,num_real_boxes,anchor_boxes):\n",
    "    \n",
    "    images_bboxes_original = image_bboxes\n",
    "    #Obtenemos los boduing boxes que son reales\n",
    "    image_bboxes = image_bboxes[:num_real_boxes,:]\n",
    "    #print(\"Bouding boxes de la imagen\",image_bboxes)\n",
    "    #Obteneos  la matriz de IoU , y el índice del anchor box que dió mejor resultado\n",
    "    \n",
    "    #Nprmalizamos con respecto al tamaño de la imagen y obtenemos la Iou con los anchor boxes\n",
    "    image_bboxes = tf.math.divide(image_bboxes,416)\n",
    "    iou_matrix,which_anchor_box_index = get_iou_matrix_tf(image_bboxes,anchor_boxes)\n",
    "    \n",
    "    print(which_anchor_box_index)\n",
    "\n",
    "    anchor_boxes_per_output = len(anchor_boxes)//2\n",
    "    #Indices de los bouding boxes que irian en cada salida, index_best_ yolo nos dice que bouding boxes de la imagen van a la salida YOLO1,\n",
    "    #porque su mejor IoU fue con los len(anchor_boxes)//2 anchor boxes mas grandes\n",
    "    index_best_yolo1 = tf.where(which_anchor_box_index>=anchor_boxes_per_output)[:,0]\n",
    "    index_best_yolo2 = tf.where(which_anchor_box_index<anchor_boxes_per_output)[:,0]\n",
    "    index_best_anchor_yolo1 = tf.gather(which_anchor_box_index,index_best_yolo1,axis=0)\n",
    "    index_best_anchor_yolo2 = tf.gather(which_anchor_box_index,index_best_yolo2,axis=0)\n",
    "    \n",
    "    print(index_best_yolo1)\n",
    "    print(index_best_anchor_yolo1)\n",
    "\n",
    "    print(index_best_yolo2)\n",
    "    print(index_best_anchor_yolo2)\n",
    "\n",
    "    \n",
    "    best_bboxes_yolo1 = tf.gather(image_bboxes,index_best_yolo1,axis =0)\n",
    "    best_anchors_yolo1 = tf.gather(anchor_boxes,index_best_anchor_yolo1, axis =0) #LOs dos anchor boxes grandes corrsponden a YOLO1\n",
    "    best_bboxes_yolo2 = tf.gather(image_bboxes,index_best_yolo2,axis =0)\n",
    "    best_anchors_yolo2 = tf.gather(anchor_boxes,index_best_anchor_yolo2, axis =0) #Los dos anchor boxes pequeños corresponden a YOLO2\n",
    "    \n",
    "    \n",
    "    if best_anchors_yolo1.shape[0] !=0:\n",
    "        tx_vector_yolo1,ty_vector_yolo1,tw_vector_yolo1,th_vector_yolo1,obj_mask_yolo1,obj_vector_yolo1= fill_yolo_output(best_bboxes_yolo1,13,anchor_boxes_per_output,best_anchors_yolo1,index_best_anchor_yolo1)\n",
    "    else:\n",
    "        tx_vector_yolo1=ty_vector_yolo1=tw_vector_yolo1=th_vector_yolo1=obj_mask_yolo1= obj_vector_yolo1=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo1 = tf.ones((1,13*13*num_anchors))\n",
    "    \n",
    "    if best_anchors_yolo2.shape[0] != 0:\n",
    "        tx_vector_yolo2,ty_vector_yolo2,tw_vector_yolo2,th_vector_yolo2,obj_mask_yolo2,obj_vector_yolo2 = fill_yolo_output(best_bboxes_yolo2,26,anchor_boxes_per_output,best_anchors_yolo2,index_best_anchor_yolo2)\n",
    "    else:\n",
    "        tx_vector_yolo2=ty_vector_yolo2=tw_vector_yolo2=th_vector_yolo2=obj_mask_yolo2 = obj_vector_yolo2=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo2 = tf.ones((1,26*26*num_anchors))\n",
    "        \n",
    "    tx_vector = tf.concat([tx_vector_yolo1,tx_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    ty_vector = tf.concat([ty_vector_yolo1,ty_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    tw_vector = tf.concat([tw_vector_yolo1,tw_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    th_vector = tf.concat([th_vector_yolo1,th_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_mask = tf.concat([obj_mask_yolo1,obj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    #noobj_mask = tf.concat([noobj_mask_yolo1,noobj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_vector = tf.concat([obj_vector_yolo1,obj_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    \n",
    "    #output = tf.concat([tx_vector,ty_vector,tw_vector,th_vector,obj_mask,noobj_mask,obj_vector],axis=1)\n",
    "    #images_bboxes_original\n",
    "    #return image,output\n",
    "    #Vamos a regresar obj mask que es 1 cuando hay objeto en grid y el anchor box especifico\n",
    "    return tf.cast(image,tf.float32)/255,(tf.concat([tx_vector,ty_vector,obj_mask],axis=1),tf.concat([tw_vector,th_vector,obj_mask],axis=1),(obj_mask),(obj_mask))\n",
    "\n",
    "def imgaug_data_augmentation(image,bboxes,num_real_boxes):\n",
    "    im_shape = image.shape\n",
    "    bbs = BoundingBoxesOnImage.from_xyxy_array(bboxes*416, shape=(416,416))\n",
    "    \n",
    "    policy = np.random.randint(5)\n",
    "    \n",
    "    #policy = 2\n",
    "    if policy == 0:\n",
    "        \n",
    "        p = np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateX(px=(-60, 60),cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "        p = np.random.random()\n",
    "        if p<=0.8:\n",
    "            aug = iaa.HistogramEqualization()\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "    elif policy==1:\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.2:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.8:\n",
    "            square_size = np.random.randint(48)\n",
    "            aug = iaa.Cutout(nb_iterations=1, size=square_size/416, squared=True)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    elif policy==2:\n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.ShearY(shear=(int(-0.06*416), int(0.06*416)), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "        p=np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "            \n",
    "    elif policy==3:\n",
    "        p=np.random.random()\n",
    "        if p<=0.6:    \n",
    "            aug = iaa.Rotate(rotate=(-30, 30), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs_aug.remove_out_of_image().clip_out_of_image()\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.MultiplySaturation((0.54, 1.54))\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    bbs.remove_out_of_image()\n",
    "    \n",
    "    return image,np.clip(bbs.to_xyxy_array(np.float32),1,415),num_real_boxes\n",
    "    \n",
    "    \n",
    "def preprocessing(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,num_real_boxes\n",
    "\n",
    "def preprocessing_validation_set(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    bboxes = tf.clip_by_value(bboxes*416,1,415)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,tf.cast(num_real_boxes,tf.int64)\n",
    "    \n",
    "@tf.function(input_signature=[tf.TensorSpec((416,416,3), tf.uint8),tf.TensorSpec((None,4), tf.float32),tf.TensorSpec((), tf.int64)]) \n",
    "def tf_numpy_albumentations_real(image,bboxes,num_real_boxes):\n",
    "    \n",
    "    boxes_shape = bboxes.shape\n",
    "    im_shape = image.shape\n",
    "\n",
    "    image,bboxes,num_real_boxes = tf.numpy_function(imgaug_data_augmentation,[image,bboxes,num_real_boxes],Tout =[tf.uint8,tf.float32,tf.int64])\n",
    " \n",
    "    image.set_shape(im_shape)\n",
    "    bboxes.set_shape(boxes_shape)\n",
    "    print(\"Imagen data type\",image.dtype)\n",
    "    print(\"Bboxes data type\",bboxes.dtype)\n",
    "    print(\"num_real_boxes\",num_real_boxes.dtype)\n",
    "\n",
    "    return image,bboxes,num_real_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen data type <dtype: 'uint8'>\n",
      "Bboxes data type <dtype: 'float32'>\n",
      "num_real_boxes <dtype: 'int64'>\n",
      "Tensor(\"ArgMax:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", shape=(None,), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "507\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "2028\n",
      "Tensor(\"ArgMax:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", dtype=int64)\n",
      "Tensor(\"add_18:0\", dtype=int64)\n",
      "507\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", dtype=int64)\n",
      "Tensor(\"add_30:0\", dtype=int64)\n",
      "2028\n"
     ]
    }
   ],
   "source": [
    "#USANDO TF.IMAGE MODULE\n",
    "#anchors =tf.constant(np.array([[0,0,0.015,0.037],[0,0,0.043,0.104],[0,0,0.11,0.278],[0,0,0.351,0.66]]),dtype=tf.float32)\n",
    "#anchors =tf.constant(np.array([[0,0,0.026,0.062],[0,0,0.067,0.183],[0,0,0.128,0.323],[0,0,0.343,0.650]]),dtype=tf.float32)\n",
    "anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(root_path+\"/pedestrian_dataset_train_tfr\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(root_path+\"/pedestrian_dataset_val_tfr_fixed\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset_val =tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(root_path+\"/pedestrian_dataset_train_tfr\")\n",
    "#.shuffle(70000)\n",
    "\n",
    "#VAMOS A HACER UN ENTRENAMIENTO CON DATA AUGMENTATION, ADEMAS DE USAR EL LOSS ORIGINAL\n",
    "\n",
    "train_dataset = raw_image_dataset.map(preprocessing,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(tf_numpy_albumentations_real,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "train_dataset = train_dataset.batch(8)\n",
    "\n",
    "val_dataset = raw_image_dataset_val.map(preprocessing_validation_set,num_parallel_calls=8)\n",
    "val_dataset = val_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "val_dataset = val_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef loss_bce_objectness(y_true,y_pred):\\n    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\\n    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\\n    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \\n    \\n    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*tf.math.log(y_pred+1e-7)[:,tf.newaxis],axis=1))\\n    \\n    return loss_obj\\n\\ndef loss_bce_no_objectness(y_true,y_pred):\\n    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\\n    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*tf.math.log(1-y_pred+1e-7)[:,tf.newaxis],axis=1))\\n    \\n    return loss_noobj\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import Loss,BinaryCrossentropy,MeanSquaredError,MeanSquaredLogarithmicError\n",
    "'''\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tx_true-tx_pred))  \n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "    \n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tx_true-tx_pred))  \n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "    \n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tf.math.exp(tw_true),tf.math.exp(tw_pred))[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tf.math.exp(th_true),tf.math.exp(th_pred))[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "    \n",
    "'''\n",
    "\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "def loss_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_no_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    \n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj\n",
    "'''\n",
    "def loss_bce_objectness(y_true,y_pred):\n",
    "    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*tf.math.log(y_pred+1e-7)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_bce_no_objectness(y_true,y_pred):\n",
    "    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*tf.math.log(1-y_pred+1e-7)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbe2c086470>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#anchors =[[10/416,14/416],[23/416,27/416],[37/416,58/416],[81/416,82/416],[135/416,169/416],[344/416,319/416]]\n",
    "anchors =[[0.02078,0.049],[0.0426,0.128],[0.08523,0.19356],[0.1506,0.4163],[0.27835,0.58651],[0.5632,0.78614]]\n",
    "\n",
    "model = TinyYOLOv3_functional(anchor_boxes = anchors,num_classes=0,mode=\"tl\")\n",
    "model.training = False\n",
    "current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'\n",
    "model.load_weights(current_directory+'/weights_functional_one_class/original_model_one_class')\n",
    "#model.load_weights_darknet(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 416, 416, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 416, 416, 16) 432         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 416, 416, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu (TensorFl [(None, 416, 416, 16 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MaxPool (TensorFlow [(None, 208, 208, 16 0           tf_op_layer_LeakyRelu[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 208, 208, 32) 4608        tf_op_layer_MaxPool[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 208, 208, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_1 (Tensor [(None, 208, 208, 32 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MaxPool_1 (TensorFl [(None, 104, 104, 32 0           tf_op_layer_LeakyRelu_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 104, 104, 64) 18432       tf_op_layer_MaxPool_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 104, 104, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_2 (Tensor [(None, 104, 104, 64 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MaxPool_2 (TensorFl [(None, 52, 52, 64)] 0           tf_op_layer_LeakyRelu_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 52, 52, 128)  73728       tf_op_layer_MaxPool_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 52, 52, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_3 (Tensor [(None, 52, 52, 128) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MaxPool_3 (TensorFl [(None, 26, 26, 128) 0           tf_op_layer_LeakyRelu_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 26, 26, 256)  294912      tf_op_layer_MaxPool_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 26, 26, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_4 (Tensor [(None, 26, 26, 256) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MaxPool_4 (TensorFl [(None, 13, 13, 256) 0           tf_op_layer_LeakyRelu_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 13, 13, 512)  1179648     tf_op_layer_MaxPool_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 13, 13, 512)  2048        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_5 (Tensor [(None, 13, 13, 512) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 14, 14, 512)  0           tf_op_layer_LeakyRelu_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MaxPool_5 (TensorFl [(None, 13, 13, 512) 0           zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, 13, 1024) 4718592     tf_op_layer_MaxPool_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 13, 13, 1024) 4096        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_6 (Tensor [(None, 13, 13, 1024 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 13, 13, 256)  262144      tf_op_layer_LeakyRelu_6[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 13, 13, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_7 (Tensor [(None, 13, 13, 256) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 13, 13, 128)  32768       tf_op_layer_LeakyRelu_7[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 13, 13, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_9 (Tensor [(None, 13, 13, 128) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ResizeBilinear (Ten [(None, 26, 26, 128) 0           tf_op_layer_LeakyRelu_9[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Concatenate (Tensor [(None, 26, 26, 384) 0           tf_op_layer_ResizeBilinear[0][0] \n",
      "                                                                 tf_op_layer_LeakyRelu_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 13, 13, 512)  1179648     tf_op_layer_LeakyRelu_7[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 26, 26, 256)  884736      tf_op_layer_Concatenate[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 13, 13, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 26, 26, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_8 (Tensor [(None, 13, 13, 512) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LeakyRelu_10 (Tenso [(None, 26, 26, 256) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 13, 13, 15)   7695        tf_op_layer_LeakyRelu_8[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 26, 26, 15)   3855        tf_op_layer_LeakyRelu_10[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(4,)]               0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(4,)]               0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_2 (TensorFlow [(4,)]               0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_3 (TensorFlow [(4,)]               0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [()]                 0           tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [()]                 0           tf_op_layer_Shape_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [()]                 0           tf_op_layer_Shape_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(5,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(5,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_3[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, None, None,  0           conv2d_9[0][0]                   \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, None, None,  0           conv2d_12[0][0]                  \n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, None, None,  0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split_1 (TensorFlow [(None, None, None,  0           tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5/shape (Te [(3,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, None, 4)]    0           tf_op_layer_split[0][0]          \n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None, None, 4)]    0           tf_op_layer_split_1[0][0]        \n",
      "                                                                 tf_op_layer_Reshape_5/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sigmoid (TensorFlow [(None, None, None,  0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sigmoid_1 (TensorFl [(None, None, None,  0           tf_op_layer_split_1[0][1]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(3,)]               0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Concateasdasdanate_boxes (Conca (None, None, 4)      0           tf_op_layer_Reshape_2[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, None, 1)]    0           tf_op_layer_Sigmoid[0][0]        \n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None, None, 1)]    0           tf_op_layer_Sigmoid_1[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split_2 (TensorFlow [(None, None, 2), (N 0           Concateasdasdanate_boxes[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Concatenate_obj (Concatenate)   (None, None, 1)      0           tf_op_layer_Reshape_1[0][0]      \n",
      "                                                                 tf_op_layer_Reshape_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 8,673,934\n",
      "Trainable params: 11,550\n",
      "Non-trainable params: 8,662,384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager execution training (For debuging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugging = False\n",
    "\n",
    "if debugging:\n",
    "    model = TinyYOLOv3_functional(anchor_boxes = anchors,num_classes=0,mode=\"tl\")\n",
    "    model.training = False\n",
    "    current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'\n",
    "    model.load_weights(current_directory+'/weights_functional_one_class/original_model_one_class')\n",
    "    \n",
    "    for epochs in range(1,2,1):\n",
    "        for (images,y_true) in train_dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                outputs = model(images)\n",
    "                #print(\"Tamaño de la etiqueta\",y_true[0].shape)\n",
    "                #print(\"Salida\",outputs[0].shape)\n",
    "                loss_x_y = loss_xy(y_true[0],outputs[0])\n",
    "                loss_w_h = loss_wh(y_true[1],outputs[1])\n",
    "                loss_obj = loss_objectness(y_true[2],outputs[2])\n",
    "                loss_noobj = loss_no_objectness(y_true[3],outputs[3])\n",
    "\n",
    "                total_loss =loss_x_y+loss_w_h+loss_obj+loss_noobj\n",
    "            print(epochs,(total_loss.numpy()))\n",
    "            grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "                #logging.info(\"{}_train_{}, {}, {}\".format(\n",
    "                #    epoch, batch, total_loss.numpy()))\n",
    "                \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr =tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_Concatenate_obj_recall', factor=0.2, patience=5, verbose=1, mode='auto',min_delta=0.05)\n",
    "\n",
    "\n",
    "checkpoint_path =root_path+  \"/training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_Concatenate_obj_recall',\n",
    "    mode='max',\n",
    "    save_best_only=True,verbose=1)\n",
    "\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(3e-4)\n",
    "\n",
    "losses = {\"tf_op_layer_split_2\": loss_xy,\n",
    "          \"tf_op_layer_split_2_1\": loss_wh,\n",
    "          \"Concatenate_obj\":loss_objectness,\n",
    "          \"Concatenate_obj_1\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"Concatenate_obj\":[Precision(0.5),Recall(0.5),TruePositives(0.5),FalsePositives(0.5)]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[4,4,2,1])\n",
    "os.chdir(root_path+ \"/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 16, con pesos 1,1,1,1 with lr=0.0001 y usando mse para el (x,y) y usando mse para (w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "    255/Unknown - 8s 30ms/step - loss: 561.3698 - tf_op_layer_split_2_loss: 62.3263 - tf_op_layer_split_2_1_loss: 11.3840 - Concatenate_obj_loss: 0.6863 - Concatenate_obj_1_loss: 411.2038 - Concatenate_obj_precision_1: 0.0026 - Concatenate_obj_recall_1: 0.0947 - Concatenate_obj_true_positives_1: 731.0000 - Concatenate_obj_false_positives_1: 277822.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-89963507c9a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=40,validation_data=val_dataset,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(current_directory+'/weights_retrain_functional/transfer_learning_experiment1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4c4c9f49b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#anchors =[[10/416,14/416],[23/416,27/416],[37/416,58/416],[81/416,82/416],[135/416,169/416],[344/416,319/416]]\n",
    "anchors =[[0.02078,0.049],[0.0426,0.128],[0.08523,0.19356],[0.1506,0.4163],[0.27835,0.58651],[0.5632,0.78614]]\n",
    "\n",
    "model = TinyYOLOv3_functional(anchor_boxes = anchors,num_classes=0,mode=\"ft\")\n",
    "model.training = True\n",
    "current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'\n",
    "model.load_weights(current_directory+'/weights_retrain_functional/transfer_learning_experiment1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr =tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_Concatenate_obj_recall', factor=0.2, patience=5, verbose=1, mode='auto',min_delta=0.05)\n",
    "\n",
    "\n",
    "checkpoint_path =root_path+  \"training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_Concatenate_obj_recall',\n",
    "    mode='max',\n",
    "    save_best_only=True,verbose=1)\n",
    "\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(3e-4)\n",
    "\n",
    "losses = {\"tf_op_layer_split_2\": loss_xy,\n",
    "          \"tf_op_layer_split_2_1\": loss_wh,\n",
    "          \"Concatenate_obj\":loss_objectness,\n",
    "          \"Concatenate_obj_1\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"Concatenate_obj\":[Precision(0.5),Recall(0.5),TruePositives(0.5),FalsePositives(0.5)]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[4,4,2,1])\n",
    "os.chdir(root_path+ \"/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   9213/Unknown - 701s 76ms/step - loss: 46.6265 - tf_op_layer_split_2_loss: 5.7335 - tf_op_layer_split_2_1_loss: 2.1941 - Concatenate_obj_loss: 0.0431 - Concatenate_obj_1_loss: 14.8300 - Concatenate_obj_precision_2: 0.6062 - Concatenate_obj_recall_2: 0.0603 - Concatenate_obj_true_positives_2: 16309.0000 - Concatenate_obj_false_positives_2: 10594.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 708s 77ms/step - loss: 46.6265 - tf_op_layer_split_2_loss: 5.7335 - tf_op_layer_split_2_1_loss: 2.1941 - Concatenate_obj_loss: 0.0431 - Concatenate_obj_1_loss: 14.8300 - Concatenate_obj_precision_2: 0.6062 - Concatenate_obj_recall_2: 0.0603 - Concatenate_obj_true_positives_2: 16309.0000 - Concatenate_obj_false_positives_2: 10594.0000 - val_loss: 40.2709 - val_tf_op_layer_split_2_loss: 5.2061 - val_tf_op_layer_split_2_1_loss: 0.7740 - val_Concatenate_obj_loss: 0.0510 - val_Concatenate_obj_1_loss: 16.2487 - val_Concatenate_obj_precision_2: 0.7856 - val_Concatenate_obj_recall_2: 0.0387 - val_Concatenate_obj_true_positives_2: 458.0000 - val_Concatenate_obj_false_positives_2: 125.0000\n",
      "Epoch 2/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 43.0487 - tf_op_layer_split_2_loss: 5.3236 - tf_op_layer_split_2_1_loss: 1.8507 - Concatenate_obj_loss: 0.0415 - Concatenate_obj_1_loss: 14.2683 - Concatenate_obj_precision_2: 0.6198 - Concatenate_obj_recall_2: 0.0753 - Concatenate_obj_true_positives_2: 20337.0000 - Concatenate_obj_false_positives_2: 12477.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 704s 76ms/step - loss: 43.0480 - tf_op_layer_split_2_loss: 5.3235 - tf_op_layer_split_2_1_loss: 1.8507 - Concatenate_obj_loss: 0.0415 - Concatenate_obj_1_loss: 14.2682 - Concatenate_obj_precision_2: 0.6198 - Concatenate_obj_recall_2: 0.0753 - Concatenate_obj_true_positives_2: 20337.0000 - Concatenate_obj_false_positives_2: 12477.0000 - val_loss: 38.5071 - val_tf_op_layer_split_2_loss: 4.9471 - val_tf_op_layer_split_2_1_loss: 0.6902 - val_Concatenate_obj_loss: 0.0500 - val_Concatenate_obj_1_loss: 15.8576 - val_Concatenate_obj_precision_2: 0.7399 - val_Concatenate_obj_recall_2: 0.0433 - val_Concatenate_obj_true_positives_2: 512.0000 - val_Concatenate_obj_false_positives_2: 180.0000\n",
      "Epoch 3/20\n",
      "9213/9213 [==============================] - ETA: 0s - loss: 41.8899 - tf_op_layer_split_2_loss: 5.1729 - tf_op_layer_split_2_1_loss: 1.7945 - Concatenate_obj_loss: 0.0407 - Concatenate_obj_1_loss: 13.9390 - Concatenate_obj_precision_2: 0.6252 - Concatenate_obj_recall_2: 0.0862 - Concatenate_obj_true_positives_2: 23301.0000 - Concatenate_obj_false_positives_2: 13970.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 710s 77ms/step - loss: 41.8899 - tf_op_layer_split_2_loss: 5.1729 - tf_op_layer_split_2_1_loss: 1.7945 - Concatenate_obj_loss: 0.0407 - Concatenate_obj_1_loss: 13.9390 - Concatenate_obj_precision_2: 0.6252 - Concatenate_obj_recall_2: 0.0862 - Concatenate_obj_true_positives_2: 23301.0000 - Concatenate_obj_false_positives_2: 13970.0000 - val_loss: 37.1803 - val_tf_op_layer_split_2_loss: 4.7219 - val_tf_op_layer_split_2_1_loss: 0.6469 - val_Concatenate_obj_loss: 0.0491 - val_Concatenate_obj_1_loss: 15.6069 - val_Concatenate_obj_precision_2: 0.7853 - val_Concatenate_obj_recall_2: 0.0424 - val_Concatenate_obj_true_positives_2: 501.0000 - val_Concatenate_obj_false_positives_2: 137.0000\n",
      "Epoch 4/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 40.3774 - tf_op_layer_split_2_loss: 4.9936 - tf_op_layer_split_2_1_loss: 1.6584 - Concatenate_obj_loss: 0.0400 - Concatenate_obj_1_loss: 13.6898 - Concatenate_obj_precision_2: 0.6351 - Concatenate_obj_recall_2: 0.0950 - Concatenate_obj_true_positives_2: 25655.0000 - Concatenate_obj_false_positives_2: 14743.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 690s 75ms/step - loss: 40.3768 - tf_op_layer_split_2_loss: 4.9935 - tf_op_layer_split_2_1_loss: 1.6583 - Concatenate_obj_loss: 0.0400 - Concatenate_obj_1_loss: 13.6898 - Concatenate_obj_precision_2: 0.6350 - Concatenate_obj_recall_2: 0.0950 - Concatenate_obj_true_positives_2: 25655.0000 - Concatenate_obj_false_positives_2: 14744.0000 - val_loss: 36.2554 - val_tf_op_layer_split_2_loss: 4.5422 - val_tf_op_layer_split_2_1_loss: 0.6349 - val_Concatenate_obj_loss: 0.0486 - val_Concatenate_obj_1_loss: 15.4498 - val_Concatenate_obj_precision_2: 0.7215 - val_Concatenate_obj_recall_2: 0.0530 - val_Concatenate_obj_true_positives_2: 627.0000 - val_Concatenate_obj_false_positives_2: 242.0000\n",
      "Epoch 5/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 39.2852 - tf_op_layer_split_2_loss: 4.8631 - tf_op_layer_split_2_1_loss: 1.5612 - Concatenate_obj_loss: 0.0395 - Concatenate_obj_1_loss: 13.5091 - Concatenate_obj_precision_2: 0.6387 - Concatenate_obj_recall_2: 0.1009 - Concatenate_obj_true_positives_2: 27271.0000 - Concatenate_obj_false_positives_2: 15424.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 704s 76ms/step - loss: 39.2849 - tf_op_layer_split_2_loss: 4.8631 - tf_op_layer_split_2_1_loss: 1.5612 - Concatenate_obj_loss: 0.0395 - Concatenate_obj_1_loss: 13.5089 - Concatenate_obj_precision_2: 0.6387 - Concatenate_obj_recall_2: 0.1009 - Concatenate_obj_true_positives_2: 27271.0000 - Concatenate_obj_false_positives_2: 15424.0000 - val_loss: 34.9794 - val_tf_op_layer_split_2_loss: 4.3518 - val_tf_op_layer_split_2_1_loss: 0.6033 - val_Concatenate_obj_loss: 0.0473 - val_Concatenate_obj_1_loss: 15.0645 - val_Concatenate_obj_precision_2: 0.7725 - val_Concatenate_obj_recall_2: 0.0574 - val_Concatenate_obj_true_positives_2: 679.0000 - val_Concatenate_obj_false_positives_2: 200.0000\n",
      "Epoch 6/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 38.6530 - tf_op_layer_split_2_loss: 4.7604 - tf_op_layer_split_2_1_loss: 1.5441 - Concatenate_obj_loss: 0.0390 - Concatenate_obj_1_loss: 13.3568 - Concatenate_obj_precision_2: 0.6412 - Concatenate_obj_recall_2: 0.1065 - Concatenate_obj_true_positives_2: 28771.0000 - Concatenate_obj_false_positives_2: 16097.0000  ETA: 11s - loss: 38.9500 - tf_op_layer_split_2_loss: 4.7944 - tf_op_layer_split_2_1_loss: 1.5623 - Concatenate_obj_loss: 0.0394 - Concatenate_obj_1_loss: 13.444WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 709s 77ms/step - loss: 38.6523 - tf_op_layer_split_2_loss: 4.7603 - tf_op_layer_split_2_1_loss: 1.5440 - Concatenate_obj_loss: 0.0390 - Concatenate_obj_1_loss: 13.3568 - Concatenate_obj_precision_2: 0.6412 - Concatenate_obj_recall_2: 0.1065 - Concatenate_obj_true_positives_2: 28771.0000 - Concatenate_obj_false_positives_2: 16097.0000 - val_loss: 34.9112 - val_tf_op_layer_split_2_loss: 4.2732 - val_tf_op_layer_split_2_1_loss: 0.7205 - val_Concatenate_obj_loss: 0.0465 - val_Concatenate_obj_1_loss: 14.8437 - val_Concatenate_obj_precision_2: 0.7663 - val_Concatenate_obj_recall_2: 0.0646 - val_Concatenate_obj_true_positives_2: 764.0000 - val_Concatenate_obj_false_positives_2: 233.0000\n",
      "Epoch 7/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 37.9139 - tf_op_layer_split_2_loss: 4.6401 - tf_op_layer_split_2_1_loss: 1.5090 - Concatenate_obj_loss: 0.0388 - Concatenate_obj_1_loss: 13.2398 - Concatenate_obj_precision_2: 0.6478 - Concatenate_obj_recall_2: 0.1115 - Concatenate_obj_true_positives_2: 30134.0000 - Concatenate_obj_false_positives_2: 16385.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 728s 79ms/step - loss: 37.9137 - tf_op_layer_split_2_loss: 4.6401 - tf_op_layer_split_2_1_loss: 1.5090 - Concatenate_obj_loss: 0.0388 - Concatenate_obj_1_loss: 13.2397 - Concatenate_obj_precision_2: 0.6478 - Concatenate_obj_recall_2: 0.1115 - Concatenate_obj_true_positives_2: 30134.0000 - Concatenate_obj_false_positives_2: 16385.0000 - val_loss: 33.7650 - val_tf_op_layer_split_2_loss: 4.0092 - val_tf_op_layer_split_2_1_loss: 0.7127 - val_Concatenate_obj_loss: 0.0465 - val_Concatenate_obj_1_loss: 14.7845 - val_Concatenate_obj_precision_2: 0.7483 - val_Concatenate_obj_recall_2: 0.0646 - val_Concatenate_obj_true_positives_2: 764.0000 - val_Concatenate_obj_false_positives_2: 257.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 37.1300 - tf_op_layer_split_2_loss: 4.5487 - tf_op_layer_split_2_1_loss: 1.4401 - Concatenate_obj_loss: 0.0383 - Concatenate_obj_1_loss: 13.0978 - Concatenate_obj_precision_2: 0.6468 - Concatenate_obj_recall_2: 0.1170 - Concatenate_obj_true_positives_2: 31607.0000 - Concatenate_obj_false_positives_2: 17260.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 706s 77ms/step - loss: 37.1293 - tf_op_layer_split_2_loss: 4.5486 - tf_op_layer_split_2_1_loss: 1.4401 - Concatenate_obj_loss: 0.0383 - Concatenate_obj_1_loss: 13.0977 - Concatenate_obj_precision_2: 0.6468 - Concatenate_obj_recall_2: 0.1170 - Concatenate_obj_true_positives_2: 31607.0000 - Concatenate_obj_false_positives_2: 17260.0000 - val_loss: 32.3938 - val_tf_op_layer_split_2_loss: 3.8683 - val_tf_op_layer_split_2_1_loss: 0.5681 - val_Concatenate_obj_loss: 0.0460 - val_Concatenate_obj_1_loss: 14.5565 - val_Concatenate_obj_precision_2: 0.7512 - val_Concatenate_obj_recall_2: 0.0687 - val_Concatenate_obj_true_positives_2: 812.0000 - val_Concatenate_obj_false_positives_2: 269.0000\n",
      "Epoch 9/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 36.6999 - tf_op_layer_split_2_loss: 4.4386 - tf_op_layer_split_2_1_loss: 1.4607 - Concatenate_obj_loss: 0.0381 - Concatenate_obj_1_loss: 13.0266 - Concatenate_obj_precision_2: 0.6449 - Concatenate_obj_recall_2: 0.1195 - Concatenate_obj_true_positives_2: 32301.0000 - Concatenate_obj_false_positives_2: 17789.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 700s 76ms/step - loss: 36.6993 - tf_op_layer_split_2_loss: 4.4385 - tf_op_layer_split_2_1_loss: 1.4607 - Concatenate_obj_loss: 0.0381 - Concatenate_obj_1_loss: 13.0265 - Concatenate_obj_precision_2: 0.6449 - Concatenate_obj_recall_2: 0.1195 - Concatenate_obj_true_positives_2: 32301.0000 - Concatenate_obj_false_positives_2: 17789.0000 - val_loss: 32.0227 - val_tf_op_layer_split_2_loss: 3.7833 - val_tf_op_layer_split_2_1_loss: 0.5774 - val_Concatenate_obj_loss: 0.0456 - val_Concatenate_obj_1_loss: 14.4887 - val_Concatenate_obj_precision_2: 0.7530 - val_Concatenate_obj_recall_2: 0.0647 - val_Concatenate_obj_true_positives_2: 765.0000 - val_Concatenate_obj_false_positives_2: 251.0000\n",
      "Epoch 10/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 36.1201 - tf_op_layer_split_2_loss: 4.3374 - tf_op_layer_split_2_1_loss: 1.4417 - Concatenate_obj_loss: 0.0379 - Concatenate_obj_1_loss: 12.9281 - Concatenate_obj_precision_2: 0.6495 - Concatenate_obj_recall_2: 0.1233 - Concatenate_obj_true_positives_2: 33322.0000 - Concatenate_obj_false_positives_2: 17979.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 700s 76ms/step - loss: 36.1196 - tf_op_layer_split_2_loss: 4.3374 - tf_op_layer_split_2_1_loss: 1.4416 - Concatenate_obj_loss: 0.0379 - Concatenate_obj_1_loss: 12.9279 - Concatenate_obj_precision_2: 0.6495 - Concatenate_obj_recall_2: 0.1233 - Concatenate_obj_true_positives_2: 33322.0000 - Concatenate_obj_false_positives_2: 17980.0000 - val_loss: 31.6694 - val_tf_op_layer_split_2_loss: 3.6253 - val_tf_op_layer_split_2_1_loss: 0.6781 - val_Concatenate_obj_loss: 0.0452 - val_Concatenate_obj_1_loss: 14.3651 - val_Concatenate_obj_precision_2: 0.7739 - val_Concatenate_obj_recall_2: 0.0692 - val_Concatenate_obj_true_positives_2: 818.0000 - val_Concatenate_obj_false_positives_2: 239.0000\n",
      "Epoch 11/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 35.5325 - tf_op_layer_split_2_loss: 4.2572 - tf_op_layer_split_2_1_loss: 1.4008 - Concatenate_obj_loss: 0.0376 - Concatenate_obj_1_loss: 12.8254 - Concatenate_obj_precision_2: 0.6532 - Concatenate_obj_recall_2: 0.1272 - Concatenate_obj_true_positives_2: 34369.0000 - Concatenate_obj_false_positives_2: 18250.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 701s 76ms/step - loss: 35.5318 - tf_op_layer_split_2_loss: 4.2571 - tf_op_layer_split_2_1_loss: 1.4007 - Concatenate_obj_loss: 0.0375 - Concatenate_obj_1_loss: 12.8252 - Concatenate_obj_precision_2: 0.6532 - Concatenate_obj_recall_2: 0.1272 - Concatenate_obj_true_positives_2: 34369.0000 - Concatenate_obj_false_positives_2: 18250.0000 - val_loss: 30.3166 - val_tf_op_layer_split_2_loss: 3.4286 - val_tf_op_layer_split_2_1_loss: 0.6012 - val_Concatenate_obj_loss: 0.0444 - val_Concatenate_obj_1_loss: 14.1086 - val_Concatenate_obj_precision_2: 0.7632 - val_Concatenate_obj_recall_2: 0.0804 - val_Concatenate_obj_true_positives_2: 951.0000 - val_Concatenate_obj_false_positives_2: 295.0000\n",
      "Epoch 12/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 35.1631 - tf_op_layer_split_2_loss: 4.1959 - tf_op_layer_split_2_1_loss: 1.3882 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.7522 - Concatenate_obj_precision_2: 0.6549 - Concatenate_obj_recall_2: 0.1303 - Concatenate_obj_true_positives_2: 35207.0000 - Concatenate_obj_false_positives_2: 18555.0000- ETA: 3s - loss: 35.2605 - tf_op_layer_split_2_loss: 4.2070 - tf_op_layer_split_2_1_loss: 1.3940 - Concatenate_obj_loss: 0.0375 - Concatenate_obj_1_loss: 12.7813 - Concatenate_obj_precision_2: 0.6549 - Concatenate_obj_recall_2: 0.1303 - Concatenate_obj_true_positives_2: 35143.0000 - ConcWARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 702s 76ms/step - loss: 35.1624 - tf_op_layer_split_2_loss: 4.1958 - tf_op_layer_split_2_1_loss: 1.3881 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.7520 - Concatenate_obj_precision_2: 0.6549 - Concatenate_obj_recall_2: 0.1303 - Concatenate_obj_true_positives_2: 35207.0000 - Concatenate_obj_false_positives_2: 18556.0000 - val_loss: 29.7733 - val_tf_op_layer_split_2_loss: 3.3318 - val_tf_op_layer_split_2_1_loss: 0.5722 - val_Concatenate_obj_loss: 0.0441 - val_Concatenate_obj_1_loss: 14.0687 - val_Concatenate_obj_precision_2: 0.7653 - val_Concatenate_obj_recall_2: 0.0781 - val_Concatenate_obj_true_positives_2: 923.0000 - val_Concatenate_obj_false_positives_2: 283.0000\n",
      "Epoch 13/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 34.5766 - tf_op_layer_split_2_loss: 4.0754 - tf_op_layer_split_2_1_loss: 1.3875 - Concatenate_obj_loss: 0.0371 - Concatenate_obj_1_loss: 12.6511 - Concatenate_obj_precision_2: 0.6550 - Concatenate_obj_recall_2: 0.1336 - Concatenate_obj_true_positives_2: 36082.0000 - Concatenate_obj_false_positives_2: 19005.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 702s 76ms/step - loss: 34.5772 - tf_op_layer_split_2_loss: 4.0756 - tf_op_layer_split_2_1_loss: 1.3875 - Concatenate_obj_loss: 0.0371 - Concatenate_obj_1_loss: 12.6510 - Concatenate_obj_precision_2: 0.6550 - Concatenate_obj_recall_2: 0.1336 - Concatenate_obj_true_positives_2: 36082.0000 - Concatenate_obj_false_positives_2: 19006.0000 - val_loss: 29.4521 - val_tf_op_layer_split_2_loss: 3.2644 - val_tf_op_layer_split_2_1_loss: 0.5787 - val_Concatenate_obj_loss: 0.0440 - val_Concatenate_obj_1_loss: 13.9918 - val_Concatenate_obj_precision_2: 0.7775 - val_Concatenate_obj_recall_2: 0.0771 - val_Concatenate_obj_true_positives_2: 912.0000 - val_Concatenate_obj_false_positives_2: 261.0000\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9212/9213 [============================>.] - ETA: 0s - loss: 34.0257 - tf_op_layer_split_2_loss: 4.0241 - tf_op_layer_split_2_1_loss: 1.3191 - Concatenate_obj_loss: 0.0369 - Concatenate_obj_1_loss: 12.5792 - Concatenate_obj_precision_2: 0.6569 - Concatenate_obj_recall_2: 0.1370 - Concatenate_obj_true_positives_2: 37028.0000 - Concatenate_obj_false_positives_2: 19344.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 703s 76ms/step - loss: 34.0252 - tf_op_layer_split_2_loss: 4.0240 - tf_op_layer_split_2_1_loss: 1.3191 - Concatenate_obj_loss: 0.0369 - Concatenate_obj_1_loss: 12.5791 - Concatenate_obj_precision_2: 0.6569 - Concatenate_obj_recall_2: 0.1370 - Concatenate_obj_true_positives_2: 37028.0000 - Concatenate_obj_false_positives_2: 19344.0000 - val_loss: 28.9101 - val_tf_op_layer_split_2_loss: 3.1254 - val_tf_op_layer_split_2_1_loss: 0.6756 - val_Concatenate_obj_loss: 0.0428 - val_Concatenate_obj_1_loss: 13.6203 - val_Concatenate_obj_precision_2: 0.7672 - val_Concatenate_obj_recall_2: 0.0886 - val_Concatenate_obj_true_positives_2: 1048.0000 - val_Concatenate_obj_false_positives_2: 318.0000\n",
      "Epoch 15/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 33.4240 - tf_op_layer_split_2_loss: 3.8919 - tf_op_layer_split_2_1_loss: 1.3184 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.5094 - Concatenate_obj_precision_2: 0.6602 - Concatenate_obj_recall_2: 0.1403 - Concatenate_obj_true_positives_2: 37910.0000 - Concatenate_obj_false_positives_2: 19512.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 702s 76ms/step - loss: 33.4235 - tf_op_layer_split_2_loss: 3.8918 - tf_op_layer_split_2_1_loss: 1.3184 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.5093 - Concatenate_obj_precision_2: 0.6602 - Concatenate_obj_recall_2: 0.1403 - Concatenate_obj_true_positives_2: 37912.0000 - Concatenate_obj_false_positives_2: 19513.0000 - val_loss: 28.0010 - val_tf_op_layer_split_2_loss: 3.0848 - val_tf_op_layer_split_2_1_loss: 0.4746 - val_Concatenate_obj_loss: 0.0430 - val_Concatenate_obj_1_loss: 13.6772 - val_Concatenate_obj_precision_2: 0.7666 - val_Concatenate_obj_recall_2: 0.0858 - val_Concatenate_obj_true_positives_2: 1015.0000 - val_Concatenate_obj_false_positives_2: 309.0000\n",
      "Epoch 16/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 33.2346 - tf_op_layer_split_2_loss: 3.8574 - tf_op_layer_split_2_1_loss: 1.3152 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4706 - Concatenate_obj_precision_2: 0.6572 - Concatenate_obj_recall_2: 0.1418 - Concatenate_obj_true_positives_2: 38323.0000 - Concatenate_obj_false_positives_2: 19988.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 694s 75ms/step - loss: 33.2341 - tf_op_layer_split_2_loss: 3.8574 - tf_op_layer_split_2_1_loss: 1.3152 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4705 - Concatenate_obj_precision_2: 0.6572 - Concatenate_obj_recall_2: 0.1418 - Concatenate_obj_true_positives_2: 38324.0000 - Concatenate_obj_false_positives_2: 19988.0000 - val_loss: 27.4393 - val_tf_op_layer_split_2_loss: 2.9385 - val_tf_op_layer_split_2_1_loss: 0.5107 - val_Concatenate_obj_loss: 0.0426 - val_Concatenate_obj_1_loss: 13.5569 - val_Concatenate_obj_precision_2: 0.7744 - val_Concatenate_obj_recall_2: 0.0880 - val_Concatenate_obj_true_positives_2: 1040.0000 - val_Concatenate_obj_false_positives_2: 303.0000\n",
      "Epoch 17/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 33.0865 - tf_op_layer_split_2_loss: 3.8171 - tf_op_layer_split_2_1_loss: 1.3372 - Concatenate_obj_loss: 0.0364 - Concatenate_obj_1_loss: 12.3966 - Concatenate_obj_precision_2: 0.6638 - Concatenate_obj_recall_2: 0.1451 - Concatenate_obj_true_positives_2: 39212.0000 - Concatenate_obj_false_positives_2: 19857.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 699s 76ms/step - loss: 33.0861 - tf_op_layer_split_2_loss: 3.8170 - tf_op_layer_split_2_1_loss: 1.3372 - Concatenate_obj_loss: 0.0364 - Concatenate_obj_1_loss: 12.3964 - Concatenate_obj_precision_2: 0.6638 - Concatenate_obj_recall_2: 0.1451 - Concatenate_obj_true_positives_2: 39212.0000 - Concatenate_obj_false_positives_2: 19857.0000 - val_loss: 27.6904 - val_tf_op_layer_split_2_loss: 2.8761 - val_tf_op_layer_split_2_1_loss: 0.6563 - val_Concatenate_obj_loss: 0.0424 - val_Concatenate_obj_1_loss: 13.4761 - val_Concatenate_obj_precision_2: 0.7549 - val_Concatenate_obj_recall_2: 0.0972 - val_Concatenate_obj_true_positives_2: 1149.0000 - val_Concatenate_obj_false_positives_2: 373.0000\n",
      "Epoch 18/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 32.8014 - tf_op_layer_split_2_loss: 3.7643 - tf_op_layer_split_2_1_loss: 1.3332 - Concatenate_obj_loss: 0.0362 - Concatenate_obj_1_loss: 12.3389 - Concatenate_obj_precision_2: 0.6617 - Concatenate_obj_recall_2: 0.1475 - Concatenate_obj_true_positives_2: 39843.0000 - Concatenate_obj_false_positives_2: 20369.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 693s 75ms/step - loss: 32.8008 - tf_op_layer_split_2_loss: 3.7643 - tf_op_layer_split_2_1_loss: 1.3331 - Concatenate_obj_loss: 0.0362 - Concatenate_obj_1_loss: 12.3387 - Concatenate_obj_precision_2: 0.6617 - Concatenate_obj_recall_2: 0.1475 - Concatenate_obj_true_positives_2: 39845.0000 - Concatenate_obj_false_positives_2: 20369.0000 - val_loss: 27.2270 - val_tf_op_layer_split_2_loss: 2.8463 - val_tf_op_layer_split_2_1_loss: 0.5840 - val_Concatenate_obj_loss: 0.0422 - val_Concatenate_obj_1_loss: 13.4211 - val_Concatenate_obj_precision_2: 0.7713 - val_Concatenate_obj_recall_2: 0.0924 - val_Concatenate_obj_true_positives_2: 1093.0000 - val_Concatenate_obj_false_positives_2: 324.0000\n",
      "Epoch 19/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 32.3783 - tf_op_layer_split_2_loss: 3.6935 - tf_op_layer_split_2_1_loss: 1.3202 - Concatenate_obj_loss: 0.0360 - Concatenate_obj_1_loss: 12.2515 - Concatenate_obj_precision_2: 0.6652 - Concatenate_obj_recall_2: 0.1521 - Concatenate_obj_true_positives_2: 41092.0000 - Concatenate_obj_false_positives_2: 20681.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 696s 76ms/step - loss: 32.3777 - tf_op_layer_split_2_loss: 3.6935 - tf_op_layer_split_2_1_loss: 1.3201 - Concatenate_obj_loss: 0.0360 - Concatenate_obj_1_loss: 12.2513 - Concatenate_obj_precision_2: 0.6652 - Concatenate_obj_recall_2: 0.1521 - Concatenate_obj_true_positives_2: 41093.0000 - Concatenate_obj_false_positives_2: 20682.0000 - val_loss: 26.5416 - val_tf_op_layer_split_2_loss: 2.7516 - val_tf_op_layer_split_2_1_loss: 0.5064 - val_Concatenate_obj_loss: 0.0423 - val_Concatenate_obj_1_loss: 13.4250 - val_Concatenate_obj_precision_2: 0.7866 - val_Concatenate_obj_recall_2: 0.0941 - val_Concatenate_obj_true_positives_2: 1113.0000 - val_Concatenate_obj_false_positives_2: 302.0000\n",
      "Epoch 20/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 31.6864 - tf_op_layer_split_2_loss: 3.6256 - tf_op_layer_split_2_1_loss: 1.2247 - Concatenate_obj_loss: 0.0360 - Concatenate_obj_1_loss: 12.2135 - Concatenate_obj_precision_2: 0.6667 - Concatenate_obj_recall_2: 0.1540 - Concatenate_obj_true_positives_2: 41619.0000 - Concatenate_obj_false_positives_2: 20811.0000WARNING:tensorflow:Can save best model only with val_Concatenate_obj_recall available, skipping.\n",
      "9213/9213 [==============================] - 693s 75ms/step - loss: 31.6858 - tf_op_layer_split_2_loss: 3.6255 - tf_op_layer_split_2_1_loss: 1.2246 - Concatenate_obj_loss: 0.0360 - Concatenate_obj_1_loss: 12.2133 - Concatenate_obj_precision_2: 0.6667 - Concatenate_obj_recall_2: 0.1540 - Concatenate_obj_true_positives_2: 41621.0000 - Concatenate_obj_false_positives_2: 20812.0000 - val_loss: 26.2163 - val_tf_op_layer_split_2_loss: 2.6902 - val_tf_op_layer_split_2_1_loss: 0.5141 - val_Concatenate_obj_loss: 0.0421 - val_Concatenate_obj_1_loss: 13.3148 - val_Concatenate_obj_precision_2: 0.7868 - val_Concatenate_obj_recall_2: 0.0936 - val_Concatenate_obj_true_positives_2: 1107.0000 - val_Concatenate_obj_false_positives_2: 300.0000\n"
     ]
    }
   ],
   "source": [
    "os.chdir(root_path+ \"/pedestrian_dataset_train_tfr\")\n",
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(current_directory+'/weights_retrain_functional/fine_tuning_part_1_experiment1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTINUACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f66716d49b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#anchors =[[10/416,14/416],[23/416,27/416],[37/416,58/416],[81/416,82/416],[135/416,169/416],[344/416,319/416]]\n",
    "anchors =[[0.02078,0.049],[0.0426,0.128],[0.08523,0.19356],[0.1506,0.4163],[0.27835,0.58651],[0.5632,0.78614]]\n",
    "\n",
    "model = TinyYOLOv3_functional(anchor_boxes = anchors,num_classes=0,mode=\"ft\")\n",
    "model.training = False\n",
    "current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'\n",
    "model.load_weights(current_directory+'/weights_retrain_functional/fine_tuning_part_1_experiment1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr =tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_Concatenate_obj_recall', factor=0.1, patience=4, verbose=1, mode='auto',min_delta=0.05)\n",
    "\n",
    "\n",
    "checkpoint_path = root_path+ \"/training_3/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_Concatenate_obj_recall',\n",
    "    mode='max',\n",
    "    save_best_only=True,verbose=1)\n",
    "\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(3e-4)\n",
    "\n",
    "losses = {\"tf_op_layer_split_2\": loss_xy,\n",
    "          \"tf_op_layer_split_2_1\": loss_wh,\n",
    "          \"Concatenate_obj\":loss_objectness,\n",
    "          \"Concatenate_obj_1\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"Concatenate_obj\":[Precision(0.5),Recall(0.5),TruePositives(0.5),FalsePositives(0.5)]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[2,1,2,1])\n",
    "os.chdir(root_path+ \"/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "   9213/Unknown - 661s 72ms/step - loss: 24.7276 - tf_op_layer_split_2_loss: 5.0535 - tf_op_layer_split_2_1_loss: 1.6996 - Concatenate_obj_loss: 0.0378 - Concatenate_obj_1_loss: 12.8455 - Concatenate_obj_precision: 0.6334 - Concatenate_obj_recall: 0.1161 - Concatenate_obj_true_positives: 31362.0000 - Concatenate_obj_false_positives: 18154.0000- 653s 72ms/step - loss: 24.8774 - tf_op_layer_split_2_loss: 5.0855 - tf_op_layer_split_2_1_loss: 1.7171 - Concatenate_obj_loss: 0.0382 - Concatenate_obj_1_loss: 12.9129 - Concatenate_obj_precision: 0.6350 - Concatenate\n",
      "Epoch 00001: val_Concatenate_obj_recall improved from -inf to 0.13735, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 668s 72ms/step - loss: 24.7276 - tf_op_layer_split_2_loss: 5.0535 - tf_op_layer_split_2_1_loss: 1.6996 - Concatenate_obj_loss: 0.0378 - Concatenate_obj_1_loss: 12.8455 - Concatenate_obj_precision: 0.6334 - Concatenate_obj_recall: 0.1161 - Concatenate_obj_true_positives: 31362.0000 - Concatenate_obj_false_positives: 18154.0000 - val_loss: 22.5685 - val_tf_op_layer_split_2_loss: 4.7708 - val_tf_op_layer_split_2_1_loss: 0.6839 - val_Concatenate_obj_loss: 0.0376 - val_Concatenate_obj_1_loss: 12.2679 - val_Concatenate_obj_precision: 0.7211 - val_Concatenate_obj_recall: 0.1373 - val_Concatenate_obj_true_positives: 1624.0000 - val_Concatenate_obj_false_positives: 628.0000\n",
      "Epoch 2/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.7008 - tf_op_layer_split_2_loss: 5.0368 - tf_op_layer_split_2_1_loss: 1.7206 - Concatenate_obj_loss: 0.0378 - Concatenate_obj_1_loss: 12.8311 - Concatenate_obj_precision: 0.6375 - Concatenate_obj_recall: 0.1175 - Concatenate_obj_true_positives: 31758.0000 - Concatenate_obj_false_positives: 18055.0000\n",
      "Epoch 00002: val_Concatenate_obj_recall improved from 0.13735 to 0.13862, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 664s 72ms/step - loss: 24.7005 - tf_op_layer_split_2_loss: 5.0367 - tf_op_layer_split_2_1_loss: 1.7205 - Concatenate_obj_loss: 0.0378 - Concatenate_obj_1_loss: 12.8310 - Concatenate_obj_precision: 0.6375 - Concatenate_obj_recall: 0.1175 - Concatenate_obj_true_positives: 31758.0000 - Concatenate_obj_false_positives: 18055.0000 - val_loss: 22.5231 - val_tf_op_layer_split_2_loss: 4.7543 - val_tf_op_layer_split_2_1_loss: 0.6890 - val_Concatenate_obj_loss: 0.0375 - val_Concatenate_obj_1_loss: 12.2503 - val_Concatenate_obj_precision: 0.7230 - val_Concatenate_obj_recall: 0.1386 - val_Concatenate_obj_true_positives: 1639.0000 - val_Concatenate_obj_false_positives: 628.0000\n",
      "Epoch 3/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.6052 - tf_op_layer_split_2_loss: 5.0154 - tf_op_layer_split_2_1_loss: 1.7058 - Concatenate_obj_loss: 0.0377 - Concatenate_obj_1_loss: 12.7931 - Concatenate_obj_precision: 0.6373 - Concatenate_obj_recall: 0.1184 - Concatenate_obj_true_positives: 32002.0000 - Concatenate_obj_false_positives: 18210.0000\n",
      "Epoch 00003: val_Concatenate_obj_recall did not improve from 0.13862\n",
      "9213/9213 [==============================] - 662s 72ms/step - loss: 24.6049 - tf_op_layer_split_2_loss: 5.0154 - tf_op_layer_split_2_1_loss: 1.7057 - Concatenate_obj_loss: 0.0377 - Concatenate_obj_1_loss: 12.7930 - Concatenate_obj_precision: 0.6373 - Concatenate_obj_recall: 0.1184 - Concatenate_obj_true_positives: 32002.0000 - Concatenate_obj_false_positives: 18210.0000 - val_loss: 22.4783 - val_tf_op_layer_split_2_loss: 4.7420 - val_tf_op_layer_split_2_1_loss: 0.6815 - val_Concatenate_obj_loss: 0.0375 - val_Concatenate_obj_1_loss: 12.2377 - val_Concatenate_obj_precision: 0.7220 - val_Concatenate_obj_recall: 0.1386 - val_Concatenate_obj_true_positives: 1639.0000 - val_Concatenate_obj_false_positives: 631.0000\n",
      "Epoch 4/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.6296 - tf_op_layer_split_2_loss: 5.0234 - tf_op_layer_split_2_1_loss: 1.7170 - Concatenate_obj_loss: 0.0377 - Concatenate_obj_1_loss: 12.7902 - Concatenate_obj_precision: 0.6372 - Concatenate_obj_recall: 0.1187 - Concatenate_obj_true_positives: 32068.0000 - Concatenate_obj_false_positives: 18259.0000\n",
      "Epoch 00004: val_Concatenate_obj_recall improved from 0.13862 to 0.13912, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 662s 72ms/step - loss: 24.6293 - tf_op_layer_split_2_loss: 5.0233 - tf_op_layer_split_2_1_loss: 1.7169 - Concatenate_obj_loss: 0.0377 - Concatenate_obj_1_loss: 12.7902 - Concatenate_obj_precision: 0.6372 - Concatenate_obj_recall: 0.1186 - Concatenate_obj_true_positives: 32068.0000 - Concatenate_obj_false_positives: 18259.0000 - val_loss: 22.4360 - val_tf_op_layer_split_2_loss: 4.7310 - val_tf_op_layer_split_2_1_loss: 0.6899 - val_Concatenate_obj_loss: 0.0374 - val_Concatenate_obj_1_loss: 12.2093 - val_Concatenate_obj_precision: 0.7202 - val_Concatenate_obj_recall: 0.1391 - val_Concatenate_obj_true_positives: 1645.0000 - val_Concatenate_obj_false_positives: 639.0000\n",
      "Epoch 5/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.5677 - tf_op_layer_split_2_loss: 4.9861 - tf_op_layer_split_2_1_loss: 1.7379 - Concatenate_obj_loss: 0.0377 - Concatenate_obj_1_loss: 12.7823 - Concatenate_obj_precision: 0.6379 - Concatenate_obj_recall: 0.1199 - Concatenate_obj_true_positives: 32400.0000 - Concatenate_obj_false_positives: 18390.0000\n",
      "Epoch 00005: val_Concatenate_obj_recall improved from 0.13912 to 0.13972, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 667s 72ms/step - loss: 24.5675 - tf_op_layer_split_2_loss: 4.9861 - tf_op_layer_split_2_1_loss: 1.7378 - Concatenate_obj_loss: 0.0377 - Concatenate_obj_1_loss: 12.7822 - Concatenate_obj_precision: 0.6379 - Concatenate_obj_recall: 0.1199 - Concatenate_obj_true_positives: 32400.0000 - Concatenate_obj_false_positives: 18390.0000 - val_loss: 22.3950 - val_tf_op_layer_split_2_loss: 4.7193 - val_tf_op_layer_split_2_1_loss: 0.6780 - val_Concatenate_obj_loss: 0.0374 - val_Concatenate_obj_1_loss: 12.2035 - val_Concatenate_obj_precision: 0.7223 - val_Concatenate_obj_recall: 0.1397 - val_Concatenate_obj_true_positives: 1652.0000 - val_Concatenate_obj_false_positives: 635.0000\n",
      "Epoch 6/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.3942 - tf_op_layer_split_2_loss: 4.9573 - tf_op_layer_split_2_1_loss: 1.6826 - Concatenate_obj_loss: 0.0375 - Concatenate_obj_1_loss: 12.7220 - Concatenate_obj_precision: 0.6372 - Concatenate_obj_recall: 0.1208 - Concatenate_obj_true_positives: 32628.0000 - Concatenate_obj_false_positives: 18574.0000\n",
      "Epoch 00006: val_Concatenate_obj_recall did not improve from 0.13972\n",
      "9213/9213 [==============================] - 676s 73ms/step - loss: 24.3939 - tf_op_layer_split_2_loss: 4.9572 - tf_op_layer_split_2_1_loss: 1.6826 - Concatenate_obj_loss: 0.0375 - Concatenate_obj_1_loss: 12.7219 - Concatenate_obj_precision: 0.6372 - Concatenate_obj_recall: 0.1208 - Concatenate_obj_true_positives: 32628.0000 - Concatenate_obj_false_positives: 18574.0000 - val_loss: 22.3564 - val_tf_op_layer_split_2_loss: 4.7076 - val_tf_op_layer_split_2_1_loss: 0.6704 - val_Concatenate_obj_loss: 0.0374 - val_Concatenate_obj_1_loss: 12.1960 - val_Concatenate_obj_precision: 0.7252 - val_Concatenate_obj_recall: 0.1397 - val_Concatenate_obj_true_positives: 1652.0000 - val_Concatenate_obj_false_positives: 626.0000\n",
      "Epoch 7/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.3884 - tf_op_layer_split_2_loss: 4.9696 - tf_op_layer_split_2_1_loss: 1.6361 - Concatenate_obj_loss: 0.0376 - Concatenate_obj_1_loss: 12.7379 - Concatenate_obj_precision: 0.6367 - Concatenate_obj_recall: 0.1204 - Concatenate_obj_true_positives: 32530.0000 - Concatenate_obj_false_positives: 18562.0000\n",
      "Epoch 00007: val_Concatenate_obj_recall did not improve from 0.13972\n",
      "9213/9213 [==============================] - 658s 71ms/step - loss: 24.3881 - tf_op_layer_split_2_loss: 4.9695 - tf_op_layer_split_2_1_loss: 1.6360 - Concatenate_obj_loss: 0.0376 - Concatenate_obj_1_loss: 12.7378 - Concatenate_obj_precision: 0.6367 - Concatenate_obj_recall: 0.1203 - Concatenate_obj_true_positives: 32530.0000 - Concatenate_obj_false_positives: 18562.0000 - val_loss: 22.3269 - val_tf_op_layer_split_2_loss: 4.6953 - val_tf_op_layer_split_2_1_loss: 0.6734 - val_Concatenate_obj_loss: 0.0374 - val_Concatenate_obj_1_loss: 12.1882 - val_Concatenate_obj_precision: 0.7244 - val_Concatenate_obj_recall: 0.1396 - val_Concatenate_obj_true_positives: 1651.0000 - val_Concatenate_obj_false_positives: 628.0000\n",
      "Epoch 8/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.2932 - tf_op_layer_split_2_loss: 4.9553 - tf_op_layer_split_2_1_loss: 1.6079 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.6998 - Concatenate_obj_precision: 0.6385 - Concatenate_obj_recall: 0.1225 - Concatenate_obj_true_positives: 33095.0000 - Concatenate_obj_false_positives: 18740.0000\n",
      "Epoch 00008: val_Concatenate_obj_recall improved from 0.13972 to 0.14301, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 666s 72ms/step - loss: 24.2929 - tf_op_layer_split_2_loss: 4.9552 - tf_op_layer_split_2_1_loss: 1.6079 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.6997 - Concatenate_obj_precision: 0.6385 - Concatenate_obj_recall: 0.1225 - Concatenate_obj_true_positives: 33095.0000 - Concatenate_obj_false_positives: 18740.0000 - val_loss: 22.2476 - val_tf_op_layer_split_2_loss: 4.6747 - val_tf_op_layer_split_2_1_loss: 0.6683 - val_Concatenate_obj_loss: 0.0373 - val_Concatenate_obj_1_loss: 12.1554 - val_Concatenate_obj_precision: 0.7230 - val_Concatenate_obj_recall: 0.1430 - val_Concatenate_obj_true_positives: 1691.0000 - val_Concatenate_obj_false_positives: 648.0000\n",
      "Epoch 9/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.2881 - tf_op_layer_split_2_loss: 4.9474 - tf_op_layer_split_2_1_loss: 1.6332 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.6854 - Concatenate_obj_precision: 0.6399 - Concatenate_obj_recall: 0.1231 - Concatenate_obj_true_positives: 33264.0000 - Concatenate_obj_false_positives: 18716.0000\n",
      "Epoch 00009: val_Concatenate_obj_recall improved from 0.14301 to 0.14369, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 668s 73ms/step - loss: 24.2878 - tf_op_layer_split_2_loss: 4.9473 - tf_op_layer_split_2_1_loss: 1.6331 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.6853 - Concatenate_obj_precision: 0.6399 - Concatenate_obj_recall: 0.1231 - Concatenate_obj_true_positives: 33264.0000 - Concatenate_obj_false_positives: 18716.0000 - val_loss: 22.2329 - val_tf_op_layer_split_2_loss: 4.6700 - val_tf_op_layer_split_2_1_loss: 0.6709 - val_Concatenate_obj_loss: 0.0373 - val_Concatenate_obj_1_loss: 12.1475 - val_Concatenate_obj_precision: 0.7233 - val_Concatenate_obj_recall: 0.1437 - val_Concatenate_obj_true_positives: 1699.0000 - val_Concatenate_obj_false_positives: 650.0000\n",
      "Epoch 10/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.2566 - tf_op_layer_split_2_loss: 4.9434 - tf_op_layer_split_2_1_loss: 1.6233 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.6716 - Concatenate_obj_precision: 0.6398 - Concatenate_obj_recall: 0.1220 - Concatenate_obj_true_positives: 32968.0000 - Concatenate_obj_false_positives: 18561.0000\n",
      "Epoch 00010: val_Concatenate_obj_recall improved from 0.14369 to 0.14420, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 668s 72ms/step - loss: 24.2563 - tf_op_layer_split_2_loss: 4.9433 - tf_op_layer_split_2_1_loss: 1.6233 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.6716 - Concatenate_obj_precision: 0.6398 - Concatenate_obj_recall: 0.1220 - Concatenate_obj_true_positives: 32968.0000 - Concatenate_obj_false_positives: 18561.0000 - val_loss: 22.1637 - val_tf_op_layer_split_2_loss: 4.6595 - val_tf_op_layer_split_2_1_loss: 0.6372 - val_Concatenate_obj_loss: 0.0372 - val_Concatenate_obj_1_loss: 12.1329 - val_Concatenate_obj_precision: 0.7228 - val_Concatenate_obj_recall: 0.1442 - val_Concatenate_obj_true_positives: 1705.0000 - val_Concatenate_obj_false_positives: 654.0000\n",
      "Epoch 11/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.2105 - tf_op_layer_split_2_loss: 4.9157 - tf_op_layer_split_2_1_loss: 1.6647 - Concatenate_obj_loss: 0.0373 - Concatenate_obj_1_loss: 12.6399 - Concatenate_obj_precision: 0.6400 - Concatenate_obj_recall: 0.1239 - Concatenate_obj_true_positives: 33482.0000 - Concatenate_obj_false_positives: 18836.0000\n",
      "Epoch 00011: val_Concatenate_obj_recall did not improve from 0.14420\n",
      "9213/9213 [==============================] - 666s 72ms/step - loss: 24.2104 - tf_op_layer_split_2_loss: 4.9156 - tf_op_layer_split_2_1_loss: 1.6647 - Concatenate_obj_loss: 0.0373 - Concatenate_obj_1_loss: 12.6399 - Concatenate_obj_precision: 0.6400 - Concatenate_obj_recall: 0.1239 - Concatenate_obj_true_positives: 33482.0000 - Concatenate_obj_false_positives: 18836.0000 - val_loss: 22.1357 - val_tf_op_layer_split_2_loss: 4.6435 - val_tf_op_layer_split_2_1_loss: 0.6567 - val_Concatenate_obj_loss: 0.0372 - val_Concatenate_obj_1_loss: 12.1175 - val_Concatenate_obj_precision: 0.7192 - val_Concatenate_obj_recall: 0.1439 - val_Concatenate_obj_true_positives: 1701.0000 - val_Concatenate_obj_false_positives: 664.0000\n",
      "Epoch 12/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.2809 - tf_op_layer_split_2_loss: 4.9364 - tf_op_layer_split_2_1_loss: 1.6922 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.6412 - Concatenate_obj_precision: 0.6412 - Concatenate_obj_recall: 0.1248 - Concatenate_obj_true_positives: 33737.0000 - Concatenate_obj_false_positives: 18875.0000\n",
      "Epoch 00012: val_Concatenate_obj_recall improved from 0.14420 to 0.14454, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 667s 72ms/step - loss: 24.2805 - tf_op_layer_split_2_loss: 4.9363 - tf_op_layer_split_2_1_loss: 1.6921 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.6411 - Concatenate_obj_precision: 0.6412 - Concatenate_obj_recall: 0.1248 - Concatenate_obj_true_positives: 33737.0000 - Concatenate_obj_false_positives: 18875.0000 - val_loss: 22.0963 - val_tf_op_layer_split_2_loss: 4.6310 - val_tf_op_layer_split_2_1_loss: 0.6538 - val_Concatenate_obj_loss: 0.0372 - val_Concatenate_obj_1_loss: 12.1062 - val_Concatenate_obj_precision: 0.7208 - val_Concatenate_obj_recall: 0.1445 - val_Concatenate_obj_true_positives: 1709.0000 - val_Concatenate_obj_false_positives: 662.0000\n",
      "Epoch 13/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.1793 - tf_op_layer_split_2_loss: 4.8928 - tf_op_layer_split_2_1_loss: 1.6791 - Concatenate_obj_loss: 0.0373 - Concatenate_obj_1_loss: 12.6399 - Concatenate_obj_precision: 0.6429 - Concatenate_obj_recall: 0.1249 - Concatenate_obj_true_positives: 33761.0000 - Concatenate_obj_false_positives: 18750.0000- ETA: 9s - loss: 24.3488 - tf_op_layer_split_2_loss: 4.9296 - tf_op_layer_split_2_1_loss: 1.6998 - Concatenate_obj_loss: 0.0377 - Concatenate_obj_1_loss: 12.7143 - Concatenate_obj_precision: 0.6445 - Concatenate_o - ETA: 1s - loss: 24.2080 - tf_op_layer_split_2_loss: 4.8990 - tf_op_layer_split_2_1_loss: 1.6826 - Concatenate_obj_loss: 0.0374 - Concatenate_obj_1_loss: 12.6526 - Concatenate_obj_precision: 0.6432 - Concatenate_obj_recall: 0.1250 - Concatenate_obj_true_positives: 33730.0000 - Concatenate_obj_false_p\n",
      "Epoch 00013: val_Concatenate_obj_recall improved from 0.14454 to 0.14657, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 662s 72ms/step - loss: 24.1790 - tf_op_layer_split_2_loss: 4.8927 - tf_op_layer_split_2_1_loss: 1.6791 - Concatenate_obj_loss: 0.0373 - Concatenate_obj_1_loss: 12.6398 - Concatenate_obj_precision: 0.6429 - Concatenate_obj_recall: 0.1249 - Concatenate_obj_true_positives: 33762.0000 - Concatenate_obj_false_positives: 18750.0000 - val_loss: 22.0448 - val_tf_op_layer_split_2_loss: 4.6141 - val_tf_op_layer_split_2_1_loss: 0.6535 - val_Concatenate_obj_loss: 0.0371 - val_Concatenate_obj_1_loss: 12.0888 - val_Concatenate_obj_precision: 0.7182 - val_Concatenate_obj_recall: 0.1466 - val_Concatenate_obj_true_positives: 1733.0000 - val_Concatenate_obj_false_positives: 680.0000\n",
      "Epoch 14/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.1551 - tf_op_layer_split_2_loss: 4.8986 - tf_op_layer_split_2_1_loss: 1.6783 - Concatenate_obj_loss: 0.0372 - Concatenate_obj_1_loss: 12.6051 - Concatenate_obj_precision: 0.6390 - Concatenate_obj_recall: 0.1247 - Concatenate_obj_true_positives: 33702.0000 - Concatenate_obj_false_positives: 19039.0000\n",
      "Epoch 00014: val_Concatenate_obj_recall did not improve from 0.14657\n",
      "9213/9213 [==============================] - 661s 72ms/step - loss: 24.1549 - tf_op_layer_split_2_loss: 4.8986 - tf_op_layer_split_2_1_loss: 1.6782 - Concatenate_obj_loss: 0.0372 - Concatenate_obj_1_loss: 12.6051 - Concatenate_obj_precision: 0.6390 - Concatenate_obj_recall: 0.1247 - Concatenate_obj_true_positives: 33702.0000 - Concatenate_obj_false_positives: 19039.0000 - val_loss: 22.0216 - val_tf_op_layer_split_2_loss: 4.6028 - val_tf_op_layer_split_2_1_loss: 0.6634 - val_Concatenate_obj_loss: 0.0371 - val_Concatenate_obj_1_loss: 12.0784 - val_Concatenate_obj_precision: 0.7216 - val_Concatenate_obj_recall: 0.1464 - val_Concatenate_obj_true_positives: 1731.0000 - val_Concatenate_obj_false_positives: 668.0000\n",
      "Epoch 15/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.0895 - tf_op_layer_split_2_loss: 4.8604 - tf_op_layer_split_2_1_loss: 1.7024 - Concatenate_obj_loss: 0.0372 - Concatenate_obj_1_loss: 12.5919 - Concatenate_obj_precision: 0.6402 - Concatenate_obj_recall: 0.1260 - Concatenate_obj_true_positives: 34035.0000 - Concatenate_obj_false_positives: 19126.0000\n",
      "Epoch 00015: val_Concatenate_obj_recall improved from 0.14657 to 0.14682, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 669s 73ms/step - loss: 24.0892 - tf_op_layer_split_2_loss: 4.8603 - tf_op_layer_split_2_1_loss: 1.7024 - Concatenate_obj_loss: 0.0372 - Concatenate_obj_1_loss: 12.5917 - Concatenate_obj_precision: 0.6402 - Concatenate_obj_recall: 0.1259 - Concatenate_obj_true_positives: 34035.0000 - Concatenate_obj_false_positives: 19126.0000 - val_loss: 21.9679 - val_tf_op_layer_split_2_loss: 4.5919 - val_tf_op_layer_split_2_1_loss: 0.6461 - val_Concatenate_obj_loss: 0.0370 - val_Concatenate_obj_1_loss: 12.0640 - val_Concatenate_obj_precision: 0.7203 - val_Concatenate_obj_recall: 0.1468 - val_Concatenate_obj_true_positives: 1736.0000 - val_Concatenate_obj_false_positives: 674.0000\n",
      "Epoch 16/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.0501 - tf_op_layer_split_2_loss: 4.8880 - tf_op_layer_split_2_1_loss: 1.6189 - Concatenate_obj_loss: 0.0372 - Concatenate_obj_1_loss: 12.5807 - Concatenate_obj_precision: 0.6428 - Concatenate_obj_recall: 0.1272 - Concatenate_obj_true_positives: 34379.0000 - Concatenate_obj_false_positives: 19108.0000\n",
      "Epoch 00016: val_Concatenate_obj_recall did not improve from 0.14682\n",
      "9213/9213 [==============================] - 678s 74ms/step - loss: 24.0498 - tf_op_layer_split_2_loss: 4.8880 - tf_op_layer_split_2_1_loss: 1.6189 - Concatenate_obj_loss: 0.0372 - Concatenate_obj_1_loss: 12.5806 - Concatenate_obj_precision: 0.6428 - Concatenate_obj_recall: 0.1272 - Concatenate_obj_true_positives: 34379.0000 - Concatenate_obj_false_positives: 19108.0000 - val_loss: 21.9533 - val_tf_op_layer_split_2_loss: 4.5878 - val_tf_op_layer_split_2_1_loss: 0.6355 - val_Concatenate_obj_loss: 0.0371 - val_Concatenate_obj_1_loss: 12.0681 - val_Concatenate_obj_precision: 0.7224 - val_Concatenate_obj_recall: 0.1455 - val_Concatenate_obj_true_positives: 1720.0000 - val_Concatenate_obj_false_positives: 661.0000\n",
      "Epoch 17/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 24.0392 - tf_op_layer_split_2_loss: 4.8853 - tf_op_layer_split_2_1_loss: 1.6198 - Concatenate_obj_loss: 0.0372 - Concatenate_obj_1_loss: 12.5746 - Concatenate_obj_precision: 0.6429 - Concatenate_obj_recall: 0.1277 - Concatenate_obj_true_positives: 34511.0000 - Concatenate_obj_false_positives: 19173.0000\n",
      "Epoch 00017: val_Concatenate_obj_recall improved from 0.14682 to 0.14758, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 665s 72ms/step - loss: 24.0390 - tf_op_layer_split_2_loss: 4.8852 - tf_op_layer_split_2_1_loss: 1.6198 - Concatenate_obj_loss: 0.0372 - Concatenate_obj_1_loss: 12.5745 - Concatenate_obj_precision: 0.6429 - Concatenate_obj_recall: 0.1277 - Concatenate_obj_true_positives: 34511.0000 - Concatenate_obj_false_positives: 19173.0000 - val_loss: 21.9151 - val_tf_op_layer_split_2_loss: 4.5731 - val_tf_op_layer_split_2_1_loss: 0.6495 - val_Concatenate_obj_loss: 0.0370 - val_Concatenate_obj_1_loss: 12.0453 - val_Concatenate_obj_precision: 0.7178 - val_Concatenate_obj_recall: 0.1476 - val_Concatenate_obj_true_positives: 1745.0000 - val_Concatenate_obj_false_positives: 686.0000\n",
      "Epoch 18/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.8691 - tf_op_layer_split_2_loss: 4.8268 - tf_op_layer_split_2_1_loss: 1.5824 - Concatenate_obj_loss: 0.0371 - Concatenate_obj_1_loss: 12.5589 - Concatenate_obj_precision: 0.6420 - Concatenate_obj_recall: 0.1273 - Concatenate_obj_true_positives: 34398.0000 - Concatenate_obj_false_positives: 19184.0000\n",
      "Epoch 00018: val_Concatenate_obj_recall improved from 0.14758 to 0.14868, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 665s 72ms/step - loss: 23.8689 - tf_op_layer_split_2_loss: 4.8267 - tf_op_layer_split_2_1_loss: 1.5823 - Concatenate_obj_loss: 0.0371 - Concatenate_obj_1_loss: 12.5588 - Concatenate_obj_precision: 0.6420 - Concatenate_obj_recall: 0.1273 - Concatenate_obj_true_positives: 34398.0000 - Concatenate_obj_false_positives: 19184.0000 - val_loss: 21.8687 - val_tf_op_layer_split_2_loss: 4.5600 - val_tf_op_layer_split_2_1_loss: 0.6500 - val_Concatenate_obj_loss: 0.0369 - val_Concatenate_obj_1_loss: 12.0249 - val_Concatenate_obj_precision: 0.7173 - val_Concatenate_obj_recall: 0.1487 - val_Concatenate_obj_true_positives: 1758.0000 - val_Concatenate_obj_false_positives: 693.0000\n",
      "Epoch 19/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.9402 - tf_op_layer_split_2_loss: 4.8520 - tf_op_layer_split_2_1_loss: 1.6396 - Concatenate_obj_loss: 0.0370 - Concatenate_obj_1_loss: 12.5225 - Concatenate_obj_precision: 0.6422 - Concatenate_obj_recall: 0.1280 - Concatenate_obj_true_positives: 34601.0000 - Concatenate_obj_false_positives: 19276.0000\n",
      "Epoch 00019: val_Concatenate_obj_recall did not improve from 0.14868\n",
      "9213/9213 [==============================] - 669s 73ms/step - loss: 23.9399 - tf_op_layer_split_2_loss: 4.8519 - tf_op_layer_split_2_1_loss: 1.6396 - Concatenate_obj_loss: 0.0370 - Concatenate_obj_1_loss: 12.5224 - Concatenate_obj_precision: 0.6422 - Concatenate_obj_recall: 0.1280 - Concatenate_obj_true_positives: 34602.0000 - Concatenate_obj_false_positives: 19276.0000 - val_loss: 21.8279 - val_tf_op_layer_split_2_loss: 4.5490 - val_tf_op_layer_split_2_1_loss: 0.6398 - val_Concatenate_obj_loss: 0.0369 - val_Concatenate_obj_1_loss: 12.0162 - val_Concatenate_obj_precision: 0.7190 - val_Concatenate_obj_recall: 0.1483 - val_Concatenate_obj_true_positives: 1753.0000 - val_Concatenate_obj_false_positives: 685.0000\n",
      "Epoch 20/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.7998 - tf_op_layer_split_2_loss: 4.8136 - tf_op_layer_split_2_1_loss: 1.5934 - Concatenate_obj_loss: 0.0369 - Concatenate_obj_1_loss: 12.5053 - Concatenate_obj_precision: 0.6412 - Concatenate_obj_recall: 0.1290 - Concatenate_obj_true_positives: 34858.0000 - Concatenate_obj_false_positives: 19504.0000\n",
      "Epoch 00020: val_Concatenate_obj_recall did not improve from 0.14868\n",
      "9213/9213 [==============================] - 666s 72ms/step - loss: 23.7996 - tf_op_layer_split_2_loss: 4.8136 - tf_op_layer_split_2_1_loss: 1.5934 - Concatenate_obj_loss: 0.0369 - Concatenate_obj_1_loss: 12.5052 - Concatenate_obj_precision: 0.6412 - Concatenate_obj_recall: 0.1290 - Concatenate_obj_true_positives: 34858.0000 - Concatenate_obj_false_positives: 19505.0000 - val_loss: 21.7902 - val_tf_op_layer_split_2_loss: 4.5356 - val_tf_op_layer_split_2_1_loss: 0.6413 - val_Concatenate_obj_loss: 0.0369 - val_Concatenate_obj_1_loss: 12.0039 - val_Concatenate_obj_precision: 0.7172 - val_Concatenate_obj_recall: 0.1473 - val_Concatenate_obj_true_positives: 1742.0000 - val_Concatenate_obj_false_positives: 687.0000\n",
      "Epoch 21/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.8411 - tf_op_layer_split_2_loss: 4.8397 - tf_op_layer_split_2_1_loss: 1.5676 - Concatenate_obj_loss: 0.0370 - Concatenate_obj_1_loss: 12.5200 - Concatenate_obj_precision: 0.6453 - Concatenate_obj_recall: 0.1296 - Concatenate_obj_true_positives: 35016.0000 - Concatenate_obj_false_positives: 19247.0000\n",
      "Epoch 00021: val_Concatenate_obj_recall did not improve from 0.14868\n",
      "9213/9213 [==============================] - 662s 72ms/step - loss: 23.8407 - tf_op_layer_split_2_loss: 4.8396 - tf_op_layer_split_2_1_loss: 1.5676 - Concatenate_obj_loss: 0.0370 - Concatenate_obj_1_loss: 12.5199 - Concatenate_obj_precision: 0.6453 - Concatenate_obj_recall: 0.1296 - Concatenate_obj_true_positives: 35016.0000 - Concatenate_obj_false_positives: 19247.0000 - val_loss: 21.7533 - val_tf_op_layer_split_2_loss: 4.5290 - val_tf_op_layer_split_2_1_loss: 0.6224 - val_Concatenate_obj_loss: 0.0369 - val_Concatenate_obj_1_loss: 11.9990 - val_Concatenate_obj_precision: 0.7178 - val_Concatenate_obj_recall: 0.1469 - val_Concatenate_obj_true_positives: 1737.0000 - val_Concatenate_obj_false_positives: 683.0000\n",
      "Epoch 22/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.8171 - tf_op_layer_split_2_loss: 4.8189 - tf_op_layer_split_2_1_loss: 1.6017 - Concatenate_obj_loss: 0.0370 - Concatenate_obj_1_loss: 12.5037 - Concatenate_obj_precision: 0.6431 - Concatenate_obj_recall: 0.1297 - Concatenate_obj_true_positives: 35058.0000 - Concatenate_obj_false_positives: 19453.0000\n",
      "Epoch 00022: val_Concatenate_obj_recall improved from 0.14868 to 0.14877, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 667s 72ms/step - loss: 23.8168 - tf_op_layer_split_2_loss: 4.8188 - tf_op_layer_split_2_1_loss: 1.6017 - Concatenate_obj_loss: 0.0370 - Concatenate_obj_1_loss: 12.5036 - Concatenate_obj_precision: 0.6431 - Concatenate_obj_recall: 0.1297 - Concatenate_obj_true_positives: 35059.0000 - Concatenate_obj_false_positives: 19453.0000 - val_loss: 21.7198 - val_tf_op_layer_split_2_loss: 4.5169 - val_tf_op_layer_split_2_1_loss: 0.6339 - val_Concatenate_obj_loss: 0.0368 - val_Concatenate_obj_1_loss: 11.9785 - val_Concatenate_obj_precision: 0.7159 - val_Concatenate_obj_recall: 0.1488 - val_Concatenate_obj_true_positives: 1759.0000 - val_Concatenate_obj_false_positives: 698.0000\n",
      "Epoch 23/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.7689 - tf_op_layer_split_2_loss: 4.8318 - tf_op_layer_split_2_1_loss: 1.5620 - Concatenate_obj_loss: 0.0369 - Concatenate_obj_1_loss: 12.4695 - Concatenate_obj_precision: 0.6420 - Concatenate_obj_recall: 0.1301 - Concatenate_obj_true_positives: 35149.0000 - Concatenate_obj_false_positives: 19600.0000\n",
      "Epoch 00023: val_Concatenate_obj_recall did not improve from 0.14877\n",
      "9213/9213 [==============================] - 662s 72ms/step - loss: 23.7686 - tf_op_layer_split_2_loss: 4.8317 - tf_op_layer_split_2_1_loss: 1.5620 - Concatenate_obj_loss: 0.0369 - Concatenate_obj_1_loss: 12.4694 - Concatenate_obj_precision: 0.6420 - Concatenate_obj_recall: 0.1300 - Concatenate_obj_true_positives: 35149.0000 - Concatenate_obj_false_positives: 19600.0000 - val_loss: 21.6893 - val_tf_op_layer_split_2_loss: 4.5051 - val_tf_op_layer_split_2_1_loss: 0.6373 - val_Concatenate_obj_loss: 0.0368 - val_Concatenate_obj_1_loss: 11.9680 - val_Concatenate_obj_precision: 0.7181 - val_Concatenate_obj_recall: 0.1483 - val_Concatenate_obj_true_positives: 1753.0000 - val_Concatenate_obj_false_positives: 688.0000\n",
      "Epoch 24/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.6547 - tf_op_layer_split_2_loss: 4.7802 - tf_op_layer_split_2_1_loss: 1.5790 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4418 - Concatenate_obj_precision: 0.6452 - Concatenate_obj_recall: 0.1323 - Concatenate_obj_true_positives: 35742.0000 - Concatenate_obj_false_positives: 19653.0000\n",
      "Epoch 00024: val_Concatenate_obj_recall improved from 0.14877 to 0.14910, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 663s 72ms/step - loss: 23.6545 - tf_op_layer_split_2_loss: 4.7801 - tf_op_layer_split_2_1_loss: 1.5790 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4417 - Concatenate_obj_precision: 0.6452 - Concatenate_obj_recall: 0.1323 - Concatenate_obj_true_positives: 35742.0000 - Concatenate_obj_false_positives: 19653.0000 - val_loss: 21.6363 - val_tf_op_layer_split_2_loss: 4.4897 - val_tf_op_layer_split_2_1_loss: 0.6211 - val_Concatenate_obj_loss: 0.0368 - val_Concatenate_obj_1_loss: 11.9623 - val_Concatenate_obj_precision: 0.7143 - val_Concatenate_obj_recall: 0.1491 - val_Concatenate_obj_true_positives: 1763.0000 - val_Concatenate_obj_false_positives: 705.0000\n",
      "Epoch 25/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.6513 - tf_op_layer_split_2_loss: 4.7878 - tf_op_layer_split_2_1_loss: 1.5576 - Concatenate_obj_loss: 0.0368 - Concatenate_obj_1_loss: 12.4446 - Concatenate_obj_precision: 0.6423 - Concatenate_obj_recall: 0.1316 - Concatenate_obj_true_positives: 35560.0000 - Concatenate_obj_false_positives: 19802.0000- ETA: 5s - loss: 23.7427 - tf_op_layer_split_2_loss: 4.8079 - tf_op_layer_split_2_1_loss: 1.5682 - Concatenate_obj_loss: 0.0370 - Concatenate_obj_1_loss: 12.4846 - Concatenate_obj_precision: 0.6431 - Concatenate_obj_recall: 0.1316 - Concatenate_obj_tru\n",
      "Epoch 00025: val_Concatenate_obj_recall improved from 0.14910 to 0.15054, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 662s 72ms/step - loss: 23.6510 - tf_op_layer_split_2_loss: 4.7877 - tf_op_layer_split_2_1_loss: 1.5576 - Concatenate_obj_loss: 0.0368 - Concatenate_obj_1_loss: 12.4446 - Concatenate_obj_precision: 0.6423 - Concatenate_obj_recall: 0.1316 - Concatenate_obj_true_positives: 35560.0000 - Concatenate_obj_false_positives: 19802.0000 - val_loss: 21.6005 - val_tf_op_layer_split_2_loss: 4.4770 - val_tf_op_layer_split_2_1_loss: 0.6291 - val_Concatenate_obj_loss: 0.0368 - val_Concatenate_obj_1_loss: 11.9439 - val_Concatenate_obj_precision: 0.7177 - val_Concatenate_obj_recall: 0.1505 - val_Concatenate_obj_true_positives: 1780.0000 - val_Concatenate_obj_false_positives: 700.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.7289 - tf_op_layer_split_2_loss: 4.7914 - tf_op_layer_split_2_1_loss: 1.6428 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4298 - Concatenate_obj_precision: 0.6462 - Concatenate_obj_recall: 0.1321 - Concatenate_obj_true_positives: 35682.0000 - Concatenate_obj_false_positives: 19539.0000\n",
      "Epoch 00026: val_Concatenate_obj_recall improved from 0.15054 to 0.15122, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 667s 72ms/step - loss: 23.7286 - tf_op_layer_split_2_loss: 4.7913 - tf_op_layer_split_2_1_loss: 1.6428 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4297 - Concatenate_obj_precision: 0.6462 - Concatenate_obj_recall: 0.1321 - Concatenate_obj_true_positives: 35682.0000 - Concatenate_obj_false_positives: 19539.0000 - val_loss: 21.5787 - val_tf_op_layer_split_2_loss: 4.4671 - val_tf_op_layer_split_2_1_loss: 0.6399 - val_Concatenate_obj_loss: 0.0367 - val_Concatenate_obj_1_loss: 11.9312 - val_Concatenate_obj_precision: 0.7152 - val_Concatenate_obj_recall: 0.1512 - val_Concatenate_obj_true_positives: 1788.0000 - val_Concatenate_obj_false_positives: 712.0000\n",
      "Epoch 27/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.5552 - tf_op_layer_split_2_loss: 4.7697 - tf_op_layer_split_2_1_loss: 1.5041 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4384 - Concatenate_obj_precision: 0.6434 - Concatenate_obj_recall: 0.1320 - Concatenate_obj_true_positives: 35665.0000 - Concatenate_obj_false_positives: 19768.0000\n",
      "Epoch 00027: val_Concatenate_obj_recall improved from 0.15122 to 0.15147, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 667s 72ms/step - loss: 23.5550 - tf_op_layer_split_2_loss: 4.7696 - tf_op_layer_split_2_1_loss: 1.5040 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4383 - Concatenate_obj_precision: 0.6434 - Concatenate_obj_recall: 0.1320 - Concatenate_obj_true_positives: 35665.0000 - Concatenate_obj_false_positives: 19768.0000 - val_loss: 21.5427 - val_tf_op_layer_split_2_loss: 4.4622 - val_tf_op_layer_split_2_1_loss: 0.6253 - val_Concatenate_obj_loss: 0.0367 - val_Concatenate_obj_1_loss: 11.9197 - val_Concatenate_obj_precision: 0.7201 - val_Concatenate_obj_recall: 0.1515 - val_Concatenate_obj_true_positives: 1791.0000 - val_Concatenate_obj_false_positives: 696.0000\n",
      "Epoch 28/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.5178 - tf_op_layer_split_2_loss: 4.7374 - tf_op_layer_split_2_1_loss: 1.5447 - Concatenate_obj_loss: 0.0368 - Concatenate_obj_1_loss: 12.4249 - Concatenate_obj_precision: 0.6458 - Concatenate_obj_recall: 0.1323 - Concatenate_obj_true_positives: 35768.0000 - Concatenate_obj_false_positives: 19614.0000\n",
      "Epoch 00028: val_Concatenate_obj_recall improved from 0.15147 to 0.15164, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 667s 72ms/step - loss: 23.5175 - tf_op_layer_split_2_loss: 4.7373 - tf_op_layer_split_2_1_loss: 1.5447 - Concatenate_obj_loss: 0.0368 - Concatenate_obj_1_loss: 12.4248 - Concatenate_obj_precision: 0.6458 - Concatenate_obj_recall: 0.1323 - Concatenate_obj_true_positives: 35768.0000 - Concatenate_obj_false_positives: 19615.0000 - val_loss: 21.4880 - val_tf_op_layer_split_2_loss: 4.4469 - val_tf_op_layer_split_2_1_loss: 0.6174 - val_Concatenate_obj_loss: 0.0366 - val_Concatenate_obj_1_loss: 11.9036 - val_Concatenate_obj_precision: 0.7186 - val_Concatenate_obj_recall: 0.1516 - val_Concatenate_obj_true_positives: 1793.0000 - val_Concatenate_obj_false_positives: 702.0000\n",
      "Epoch 29/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.5997 - tf_op_layer_split_2_loss: 4.7628 - tf_op_layer_split_2_1_loss: 1.5991 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4017 - Concatenate_obj_precision: 0.6465 - Concatenate_obj_recall: 0.1343 - Concatenate_obj_true_positives: 36298.0000 - Concatenate_obj_false_positives: 19844.0000\n",
      "Epoch 00029: val_Concatenate_obj_recall improved from 0.15164 to 0.15291, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 668s 72ms/step - loss: 23.5994 - tf_op_layer_split_2_loss: 4.7627 - tf_op_layer_split_2_1_loss: 1.5991 - Concatenate_obj_loss: 0.0367 - Concatenate_obj_1_loss: 12.4016 - Concatenate_obj_precision: 0.6465 - Concatenate_obj_recall: 0.1343 - Concatenate_obj_true_positives: 36298.0000 - Concatenate_obj_false_positives: 19844.0000 - val_loss: 21.4727 - val_tf_op_layer_split_2_loss: 4.4380 - val_tf_op_layer_split_2_1_loss: 0.6265 - val_Concatenate_obj_loss: 0.0366 - val_Concatenate_obj_1_loss: 11.8970 - val_Concatenate_obj_precision: 0.7177 - val_Concatenate_obj_recall: 0.1529 - val_Concatenate_obj_true_positives: 1808.0000 - val_Concatenate_obj_false_positives: 711.0000\n",
      "Epoch 30/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.5353 - tf_op_layer_split_2_loss: 4.7567 - tf_op_layer_split_2_1_loss: 1.5746 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3743 - Concatenate_obj_precision: 0.6446 - Concatenate_obj_recall: 0.1341 - Concatenate_obj_true_positives: 36228.0000 - Concatenate_obj_false_positives: 19971.0000\n",
      "Epoch 00030: val_Concatenate_obj_recall improved from 0.15291 to 0.15299, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 672s 73ms/step - loss: 23.5349 - tf_op_layer_split_2_loss: 4.7566 - tf_op_layer_split_2_1_loss: 1.5745 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3742 - Concatenate_obj_precision: 0.6446 - Concatenate_obj_recall: 0.1341 - Concatenate_obj_true_positives: 36229.0000 - Concatenate_obj_false_positives: 19972.0000 - val_loss: 21.4241 - val_tf_op_layer_split_2_loss: 4.4290 - val_tf_op_layer_split_2_1_loss: 0.6117 - val_Concatenate_obj_loss: 0.0366 - val_Concatenate_obj_1_loss: 11.8813 - val_Concatenate_obj_precision: 0.7193 - val_Concatenate_obj_recall: 0.1530 - val_Concatenate_obj_true_positives: 1809.0000 - val_Concatenate_obj_false_positives: 706.0000\n",
      "Epoch 31/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.4692 - tf_op_layer_split_2_loss: 4.7369 - tf_op_layer_split_2_1_loss: 1.5625 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3598 - Concatenate_obj_precision: 0.6454 - Concatenate_obj_recall: 0.1343 - Concatenate_obj_true_positives: 36293.0000 - Concatenate_obj_false_positives: 19944.0000\n",
      "Epoch 00031: val_Concatenate_obj_recall did not improve from 0.15299\n",
      "9213/9213 [==============================] - 658s 71ms/step - loss: 23.4691 - tf_op_layer_split_2_loss: 4.7368 - tf_op_layer_split_2_1_loss: 1.5625 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3598 - Concatenate_obj_precision: 0.6454 - Concatenate_obj_recall: 0.1343 - Concatenate_obj_true_positives: 36293.0000 - Concatenate_obj_false_positives: 19944.0000 - val_loss: 21.4018 - val_tf_op_layer_split_2_loss: 4.4165 - val_tf_op_layer_split_2_1_loss: 0.6139 - val_Concatenate_obj_loss: 0.0366 - val_Concatenate_obj_1_loss: 11.8817 - val_Concatenate_obj_precision: 0.7224 - val_Concatenate_obj_recall: 0.1530 - val_Concatenate_obj_true_positives: 1809.0000 - val_Concatenate_obj_false_positives: 695.0000\n",
      "Epoch 32/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.4839 - tf_op_layer_split_2_loss: 4.7084 - tf_op_layer_split_2_1_loss: 1.6184 - Concatenate_obj_loss: 0.0366 - Concatenate_obj_1_loss: 12.3755 - Concatenate_obj_precision: 0.6482 - Concatenate_obj_recall: 0.1350 - Concatenate_obj_true_positives: 36479.0000 - Concatenate_obj_false_positives: 19801.0000\n",
      "Epoch 00032: val_Concatenate_obj_recall improved from 0.15299 to 0.15384, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 661s 72ms/step - loss: 23.4839 - tf_op_layer_split_2_loss: 4.7085 - tf_op_layer_split_2_1_loss: 1.6183 - Concatenate_obj_loss: 0.0366 - Concatenate_obj_1_loss: 12.3755 - Concatenate_obj_precision: 0.6482 - Concatenate_obj_recall: 0.1350 - Concatenate_obj_true_positives: 36479.0000 - Concatenate_obj_false_positives: 19801.0000 - val_loss: 21.3666 - val_tf_op_layer_split_2_loss: 4.4038 - val_tf_op_layer_split_2_1_loss: 0.6249 - val_Concatenate_obj_loss: 0.0365 - val_Concatenate_obj_1_loss: 11.8611 - val_Concatenate_obj_precision: 0.7187 - val_Concatenate_obj_recall: 0.1538 - val_Concatenate_obj_true_positives: 1819.0000 - val_Concatenate_obj_false_positives: 712.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.4599 - tf_op_layer_split_2_loss: 4.7282 - tf_op_layer_split_2_1_loss: 1.5687 - Concatenate_obj_loss: 0.0366 - Concatenate_obj_1_loss: 12.3616 - Concatenate_obj_precision: 0.6446 - Concatenate_obj_recall: 0.1357 - Concatenate_obj_true_positives: 36678.0000 - Concatenate_obj_false_positives: 20225.0000\n",
      "Epoch 00033: val_Concatenate_obj_recall did not improve from 0.15384\n",
      "9213/9213 [==============================] - 668s 73ms/step - loss: 23.4597 - tf_op_layer_split_2_loss: 4.7281 - tf_op_layer_split_2_1_loss: 1.5686 - Concatenate_obj_loss: 0.0366 - Concatenate_obj_1_loss: 12.3616 - Concatenate_obj_precision: 0.6446 - Concatenate_obj_recall: 0.1357 - Concatenate_obj_true_positives: 36679.0000 - Concatenate_obj_false_positives: 20225.0000 - val_loss: 21.3432 - val_tf_op_layer_split_2_loss: 4.3948 - val_tf_op_layer_split_2_1_loss: 0.6203 - val_Concatenate_obj_loss: 0.0365 - val_Concatenate_obj_1_loss: 11.8602 - val_Concatenate_obj_precision: 0.7211 - val_Concatenate_obj_recall: 0.1532 - val_Concatenate_obj_true_positives: 1812.0000 - val_Concatenate_obj_false_positives: 701.0000\n",
      "Epoch 34/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.4079 - tf_op_layer_split_2_loss: 4.7265 - tf_op_layer_split_2_1_loss: 1.5413 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3405 - Concatenate_obj_precision: 0.6454 - Concatenate_obj_recall: 0.1351 - Concatenate_obj_true_positives: 36505.0000 - Concatenate_obj_false_positives: 20053.0000\n",
      "Epoch 00034: val_Concatenate_obj_recall did not improve from 0.15384\n",
      "9213/9213 [==============================] - 675s 73ms/step - loss: 23.4078 - tf_op_layer_split_2_loss: 4.7265 - tf_op_layer_split_2_1_loss: 1.5413 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3405 - Concatenate_obj_precision: 0.6454 - Concatenate_obj_recall: 0.1351 - Concatenate_obj_true_positives: 36505.0000 - Concatenate_obj_false_positives: 20053.0000 - val_loss: 21.3059 - val_tf_op_layer_split_2_loss: 4.3810 - val_tf_op_layer_split_2_1_loss: 0.6283 - val_Concatenate_obj_loss: 0.0365 - val_Concatenate_obj_1_loss: 11.8426 - val_Concatenate_obj_precision: 0.7218 - val_Concatenate_obj_recall: 0.1534 - val_Concatenate_obj_true_positives: 1814.0000 - val_Concatenate_obj_false_positives: 699.0000\n",
      "Epoch 35/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.4965 - tf_op_layer_split_2_loss: 4.7157 - tf_op_layer_split_2_1_loss: 1.6551 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3371 - Concatenate_obj_precision: 0.6468 - Concatenate_obj_recall: 0.1365 - Concatenate_obj_true_positives: 36873.0000 - Concatenate_obj_false_positives: 20138.0000\n",
      "Epoch 00035: val_Concatenate_obj_recall improved from 0.15384 to 0.15553, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 673s 73ms/step - loss: 23.4962 - tf_op_layer_split_2_loss: 4.7156 - tf_op_layer_split_2_1_loss: 1.6551 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3370 - Concatenate_obj_precision: 0.6468 - Concatenate_obj_recall: 0.1365 - Concatenate_obj_true_positives: 36873.0000 - Concatenate_obj_false_positives: 20138.0000 - val_loss: 21.2720 - val_tf_op_layer_split_2_loss: 4.3744 - val_tf_op_layer_split_2_1_loss: 0.6200 - val_Concatenate_obj_loss: 0.0364 - val_Concatenate_obj_1_loss: 11.8304 - val_Concatenate_obj_precision: 0.7192 - val_Concatenate_obj_recall: 0.1555 - val_Concatenate_obj_true_positives: 1839.0000 - val_Concatenate_obj_false_positives: 718.0000\n",
      "Epoch 36/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.3541 - tf_op_layer_split_2_loss: 4.7005 - tf_op_layer_split_2_1_loss: 1.5677 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3125 - Concatenate_obj_precision: 0.6468 - Concatenate_obj_recall: 0.1369 - Concatenate_obj_true_positives: 36999.0000 - Concatenate_obj_false_positives: 20203.0000\n",
      "Epoch 00036: val_Concatenate_obj_recall improved from 0.15553 to 0.15587, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 665s 72ms/step - loss: 23.3538 - tf_op_layer_split_2_loss: 4.7004 - tf_op_layer_split_2_1_loss: 1.5676 - Concatenate_obj_loss: 0.0365 - Concatenate_obj_1_loss: 12.3125 - Concatenate_obj_precision: 0.6468 - Concatenate_obj_recall: 0.1369 - Concatenate_obj_true_positives: 36999.0000 - Concatenate_obj_false_positives: 20203.0000 - val_loss: 21.2459 - val_tf_op_layer_split_2_loss: 4.3669 - val_tf_op_layer_split_2_1_loss: 0.6172 - val_Concatenate_obj_loss: 0.0364 - val_Concatenate_obj_1_loss: 11.8221 - val_Concatenate_obj_precision: 0.7210 - val_Concatenate_obj_recall: 0.1559 - val_Concatenate_obj_true_positives: 1843.0000 - val_Concatenate_obj_false_positives: 713.0000\n",
      "Epoch 37/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.2818 - tf_op_layer_split_2_loss: 4.6928 - tf_op_layer_split_2_1_loss: 1.5270 - Concatenate_obj_loss: 0.0364 - Concatenate_obj_1_loss: 12.2964 - Concatenate_obj_precision: 0.6469 - Concatenate_obj_recall: 0.1376 - Concatenate_obj_true_positives: 37192.0000 - Concatenate_obj_false_positives: 20298.0000\n",
      "Epoch 00037: val_Concatenate_obj_recall improved from 0.15587 to 0.15663, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 664s 72ms/step - loss: 23.2817 - tf_op_layer_split_2_loss: 4.6928 - tf_op_layer_split_2_1_loss: 1.5269 - Concatenate_obj_loss: 0.0364 - Concatenate_obj_1_loss: 12.2963 - Concatenate_obj_precision: 0.6469 - Concatenate_obj_recall: 0.1376 - Concatenate_obj_true_positives: 37192.0000 - Concatenate_obj_false_positives: 20298.0000 - val_loss: 21.2104 - val_tf_op_layer_split_2_loss: 4.3561 - val_tf_op_layer_split_2_1_loss: 0.6195 - val_Concatenate_obj_loss: 0.0364 - val_Concatenate_obj_1_loss: 11.8060 - val_Concatenate_obj_precision: 0.7192 - val_Concatenate_obj_recall: 0.1566 - val_Concatenate_obj_true_positives: 1852.0000 - val_Concatenate_obj_false_positives: 723.0000\n",
      "Epoch 38/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.2439 - tf_op_layer_split_2_loss: 4.6590 - tf_op_layer_split_2_1_loss: 1.5772 - Concatenate_obj_loss: 0.0363 - Concatenate_obj_1_loss: 12.2762 - Concatenate_obj_precision: 0.6494 - Concatenate_obj_recall: 0.1386 - Concatenate_obj_true_positives: 37456.0000 - Concatenate_obj_false_positives: 20221.0000\n",
      "Epoch 00038: val_Concatenate_obj_recall did not improve from 0.15663\n",
      "9213/9213 [==============================] - 669s 73ms/step - loss: 23.2438 - tf_op_layer_split_2_loss: 4.6589 - tf_op_layer_split_2_1_loss: 1.5772 - Concatenate_obj_loss: 0.0363 - Concatenate_obj_1_loss: 12.2762 - Concatenate_obj_precision: 0.6494 - Concatenate_obj_recall: 0.1386 - Concatenate_obj_true_positives: 37456.0000 - Concatenate_obj_false_positives: 20221.0000 - val_loss: 21.1557 - val_tf_op_layer_split_2_loss: 4.3464 - val_tf_op_layer_split_2_1_loss: 0.5872 - val_Concatenate_obj_loss: 0.0364 - val_Concatenate_obj_1_loss: 11.8029 - val_Concatenate_obj_precision: 0.7243 - val_Concatenate_obj_recall: 0.1551 - val_Concatenate_obj_true_positives: 1834.0000 - val_Concatenate_obj_false_positives: 698.0000\n",
      "Epoch 39/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.3029 - tf_op_layer_split_2_loss: 4.6806 - tf_op_layer_split_2_1_loss: 1.5938 - Concatenate_obj_loss: 0.0363 - Concatenate_obj_1_loss: 12.2752 - Concatenate_obj_precision: 0.6508 - Concatenate_obj_recall: 0.1389 - Concatenate_obj_true_positives: 37546.0000 - Concatenate_obj_false_positives: 20144.0000\n",
      "Epoch 00039: val_Concatenate_obj_recall did not improve from 0.15663\n",
      "9213/9213 [==============================] - 666s 72ms/step - loss: 23.3026 - tf_op_layer_split_2_loss: 4.6805 - tf_op_layer_split_2_1_loss: 1.5938 - Concatenate_obj_loss: 0.0363 - Concatenate_obj_1_loss: 12.2751 - Concatenate_obj_precision: 0.6508 - Concatenate_obj_recall: 0.1389 - Concatenate_obj_true_positives: 37546.0000 - Concatenate_obj_false_positives: 20145.0000 - val_loss: 21.1198 - val_tf_op_layer_split_2_loss: 4.3328 - val_tf_op_layer_split_2_1_loss: 0.5921 - val_Concatenate_obj_loss: 0.0363 - val_Concatenate_obj_1_loss: 11.7895 - val_Concatenate_obj_precision: 0.7217 - val_Concatenate_obj_recall: 0.1555 - val_Concatenate_obj_true_positives: 1839.0000 - val_Concatenate_obj_false_positives: 709.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.1874 - tf_op_layer_split_2_loss: 4.6814 - tf_op_layer_split_2_1_loss: 1.4923 - Concatenate_obj_loss: 0.0363 - Concatenate_obj_1_loss: 12.2597 - Concatenate_obj_precision: 0.6489 - Concatenate_obj_recall: 0.1393 - Concatenate_obj_true_positives: 37629.0000 - Concatenate_obj_false_positives: 20364.0000- ETA: 2s - loss: 23.2352 - tf_op_layer_split_2_loss: 4.6915 - tf_op_layer_split_2_1_loss: 1.4976 - Concatenate_obj_loss: 0.0364 - Concatenate_obj_1_loss: 12.2816 - Concatenate_obj_precision: 0.6494 - Concatenate_obj_recall: 0.1393 - Concatenate_obj_true_positives: 37560.0000 - Concaten\n",
      "Epoch 00040: val_Concatenate_obj_recall did not improve from 0.15663\n",
      "9213/9213 [==============================] - 682s 74ms/step - loss: 23.1872 - tf_op_layer_split_2_loss: 4.6814 - tf_op_layer_split_2_1_loss: 1.4922 - Concatenate_obj_loss: 0.0363 - Concatenate_obj_1_loss: 12.2596 - Concatenate_obj_precision: 0.6489 - Concatenate_obj_recall: 0.1393 - Concatenate_obj_true_positives: 37629.0000 - Concatenate_obj_false_positives: 20364.0000 - val_loss: 21.0960 - val_tf_op_layer_split_2_loss: 4.3247 - val_tf_op_layer_split_2_1_loss: 0.6013 - val_Concatenate_obj_loss: 0.0363 - val_Concatenate_obj_1_loss: 11.7726 - val_Concatenate_obj_precision: 0.7170 - val_Concatenate_obj_recall: 0.1566 - val_Concatenate_obj_true_positives: 1852.0000 - val_Concatenate_obj_false_positives: 731.0000\n"
     ]
    }
   ],
   "source": [
    "os.chdir(root_path+ \"/pedestrian_dataset_train_tfr\")\n",
    "history = model.fit(train_dataset, epochs=40,validation_data=val_dataset,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(current_directory+'/weights_retrain_functional/fine_tuning_part_2_experiment1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7944552518>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#anchors =[[10/416,14/416],[23/416,27/416],[37/416,58/416],[81/416,82/416],[135/416,169/416],[344/416,319/416]]\n",
    "anchors =[[0.02078,0.049],[0.0426,0.128],[0.08523,0.19356],[0.1506,0.4163],[0.27835,0.58651],[0.5632,0.78614]]\n",
    "\n",
    "model = TinyYOLOv3_functional(anchor_boxes = anchors,num_classes=0,mode=\"tl\",training=True)\n",
    "model.training = False\n",
    "current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'\n",
    "model.load_weights(\"/tf/home/sergio/Tesis/training_3/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr =tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_Concatenate_obj_recall', factor=0.1, patience=4, verbose=1, mode='auto',min_delta=0.05)\n",
    "\n",
    "\n",
    "checkpoint_path = root_path+ \"/training_3/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_Concatenate_obj_recall',\n",
    "    mode='max',\n",
    "    save_best_only=True,verbose=1)\n",
    "\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "losses = {\"tf_op_layer_split_2\": loss_xy,\n",
    "          \"tf_op_layer_split_2_1\": loss_wh,\n",
    "          \"Concatenate_obj\":loss_objectness,\n",
    "          \"Concatenate_obj_1\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"Concatenate_obj\":[Precision(0.5),Recall(0.5),TruePositives(0.5),FalsePositives(0.5)]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[2,1,2,1])\n",
    "os.chdir(root_path+ \"/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   9213/Unknown - 309s 34ms/step - loss: 23.1843 - tf_op_layer_split_2_loss: 4.7072 - tf_op_layer_split_2_1_loss: 1.5619 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1363 - Concatenate_obj_precision: 0.6566 - Concatenate_obj_recall: 0.1352 - Concatenate_obj_true_positives: 36536.0000 - Concatenate_obj_false_positives: 19108.0000\n",
      "Epoch 00001: val_Concatenate_obj_recall improved from -inf to 0.16788, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 317s 34ms/step - loss: 23.1843 - tf_op_layer_split_2_loss: 4.7072 - tf_op_layer_split_2_1_loss: 1.5619 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1363 - Concatenate_obj_precision: 0.6566 - Concatenate_obj_recall: 0.1352 - Concatenate_obj_true_positives: 36536.0000 - Concatenate_obj_false_positives: 19108.0000 - val_loss: 21.1577 - val_tf_op_layer_split_2_loss: 4.3489 - val_tf_op_layer_split_2_1_loss: 0.6142 - val_Concatenate_obj_loss: 0.0362 - val_Concatenate_obj_1_loss: 11.7732 - val_Concatenate_obj_precision: 0.7057 - val_Concatenate_obj_recall: 0.1679 - val_Concatenate_obj_true_positives: 1985.0000 - val_Concatenate_obj_false_positives: 828.0000\n",
      "Epoch 2/20\n",
      "9213/9213 [==============================] - ETA: 0s - loss: 23.2868 - tf_op_layer_split_2_loss: 4.7702 - tf_op_layer_split_2_1_loss: 1.5277 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1468 - Concatenate_obj_precision: 0.6486 - Concatenate_obj_recall: 0.1403 - Concatenate_obj_true_positives: 37918.0000 - Concatenate_obj_false_positives: 20545.0000  ETA: 13s - loss: 23.3857 - tf_op_layer_split\n",
      "Epoch 00002: val_Concatenate_obj_recall improved from 0.16788 to 0.17143, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 294s 32ms/step - loss: 23.2868 - tf_op_layer_split_2_loss: 4.7702 - tf_op_layer_split_2_1_loss: 1.5277 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1468 - Concatenate_obj_precision: 0.6486 - Concatenate_obj_recall: 0.1403 - Concatenate_obj_true_positives: 37918.0000 - Concatenate_obj_false_positives: 20545.0000 - val_loss: 21.1438 - val_tf_op_layer_split_2_loss: 4.3468 - val_tf_op_layer_split_2_1_loss: 0.6129 - val_Concatenate_obj_loss: 0.0362 - val_Concatenate_obj_1_loss: 11.7649 - val_Concatenate_obj_precision: 0.7033 - val_Concatenate_obj_recall: 0.1714 - val_Concatenate_obj_true_positives: 2027.0000 - val_Concatenate_obj_false_positives: 855.0000\n",
      "Epoch 3/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.1763 - tf_op_layer_split_2_loss: 4.7277 - tf_op_layer_split_2_1_loss: 1.5202 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1289 - Concatenate_obj_precision: 0.6447 - Concatenate_obj_recall: 0.1410 - Concatenate_obj_true_positives: 38091.0000 - Concatenate_obj_false_positives: 20989.0000- ETA: 5s - loss: 23.3396 - tf_op_layer_split_2_loss: 4.7631 - tf_op_layer_split_2_1_loss: 1.5398 - Concatenate_obj_loss: 0.0362 - Concatenate_obj_1_loss: 12.2011 - Concatenate_obj_precision: 0.6462 - Concatenate_obj_recall: 0.1409 - Concatena\n",
      "Epoch 00003: val_Concatenate_obj_recall improved from 0.17143 to 0.17253, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 307s 33ms/step - loss: 23.1762 - tf_op_layer_split_2_loss: 4.7277 - tf_op_layer_split_2_1_loss: 1.5202 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1289 - Concatenate_obj_precision: 0.6447 - Concatenate_obj_recall: 0.1410 - Concatenate_obj_true_positives: 38092.0000 - Concatenate_obj_false_positives: 20989.0000 - val_loss: 21.1383 - val_tf_op_layer_split_2_loss: 4.3460 - val_tf_op_layer_split_2_1_loss: 0.6125 - val_Concatenate_obj_loss: 0.0362 - val_Concatenate_obj_1_loss: 11.7616 - val_Concatenate_obj_precision: 0.7015 - val_Concatenate_obj_recall: 0.1725 - val_Concatenate_obj_true_positives: 2040.0000 - val_Concatenate_obj_false_positives: 868.0000\n",
      "Epoch 4/20\n",
      "9211/9213 [============================>.] - ETA: 0s - loss: 23.2432 - tf_op_layer_split_2_loss: 4.7338 - tf_op_layer_split_2_1_loss: 1.5575 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1462 - Concatenate_obj_precision: 0.6446 - Concatenate_obj_recall: 0.1427 - Concatenate_obj_true_positives: 38553.0000 - Concatenate_obj_false_positives: 21256.0000\n",
      "Epoch 00004: val_Concatenate_obj_recall improved from 0.17253 to 0.17304, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 307s 33ms/step - loss: 23.2411 - tf_op_layer_split_2_loss: 4.7334 - tf_op_layer_split_2_1_loss: 1.5573 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1453 - Concatenate_obj_precision: 0.6446 - Concatenate_obj_recall: 0.1427 - Concatenate_obj_true_positives: 38554.0000 - Concatenate_obj_false_positives: 21260.0000 - val_loss: 21.1330 - val_tf_op_layer_split_2_loss: 4.3444 - val_tf_op_layer_split_2_1_loss: 0.6120 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7600 - val_Concatenate_obj_precision: 0.7012 - val_Concatenate_obj_recall: 0.1730 - val_Concatenate_obj_true_positives: 2046.0000 - val_Concatenate_obj_false_positives: 872.0000\n",
      "Epoch 5/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.1683 - tf_op_layer_split_2_loss: 4.6971 - tf_op_layer_split_2_1_loss: 1.5792 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1233 - Concatenate_obj_precision: 0.6439 - Concatenate_obj_recall: 0.1428 - Concatenate_obj_true_positives: 38579.0000 - Concatenate_obj_false_positives: 21334.0000\n",
      "Epoch 00005: val_Concatenate_obj_recall improved from 0.17304 to 0.17371, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 286s 31ms/step - loss: 23.1680 - tf_op_layer_split_2_loss: 4.6971 - tf_op_layer_split_2_1_loss: 1.5791 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1232 - Concatenate_obj_precision: 0.6439 - Concatenate_obj_recall: 0.1428 - Concatenate_obj_true_positives: 38579.0000 - Concatenate_obj_false_positives: 21335.0000 - val_loss: 21.1301 - val_tf_op_layer_split_2_loss: 4.3436 - val_tf_op_layer_split_2_1_loss: 0.6124 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7583 - val_Concatenate_obj_precision: 0.7005 - val_Concatenate_obj_recall: 0.1737 - val_Concatenate_obj_true_positives: 2054.0000 - val_Concatenate_obj_false_positives: 878.0000\n",
      "Epoch 6/20\n",
      "9213/9213 [==============================] - ETA: 0s - loss: 23.2415 - tf_op_layer_split_2_loss: 4.7398 - tf_op_layer_split_2_1_loss: 1.5636 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1266 - Concatenate_obj_precision: 0.6457 - Concatenate_obj_recall: 0.1437 - Concatenate_obj_true_positives: 38818.0000 - Concatenate_obj_false_positives: 21301.0000\n",
      "Epoch 00006: val_Concatenate_obj_recall improved from 0.17371 to 0.17439, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 273s 30ms/step - loss: 23.2415 - tf_op_layer_split_2_loss: 4.7398 - tf_op_layer_split_2_1_loss: 1.5636 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1266 - Concatenate_obj_precision: 0.6457 - Concatenate_obj_recall: 0.1437 - Concatenate_obj_true_positives: 38818.0000 - Concatenate_obj_false_positives: 21301.0000 - val_loss: 21.1257 - val_tf_op_layer_split_2_loss: 4.3424 - val_tf_op_layer_split_2_1_loss: 0.6116 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7571 - val_Concatenate_obj_precision: 0.7014 - val_Concatenate_obj_recall: 0.1744 - val_Concatenate_obj_true_positives: 2062.0000 - val_Concatenate_obj_false_positives: 878.0000\n",
      "Epoch 7/20\n",
      "9211/9213 [============================>.] - ETA: 0s - loss: 23.1260 - tf_op_layer_split_2_loss: 4.6924 - tf_op_layer_split_2_1_loss: 1.5413 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1283 - Concatenate_obj_precision: 0.6443 - Concatenate_obj_recall: 0.1434 - Concatenate_obj_true_positives: 38762.0000 - Concatenate_obj_false_positives: 21395.0000\n",
      "Epoch 00007: val_Concatenate_obj_recall improved from 0.17439 to 0.17490, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 275s 30ms/step - loss: 23.1239 - tf_op_layer_split_2_loss: 4.6919 - tf_op_layer_split_2_1_loss: 1.5411 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1274 - Concatenate_obj_precision: 0.6443 - Concatenate_obj_recall: 0.1434 - Concatenate_obj_true_positives: 38764.0000 - Concatenate_obj_false_positives: 21399.0000 - val_loss: 21.1226 - val_tf_op_layer_split_2_loss: 4.3416 - val_tf_op_layer_split_2_1_loss: 0.6117 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7555 - val_Concatenate_obj_precision: 0.7001 - val_Concatenate_obj_recall: 0.1749 - val_Concatenate_obj_true_positives: 2068.0000 - val_Concatenate_obj_false_positives: 886.0000\n",
      "Epoch 8/20\n",
      "9211/9213 [============================>.] - ETA: 0s - loss: 23.0948 - tf_op_layer_split_2_loss: 4.6881 - tf_op_layer_split_2_1_loss: 1.5093 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1376 - Concatenate_obj_precision: 0.6421 - Concatenate_obj_recall: 0.1443 - Concatenate_obj_true_positives: 38985.0000 - Concatenate_obj_false_positives: 21731.0000\n",
      "Epoch 00008: val_Concatenate_obj_recall improved from 0.17490 to 0.17515, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 271s 29ms/step - loss: 23.0932 - tf_op_layer_split_2_loss: 4.6879 - tf_op_layer_split_2_1_loss: 1.5091 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1366 - Concatenate_obj_precision: 0.6421 - Concatenate_obj_recall: 0.1442 - Concatenate_obj_true_positives: 38987.0000 - Concatenate_obj_false_positives: 21735.0000 - val_loss: 21.1202 - val_tf_op_layer_split_2_loss: 4.3413 - val_tf_op_layer_split_2_1_loss: 0.6107 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7548 - val_Concatenate_obj_precision: 0.6999 - val_Concatenate_obj_recall: 0.1752 - val_Concatenate_obj_true_positives: 2071.0000 - val_Concatenate_obj_false_positives: 888.0000\n",
      "Epoch 9/20\n",
      "9211/9213 [============================>.] - ETA: 0s - loss: 23.2538 - tf_op_layer_split_2_loss: 4.7425 - tf_op_layer_split_2_1_loss: 1.5826 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1146 - Concatenate_obj_precision: 0.6443 - Concatenate_obj_recall: 0.1447 - Concatenate_obj_true_positives: 39081.0000 - Concatenate_obj_false_positives: 21578.0000\n",
      "Epoch 00009: val_Concatenate_obj_recall improved from 0.17515 to 0.17583, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 271s 29ms/step - loss: 23.2519 - tf_op_layer_split_2_loss: 4.7421 - tf_op_layer_split_2_1_loss: 1.5824 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1137 - Concatenate_obj_precision: 0.6443 - Concatenate_obj_recall: 0.1446 - Concatenate_obj_true_positives: 39082.0000 - Concatenate_obj_false_positives: 21580.0000 - val_loss: 21.1188 - val_tf_op_layer_split_2_loss: 4.3410 - val_tf_op_layer_split_2_1_loss: 0.6109 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7535 - val_Concatenate_obj_precision: 0.6995 - val_Concatenate_obj_recall: 0.1758 - val_Concatenate_obj_true_positives: 2079.0000 - val_Concatenate_obj_false_positives: 893.0000\n",
      "Epoch 10/20\n",
      "9211/9213 [============================>.] - ETA: 0s - loss: 23.2037 - tf_op_layer_split_2_loss: 4.7204 - tf_op_layer_split_2_1_loss: 1.5606 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1305 - Concatenate_obj_precision: 0.6415 - Concatenate_obj_recall: 0.1440 - Concatenate_obj_true_positives: 38917.0000 - Concatenate_obj_false_positives: 21745.0000\n",
      "Epoch 00010: val_Concatenate_obj_recall improved from 0.17583 to 0.17608, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 271s 29ms/step - loss: 23.2016 - tf_op_layer_split_2_loss: 4.7200 - tf_op_layer_split_2_1_loss: 1.5604 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1296 - Concatenate_obj_precision: 0.6415 - Concatenate_obj_recall: 0.1440 - Concatenate_obj_true_positives: 38919.0000 - Concatenate_obj_false_positives: 21749.0000 - val_loss: 21.1164 - val_tf_op_layer_split_2_loss: 4.3403 - val_tf_op_layer_split_2_1_loss: 0.6103 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7532 - val_Concatenate_obj_precision: 0.6984 - val_Concatenate_obj_recall: 0.1761 - val_Concatenate_obj_true_positives: 2082.0000 - val_Concatenate_obj_false_positives: 899.0000\n",
      "Epoch 11/20\n",
      "9211/9213 [============================>.] - ETA: 0s - loss: 23.0888 - tf_op_layer_split_2_loss: 4.7045 - tf_op_layer_split_2_1_loss: 1.4887 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1193 - Concatenate_obj_precision: 0.6442 - Concatenate_obj_recall: 0.1451 - Concatenate_obj_true_positives: 39205.0000 - Concatenate_obj_false_positives: 21649.0000- ETA: 7s - loss: 23.2373 - tf_op_layer_split_2_loss: 4.7404 - tf_op_layer_split_2_1_loss: 1.5026 - Concatenate_obj_loss: 0.0362 - Concatenate_obj_1_loss: 12.1815 - Concatenate_obj_precision: 0.6459 - Conc\n",
      "Epoch 00011: val_Concatenate_obj_recall improved from 0.17608 to 0.17701, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 271s 29ms/step - loss: 23.0867 - tf_op_layer_split_2_loss: 4.7041 - tf_op_layer_split_2_1_loss: 1.4885 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1183 - Concatenate_obj_precision: 0.6442 - Concatenate_obj_recall: 0.1451 - Concatenate_obj_true_positives: 39207.0000 - Concatenate_obj_false_positives: 21653.0000 - val_loss: 21.1128 - val_tf_op_layer_split_2_loss: 4.3393 - val_tf_op_layer_split_2_1_loss: 0.6096 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7524 - val_Concatenate_obj_precision: 0.6993 - val_Concatenate_obj_recall: 0.1770 - val_Concatenate_obj_true_positives: 2093.0000 - val_Concatenate_obj_false_positives: 900.0000\n",
      "Epoch 12/20\n",
      "9211/9213 [============================>.] - ETA: 0s - loss: 23.2493 - tf_op_layer_split_2_loss: 4.7222 - tf_op_layer_split_2_1_loss: 1.5929 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1403 - Concatenate_obj_precision: 0.6415 - Concatenate_obj_recall: 0.1457 - Concatenate_obj_true_positives: 39372.0000 - Concatenate_obj_false_positives: 22007.0000\n",
      "Epoch 00012: val_Concatenate_obj_recall improved from 0.17701 to 0.17718, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 272s 29ms/step - loss: 23.2471 - tf_op_layer_split_2_loss: 4.7217 - tf_op_layer_split_2_1_loss: 1.5927 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1394 - Concatenate_obj_precision: 0.6414 - Concatenate_obj_recall: 0.1457 - Concatenate_obj_true_positives: 39374.0000 - Concatenate_obj_false_positives: 22009.0000 - val_loss: 21.1139 - val_tf_op_layer_split_2_loss: 4.3393 - val_tf_op_layer_split_2_1_loss: 0.6106 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7523 - val_Concatenate_obj_precision: 0.7000 - val_Concatenate_obj_recall: 0.1772 - val_Concatenate_obj_true_positives: 2095.0000 - val_Concatenate_obj_false_positives: 898.0000\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.2337 - tf_op_layer_split_2_loss: 4.7443 - tf_op_layer_split_2_1_loss: 1.5563 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1170 - Concatenate_obj_precision: 0.6453 - Concatenate_obj_recall: 0.1449 - Concatenate_obj_true_positives: 39137.0000 - Concatenate_obj_false_positives: 21508.0000\n",
      "Epoch 00013: val_Concatenate_obj_recall did not improve from 0.17718\n",
      "9213/9213 [==============================] - 270s 29ms/step - loss: 23.2334 - tf_op_layer_split_2_loss: 4.7443 - tf_op_layer_split_2_1_loss: 1.5563 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1170 - Concatenate_obj_precision: 0.6453 - Concatenate_obj_recall: 0.1449 - Concatenate_obj_true_positives: 39137.0000 - Concatenate_obj_false_positives: 21510.0000 - val_loss: 21.1134 - val_tf_op_layer_split_2_loss: 4.3392 - val_tf_op_layer_split_2_1_loss: 0.6107 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7521 - val_Concatenate_obj_precision: 0.6997 - val_Concatenate_obj_recall: 0.1772 - val_Concatenate_obj_true_positives: 2095.0000 - val_Concatenate_obj_false_positives: 899.0000\n",
      "Epoch 14/20\n",
      "9211/9213 [============================>.] - ETA: 0s - loss: 23.1597 - tf_op_layer_split_2_loss: 4.7040 - tf_op_layer_split_2_1_loss: 1.5637 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1164 - Concatenate_obj_precision: 0.6423 - Concatenate_obj_recall: 0.1450 - Concatenate_obj_true_positives: 39168.0000 - Concatenate_obj_false_positives: 21817.0000\n",
      "Epoch 00014: val_Concatenate_obj_recall improved from 0.17718 to 0.17777, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 270s 29ms/step - loss: 23.1577 - tf_op_layer_split_2_loss: 4.7035 - tf_op_layer_split_2_1_loss: 1.5635 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1155 - Concatenate_obj_precision: 0.6422 - Concatenate_obj_recall: 0.1450 - Concatenate_obj_true_positives: 39170.0000 - Concatenate_obj_false_positives: 21820.0000 - val_loss: 21.1120 - val_tf_op_layer_split_2_loss: 4.3386 - val_tf_op_layer_split_2_1_loss: 0.6112 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7513 - val_Concatenate_obj_precision: 0.6997 - val_Concatenate_obj_recall: 0.1778 - val_Concatenate_obj_true_positives: 2102.0000 - val_Concatenate_obj_false_positives: 902.0000\n",
      "Epoch 15/20\n",
      "9211/9213 [============================>.] - ETA: 0s - loss: 23.3130 - tf_op_layer_split_2_loss: 4.7764 - tf_op_layer_split_2_1_loss: 1.5667 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1217 - Concatenate_obj_precision: 0.6442 - Concatenate_obj_recall: 0.1447 - Concatenate_obj_true_positives: 39122.0000 - Concatenate_obj_false_positives: 21604.0000\n",
      "Epoch 00015: val_Concatenate_obj_recall improved from 0.17777 to 0.17794, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 270s 29ms/step - loss: 23.3109 - tf_op_layer_split_2_loss: 4.7759 - tf_op_layer_split_2_1_loss: 1.5665 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1207 - Concatenate_obj_precision: 0.6442 - Concatenate_obj_recall: 0.1447 - Concatenate_obj_true_positives: 39124.0000 - Concatenate_obj_false_positives: 21607.0000 - val_loss: 21.1103 - val_tf_op_layer_split_2_loss: 4.3384 - val_tf_op_layer_split_2_1_loss: 0.6104 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7507 - val_Concatenate_obj_precision: 0.6985 - val_Concatenate_obj_recall: 0.1779 - val_Concatenate_obj_true_positives: 2104.0000 - val_Concatenate_obj_false_positives: 908.0000\n",
      "Epoch 16/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.1979 - tf_op_layer_split_2_loss: 4.7195 - tf_op_layer_split_2_1_loss: 1.5529 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1342 - Concatenate_obj_precision: 0.6440 - Concatenate_obj_recall: 0.1456 - Concatenate_obj_true_positives: 39337.0000 - Concatenate_obj_false_positives: 21746.0000\n",
      "Epoch 00016: val_Concatenate_obj_recall improved from 0.17794 to 0.17811, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 271s 29ms/step - loss: 23.1976 - tf_op_layer_split_2_loss: 4.7194 - tf_op_layer_split_2_1_loss: 1.5529 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1342 - Concatenate_obj_precision: 0.6440 - Concatenate_obj_recall: 0.1456 - Concatenate_obj_true_positives: 39337.0000 - Concatenate_obj_false_positives: 21748.0000 - val_loss: 21.1087 - val_tf_op_layer_split_2_loss: 4.3377 - val_tf_op_layer_split_2_1_loss: 0.6103 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7508 - val_Concatenate_obj_precision: 0.6987 - val_Concatenate_obj_recall: 0.1781 - val_Concatenate_obj_true_positives: 2106.0000 - val_Concatenate_obj_false_positives: 908.0000\n",
      "Epoch 17/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.2044 - tf_op_layer_split_2_loss: 4.7270 - tf_op_layer_split_2_1_loss: 1.5287 - Concatenate_obj_loss: 0.0360 - Concatenate_obj_1_loss: 12.1497 - Concatenate_obj_precision: 0.6419 - Concatenate_obj_recall: 0.1451 - Concatenate_obj_true_positives: 39226.0000 - Concatenate_obj_false_positives: 21885.0000\n",
      "Epoch 00017: val_Concatenate_obj_recall improved from 0.17811 to 0.17837, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 274s 30ms/step - loss: 23.2041 - tf_op_layer_split_2_loss: 4.7269 - tf_op_layer_split_2_1_loss: 1.5287 - Concatenate_obj_loss: 0.0360 - Concatenate_obj_1_loss: 12.1496 - Concatenate_obj_precision: 0.6419 - Concatenate_obj_recall: 0.1451 - Concatenate_obj_true_positives: 39226.0000 - Concatenate_obj_false_positives: 21887.0000 - val_loss: 21.1064 - val_tf_op_layer_split_2_loss: 4.3371 - val_tf_op_layer_split_2_1_loss: 0.6098 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7502 - val_Concatenate_obj_precision: 0.6981 - val_Concatenate_obj_recall: 0.1784 - val_Concatenate_obj_true_positives: 2109.0000 - val_Concatenate_obj_false_positives: 912.0000\n",
      "Epoch 18/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.1069 - tf_op_layer_split_2_loss: 4.6958 - tf_op_layer_split_2_1_loss: 1.5080 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1357 - Concatenate_obj_precision: 0.6422 - Concatenate_obj_recall: 0.1453 - Concatenate_obj_true_positives: 39282.0000 - Concatenate_obj_false_positives: 21886.0000\n",
      "Epoch 00018: val_Concatenate_obj_recall improved from 0.17837 to 0.17845, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 281s 30ms/step - loss: 23.1066 - tf_op_layer_split_2_loss: 4.6957 - tf_op_layer_split_2_1_loss: 1.5080 - Concatenate_obj_loss: 0.0359 - Concatenate_obj_1_loss: 12.1356 - Concatenate_obj_precision: 0.6422 - Concatenate_obj_recall: 0.1453 - Concatenate_obj_true_positives: 39282.0000 - Concatenate_obj_false_positives: 21887.0000 - val_loss: 21.1049 - val_tf_op_layer_split_2_loss: 4.3363 - val_tf_op_layer_split_2_1_loss: 0.6100 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7501 - val_Concatenate_obj_precision: 0.6982 - val_Concatenate_obj_recall: 0.1785 - val_Concatenate_obj_true_positives: 2110.0000 - val_Concatenate_obj_false_positives: 912.0000\n",
      "Epoch 19/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.1899 - tf_op_layer_split_2_loss: 4.7419 - tf_op_layer_split_2_1_loss: 1.5260 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1085 - Concatenate_obj_precision: 0.6431 - Concatenate_obj_recall: 0.1463 - Concatenate_obj_true_positives: 39521.0000 - Concatenate_obj_false_positives: 21936.0000\n",
      "Epoch 00019: val_Concatenate_obj_recall did not improve from 0.17845\n",
      "9213/9213 [==============================] - 282s 31ms/step - loss: 23.1898 - tf_op_layer_split_2_loss: 4.7420 - tf_op_layer_split_2_1_loss: 1.5259 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1083 - Concatenate_obj_precision: 0.6431 - Concatenate_obj_recall: 0.1463 - Concatenate_obj_true_positives: 39522.0000 - Concatenate_obj_false_positives: 21936.0000 - val_loss: 21.1041 - val_tf_op_layer_split_2_loss: 4.3365 - val_tf_op_layer_split_2_1_loss: 0.6094 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7494 - val_Concatenate_obj_precision: 0.6980 - val_Concatenate_obj_recall: 0.1785 - val_Concatenate_obj_true_positives: 2110.0000 - val_Concatenate_obj_false_positives: 913.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "9213/9213 [==============================] - ETA: 0s - loss: 23.1517 - tf_op_layer_split_2_loss: 4.7371 - tf_op_layer_split_2_1_loss: 1.5063 - Concatenate_obj_loss: 0.0357 - Concatenate_obj_1_loss: 12.0997 - Concatenate_obj_precision: 0.6431 - Concatenate_obj_recall: 0.1459 - Concatenate_obj_true_positives: 39404.0000 - Concatenate_obj_false_positives: 21864.0000\n",
      "Epoch 00020: val_Concatenate_obj_recall improved from 0.17845 to 0.17854, saving model to /tf/home/sergio/Tesis/training_3/cp.ckpt\n",
      "9213/9213 [==============================] - 283s 31ms/step - loss: 23.1517 - tf_op_layer_split_2_loss: 4.7371 - tf_op_layer_split_2_1_loss: 1.5063 - Concatenate_obj_loss: 0.0357 - Concatenate_obj_1_loss: 12.0997 - Concatenate_obj_precision: 0.6431 - Concatenate_obj_recall: 0.1459 - Concatenate_obj_true_positives: 39404.0000 - Concatenate_obj_false_positives: 21864.0000 - val_loss: 21.1037 - val_tf_op_layer_split_2_loss: 4.3364 - val_tf_op_layer_split_2_1_loss: 0.6095 - val_Concatenate_obj_loss: 0.0361 - val_Concatenate_obj_1_loss: 11.7491 - val_Concatenate_obj_precision: 0.6988 - val_Concatenate_obj_recall: 0.1785 - val_Concatenate_obj_true_positives: 2111.0000 - val_Concatenate_obj_false_positives: 910.0000\n"
     ]
    }
   ],
   "source": [
    "os.chdir(root_path+ \"/pedestrian_dataset_train_tfr\")\n",
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(current_directory+'/weights_retrain_functional/fine_tuning_part_3_experiment1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COntinuacion Fine Tuning FInal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb0b7f631d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#anchors =[[10/416,14/416],[23/416,27/416],[37/416,58/416],[81/416,82/416],[135/416,169/416],[344/416,319/416]]\n",
    "anchors =[[0.02078,0.049],[0.0426,0.128],[0.08523,0.19356],[0.1506,0.4163],[0.27835,0.58651],[0.5632,0.78614]]\n",
    "\n",
    "model = TinyYOLOv3_functional(anchor_boxes = anchors,num_classes=0,mode=\"ft\",training=True)\n",
    "model.training = False\n",
    "current_directory= '/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'\n",
    "model.load_weights(\"/tf/home/sergio/Tesis/training_3/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr =tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_Concatenate_obj_recall', factor=0.1, patience=4, verbose=1, mode='auto',min_delta=0.05)\n",
    "\n",
    "\n",
    "checkpoint_path = root_path+ \"/training_4/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_Concatenate_obj_recall',\n",
    "    mode='max',\n",
    "    save_best_only=True,verbose=1)\n",
    "\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "losses = {\"tf_op_layer_split_2\": loss_xy,\n",
    "          \"tf_op_layer_split_2_1\": loss_wh,\n",
    "          \"Concatenate_obj\":loss_objectness,\n",
    "          \"Concatenate_obj_1\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"Concatenate_obj\":[Precision(0.5),Recall(0.5),TruePositives(0.5),FalsePositives(0.5)]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[2,1,2,1])\n",
    "os.chdir(root_path+ \"/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   9213/Unknown - 657s 71ms/step - loss: 23.3202 - tf_op_layer_split_2_loss: 4.6950 - tf_op_layer_split_2_1_loss: 1.5623 - Concatenate_obj_loss: 0.0364 - Concatenate_obj_1_loss: 12.2951 - Concatenate_obj_precision: 0.6463 - Concatenate_obj_recall: 0.1410 - Concatenate_obj_true_positives: 38108.0000 - Concatenate_obj_false_positives: 20858.0000- 615s 71ms/step - loss: 23.3505 - tf_op_layer_split_2_loss\n",
      "Epoch 00001: val_Concatenate_obj_recall improved from -inf to 0.15680, saving model to /tf/home/sergio/Tesis/training_4/cp.ckpt\n",
      "9213/9213 [==============================] - 665s 72ms/step - loss: 23.3202 - tf_op_layer_split_2_loss: 4.6950 - tf_op_layer_split_2_1_loss: 1.5623 - Concatenate_obj_loss: 0.0364 - Concatenate_obj_1_loss: 12.2951 - Concatenate_obj_precision: 0.6463 - Concatenate_obj_recall: 0.1410 - Concatenate_obj_true_positives: 38108.0000 - Concatenate_obj_false_positives: 20858.0000 - val_loss: 21.1535 - val_tf_op_layer_split_2_loss: 4.3429 - val_tf_op_layer_split_2_1_loss: 0.5964 - val_Concatenate_obj_loss: 0.0364 - val_Concatenate_obj_1_loss: 11.7986 - val_Concatenate_obj_precision: 0.7183 - val_Concatenate_obj_recall: 0.1568 - val_Concatenate_obj_true_positives: 1854.0000 - val_Concatenate_obj_false_positives: 727.0000\n",
      "Epoch 2/20\n",
      "9212/9213 [============================>.] - ETA: 0s - loss: 23.2385 - tf_op_layer_split_2_loss: 4.6608 - tf_op_layer_split_2_1_loss: 1.5592 - Concatenate_obj_loss: 0.0364 - Concatenate_obj_1_loss: 12.2851 - Concatenate_obj_precision: 0.6472 - Concatenate_obj_recall: 0.1389 - Concatenate_obj_true_positives: 37545.0000 - Concatenate_obj_false_positives: 20464.0000\n",
      "Epoch 00002: val_Concatenate_obj_recall improved from 0.15680 to 0.15697, saving model to /tf/home/sergio/Tesis/training_4/cp.ckpt\n",
      "9213/9213 [==============================] - 663s 72ms/step - loss: 23.2382 - tf_op_layer_split_2_loss: 4.6607 - tf_op_layer_split_2_1_loss: 1.5592 - Concatenate_obj_loss: 0.0364 - Concatenate_obj_1_loss: 12.2850 - Concatenate_obj_precision: 0.6472 - Concatenate_obj_recall: 0.1389 - Concatenate_obj_true_positives: 37546.0000 - Concatenate_obj_false_positives: 20464.0000 - val_loss: 21.1071 - val_tf_op_layer_split_2_loss: 4.3263 - val_tf_op_layer_split_2_1_loss: 0.5897 - val_Concatenate_obj_loss: 0.0364 - val_Concatenate_obj_1_loss: 11.7920 - val_Concatenate_obj_precision: 0.7197 - val_Concatenate_obj_recall: 0.1570 - val_Concatenate_obj_true_positives: 1856.0000 - val_Concatenate_obj_false_positives: 723.0000\n",
      "Epoch 3/20\n",
      "6573/9213 [====================>.........] - ETA: 3:10 - loss: 23.0180 - tf_op_layer_split_2_loss: 4.6242 - tf_op_layer_split_2_1_loss: 1.5217 - Concatenate_obj_loss: 0.0358 - Concatenate_obj_1_loss: 12.1763 - Concatenate_obj_precision: 0.6470 - Concatenate_obj_recall: 0.1373 - Concatenate_obj_true_positives: 26205.0000 - Concatenate_obj_false_positives: 14298.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-098dd41d56a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m\"/pedestrian_dataset_train_tfr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.chdir(root_path+ \"/pedestrian_dataset_train_tfr\")\n",
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset,callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/tf/home/sergio/Tesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(root_path+\"/TinyYOLOv3-Pedestrian-Detection\")\n",
    "\n",
    "from YOLOblocks import TinyYOLOv3,BasicBlock,PredictionLayer#,YOLOLossBasicBlock\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "#from tensorflow.python.tools import freeze_graph\n",
    "#from skimage.io import imread,imshow\n",
    "#from skimage.transform import resize \n",
    "import time\n",
    "#from tensorflow.compat.v1.image import decode_image\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'bboxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'num_real_boxes':tf.io.FixedLenFeature([], tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_matrix_tf(box_arr1, box_arr2):\n",
    "    \n",
    "    box_arr1 = box_arr1 -tf.tile(box_arr1[:,:2],[1,2])\n",
    "    #print(box_arr1)\n",
    "    x11, y11, x12, y12 = tf.split(box_arr1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = tf.split(box_arr2, 4, axis=1)\n",
    "    xA = tf.maximum(x11, tf.transpose(x21))\n",
    "    yA = tf.maximum(y11, tf.transpose(y21))\n",
    "    xB = tf.minimum(x12, tf.transpose(x22))\n",
    "    yB = tf.minimum(y12, tf.transpose(y22))\n",
    "    interArea = tf.maximum((xB - xA + 1e-9), 0) * tf.maximum((yB - yA + 1e-9), 0)\n",
    "    boxAArea = (x12 - x11 + 1e-9) * (y12 - y11 + 1e-9)\n",
    "    boxBArea = (x22 - x21 + 1e-9) * (y22 - y21 + 1e-9)\n",
    "    iou = interArea / (boxAArea + tf.transpose(boxBArea) - interArea)\n",
    "    return iou,tf.argmax(iou,axis=1)#[:,tf.newaxis]\n",
    "\n",
    "\n",
    "def fill_yolo_output(boxes,grid_size,num_anchors,which_anchor_box,which_anchor_box_index):\n",
    "    #print(boxes.shape)\n",
    "    #noobj_mask = tf.ones((1,grid_size*grid_size*num_anchors))\n",
    "    #print(noobj_mask.shape)\n",
    "    \n",
    "    x_min,y_min,x_max,y_max =tf.split(boxes,4,axis=1)\n",
    "\n",
    "    #Transforma las coordenadas de (xmin,ymin,xmax,ymax) --> (xcenter,ycenter,width,height)\n",
    "    width = x_max-x_min\n",
    "    height = y_max-y_min\n",
    "    x_global =x_min + tf.math.divide(x_max - x_min,2)\n",
    "    y_global =y_min + tf.math.divide(y_max - y_min,2)\n",
    "    \n",
    "    \n",
    "    x_min_anchor,y_min_anchor,x_max_anchor,y_max_anchor =tf.split(which_anchor_box,4,axis=1)\n",
    "    \n",
    "    width_anchor = x_max_anchor-x_min_anchor\n",
    "    height_anchor = y_max_anchor-y_min_anchor\n",
    "    x_global_anchor =x_min_anchor + tf.math.divide(x_max_anchor - x_min_anchor,2)\n",
    "    y_global_anchor =y_min_anchor + tf.math.divide(y_max_anchor - y_min_anchor,2)   \n",
    "\n",
    "    \n",
    "    #print(\"el x original\",x_global)\n",
    "    #print(\"el y original\",y_global)\n",
    "    #print(\"el w original\",width)\n",
    "    #print(\"el h original\",height)\n",
    "    \n",
    "    #porción de la imagen que hay en cada celda\n",
    "    pixel_per_grid = tf.math.divide(1.,grid_size)\n",
    "    #print(pixel_per_grid)\n",
    "    \n",
    "    #Obtenemos la coordenada de la celda donde están los boundingboxes\n",
    "    offset_grid_x = x_global//pixel_per_grid\n",
    "    offset_grid_y = y_global//pixel_per_grid\n",
    "    \n",
    "    #Obtenemos el el centro locacon referencia  al celda encontrada previamente\n",
    "    x_local =tf.math.floormod(x_global,pixel_per_grid)\n",
    "    y_local =tf.math.floormod(y_global,pixel_per_grid)\n",
    "    #print(x_local,y_local)\n",
    "    \n",
    "    #Valores tx e ty del groudtruth\n",
    "    tx = tf.math.log(x_local + 1e-07/(1-x_local))\n",
    "    ty = tf.math.log(y_local+1e-07/(1-y_local))\n",
    "    #tw = tf.math.log(tf.math.divide(width+1e-07,width_anchor))\n",
    "    #th = tf.math.log(tf.math.divide(height+1e-07,height_anchor))\n",
    "    tw = tf.math.divide(width+1e-07,width_anchor)\n",
    "    th = tf.math.divide(height+1e-07,height_anchor)\n",
    "    tobj_mask = tf.ones_like(tx)\n",
    "    tobj = tf.concat([tobj_mask,tobj_mask],axis=0)\n",
    "    \n",
    "    #tnoobj = tf.zeros_like(tx)    \n",
    "    #tobj = tf.ones((grid_size*grid_size*num_anchors,1))\n",
    "    #tnoobj = tf.zeros((grid_size*grid_size*num_anchors,1))\n",
    "    #print(\"Lo que la red debe predecir\",tx.numpy(),ty.numpy(),tw.numpy(),th.numpy())\n",
    "    #x_global = (offset_grid_x * pixel_per_grid) + tf.math.sigmoid(tx)\n",
    "    #y_global = (offset_grid_y * pixel_per_grid) + tf.math.sigmoid(ty)\n",
    "    #w = width_anchor*tf.math.exp(tw)\n",
    "    #h = height_anchor*tf.math.exp(th)\n",
    "    #print(\"obtnemos el x_real\",x_global)\n",
    "    #print(\"obtenemos el y_real\",y_global)\n",
    "    #print(\"obtenemos el w real\",w)\n",
    "    #print(\"obtenemos el h real\",h)\n",
    "    \n",
    "    #anchor_boxes_per_output = num_anchors//2\n",
    "\n",
    "    #Residuo indica cual de los 3 anchor boxes de la coordenada es la que llevara el 1\n",
    "    #Coord representa la coordenada del grid\n",
    "    \n",
    "    residuo = tf.math.floormod(which_anchor_box_index,num_anchors)[:,tf.newaxis]\n",
    "    coord = tf.cast(num_anchors*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    \n",
    "    coord_objectness = tf.cast(2*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    coord_objectness2 = coord_objectness+1\n",
    "    coord_objectess_global = tf.concat([coord_objectness,coord_objectness2],axis=0)\n",
    "    \n",
    "    output_position = residuo+coord\n",
    "    print(\"tipo de aoutput_positivon\",output_position)\n",
    "    \n",
    "    print(output_position)\n",
    "    \n",
    "    dense_shape = grid_size*grid_size*num_anchors\n",
    "    print(dense_shape)\n",
    "    tx_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tx[:,0], dense_shape=[dense_shape]))\n",
    "    ty_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=ty[:,0], dense_shape=[dense_shape]))\n",
    "    tw_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tw[:,0], dense_shape=[dense_shape]))\n",
    "    th_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=th[:,0], dense_shape=[dense_shape]))\n",
    "    obj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tobj_mask[:,0], dense_shape=[dense_shape]))\n",
    "    objectness_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=coord_objectess_global, values=tobj[:,0], dense_shape=[dense_shape]))\n",
    "    #noobj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tnoobj[:,0], dense_shape=[dense_shape]))\n",
    "    #obj_mask =tx_vector=ty_vector=tw_vector=th_vector = tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "    \n",
    "    tx_vector_dense = tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=False, name=\"Dense_tx\")\n",
    "    ty_vector_dense = tf.sparse.to_dense(ty_vector, default_value=0, validate_indices=False, name=\"Dense_ty\")\n",
    "    tw_vector_dense = tf.sparse.to_dense(tw_vector, default_value=0, validate_indices=False, name=\"Dense_tw\")\n",
    "    th_vector_dense = tf.sparse.to_dense(th_vector, default_value=0, validate_indices=False, name=\"Dense_th\")\n",
    "    obj_mask_dense =  tf.sparse.to_dense(obj_mask, default_value=0, validate_indices=False, name=\"Dense_obj\")\n",
    "    #noobj_mask_dense = 1-obj_mask_dense\n",
    "    objectness_vector_dense =  tf.sparse.to_dense(objectness_vector, default_value=0, validate_indices=False)\n",
    "    \n",
    "    #noobj_mask_dense= tf.sparse.to_dense(noobj_mask, default_value=1, validate_indices=False, name=\"Dense_noobj\")\n",
    "    ##print(tx_vector.to_dense)\n",
    "    #print(tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=True, name=None)\n",
    "    #tx_vector=tx_vector[[3,2],]\n",
    "    #tx_vector[output_position[:,0]] = tx\n",
    "    #print(\"coordenada de la salida:\",output_position)\n",
    "    \n",
    "    #return ((tx_vector_dense,ty_vector_dense,obj_mask_dense),(tw_vector_dense,th_vector_dense,obj_mask_dense),(objectness),(objectness))\n",
    "    \n",
    "    return tx_vector_dense,ty_vector_dense,tw_vector_dense,th_vector_dense,obj_mask_dense,objectness_vector_dense\n",
    "\n",
    "def build_targets(image,image_bboxes,num_real_boxes,anchor_boxes):\n",
    "    \n",
    "    images_bboxes_original = image_bboxes\n",
    "    #Obtenemos los boduing boxes que son reales\n",
    "    image_bboxes = image_bboxes[:num_real_boxes,:]\n",
    "    #print(\"Bouding boxes de la imagen\",image_bboxes)\n",
    "    #Obteneos  la matriz de IoU , y el índice del anchor box que dió mejor resultado\n",
    "    \n",
    "    #Nprmalizamos con respecto al tamaño de la imagen y obtenemos la Iou con los anchor boxes\n",
    "    image_bboxes = tf.math.divide(image_bboxes,416)\n",
    "    iou_matrix,which_anchor_box_index = get_iou_matrix_tf(image_bboxes,anchor_boxes)\n",
    "    \n",
    "    print(which_anchor_box_index)\n",
    "\n",
    "    anchor_boxes_per_output = len(anchor_boxes)//2\n",
    "    #Indices de los bouding boxes que irian en cada salida, index_best_ yolo nos dice que bouding boxes de la imagen van a la salida YOLO1,\n",
    "    #porque su mejor IoU fue con los len(anchor_boxes)//2 anchor boxes mas grandes\n",
    "    index_best_yolo1 = tf.where(which_anchor_box_index>=anchor_boxes_per_output)[:,0]\n",
    "    index_best_yolo2 = tf.where(which_anchor_box_index<anchor_boxes_per_output)[:,0]\n",
    "    index_best_anchor_yolo1 = tf.gather(which_anchor_box_index,index_best_yolo1,axis=0)\n",
    "    index_best_anchor_yolo2 = tf.gather(which_anchor_box_index,index_best_yolo2,axis=0)\n",
    "    \n",
    "    print(index_best_yolo1)\n",
    "    print(index_best_anchor_yolo1)\n",
    "\n",
    "    print(index_best_yolo2)\n",
    "    print(index_best_anchor_yolo2)\n",
    "\n",
    "    \n",
    "    best_bboxes_yolo1 = tf.gather(image_bboxes,index_best_yolo1,axis =0)\n",
    "    best_anchors_yolo1 = tf.gather(anchor_boxes,index_best_anchor_yolo1, axis =0) #LOs dos anchor boxes grandes corrsponden a YOLO1\n",
    "    best_bboxes_yolo2 = tf.gather(image_bboxes,index_best_yolo2,axis =0)\n",
    "    best_anchors_yolo2 = tf.gather(anchor_boxes,index_best_anchor_yolo2, axis =0) #Los dos anchor boxes pequeños corresponden a YOLO2\n",
    "    \n",
    "    \n",
    "    if best_anchors_yolo1.shape[0] !=0:\n",
    "        tx_vector_yolo1,ty_vector_yolo1,tw_vector_yolo1,th_vector_yolo1,obj_mask_yolo1,obj_vector_yolo1= fill_yolo_output(best_bboxes_yolo1,13,anchor_boxes_per_output,best_anchors_yolo1,index_best_anchor_yolo1)\n",
    "    else:\n",
    "        tx_vector_yolo1=ty_vector_yolo1=tw_vector_yolo1=th_vector_yolo1=obj_mask_yolo1= obj_vector_yolo1=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo1 = tf.ones((1,13*13*num_anchors))\n",
    "    \n",
    "    if best_anchors_yolo2.shape[0] != 0:\n",
    "        tx_vector_yolo2,ty_vector_yolo2,tw_vector_yolo2,th_vector_yolo2,obj_mask_yolo2,obj_vector_yolo2 = fill_yolo_output(best_bboxes_yolo2,26,anchor_boxes_per_output,best_anchors_yolo2,index_best_anchor_yolo2)\n",
    "    else:\n",
    "        tx_vector_yolo2=ty_vector_yolo2=tw_vector_yolo2=th_vector_yolo2=obj_mask_yolo2 = obj_vector_yolo2=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo2 = tf.ones((1,26*26*num_anchors))\n",
    "        \n",
    "    tx_vector = tf.concat([tx_vector_yolo1,tx_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    ty_vector = tf.concat([ty_vector_yolo1,ty_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    tw_vector = tf.concat([tw_vector_yolo1,tw_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    th_vector = tf.concat([th_vector_yolo1,th_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_mask = tf.concat([obj_mask_yolo1,obj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    #noobj_mask = tf.concat([noobj_mask_yolo1,noobj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_vector = tf.concat([obj_vector_yolo1,obj_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    \n",
    "    #output = tf.concat([tx_vector,ty_vector,tw_vector,th_vector,obj_mask,noobj_mask,obj_vector],axis=1)\n",
    "    #images_bboxes_original\n",
    "    #return image,output\n",
    "    #Vamos a regresar obj mask que es 1 cuando hay objeto en grid y el anchor box especifico\n",
    "    return tf.cast(image,tf.float32)/255,(tf.concat([tx_vector,ty_vector,obj_mask],axis=1),tf.concat([tw_vector,th_vector,obj_mask],axis=1),(obj_mask),(obj_mask))\n",
    "\n",
    "def imgaug_data_augmentation(image,bboxes,num_real_boxes):\n",
    "    im_shape = image.shape\n",
    "    bbs = BoundingBoxesOnImage.from_xyxy_array(bboxes*416, shape=(416,416))\n",
    "    \n",
    "    policy = np.random.randint(5)\n",
    "    \n",
    "    #policy = 2\n",
    "    if policy == 0:\n",
    "        \n",
    "        p = np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateX(px=(-60, 60),cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "        p = np.random.random()\n",
    "        if p<=0.8:\n",
    "            aug = iaa.HistogramEqualization()\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "    elif policy==1:\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.2:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.8:\n",
    "            square_size = np.random.randint(48)\n",
    "            aug = iaa.Cutout(nb_iterations=1, size=square_size/416, squared=True)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    elif policy==2:\n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.ShearY(shear=(int(-0.06*416), int(0.06*416)), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "        p=np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "            \n",
    "    elif policy==3:\n",
    "        p=np.random.random()\n",
    "        if p<=0.6:    \n",
    "            aug = iaa.Rotate(rotate=(-30, 30), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs_aug.remove_out_of_image().clip_out_of_image()\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.MultiplySaturation((0.54, 1.54))\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    bbs.remove_out_of_image()\n",
    "    \n",
    "    return image,np.clip(bbs.to_xyxy_array(np.float32),1,415),num_real_boxes\n",
    "    \n",
    "    \n",
    "def preprocessing(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,num_real_boxes\n",
    "\n",
    "def preprocessing_validation_set(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    bboxes = tf.clip_by_value(bboxes*416,1,415)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,tf.cast(num_real_boxes,tf.int64)\n",
    "    \n",
    "@tf.function(input_signature=[tf.TensorSpec((416,416,3), tf.uint8),tf.TensorSpec((None,4), tf.float32),tf.TensorSpec((), tf.int64)]) \n",
    "def tf_numpy_albumentations_real(image,bboxes,num_real_boxes):\n",
    "    \n",
    "    boxes_shape = bboxes.shape\n",
    "    im_shape = image.shape\n",
    "\n",
    "    image,bboxes,num_real_boxes = tf.numpy_function(imgaug_data_augmentation,[image,bboxes,num_real_boxes],Tout =[tf.uint8,tf.float32,tf.int64])\n",
    " \n",
    "    image.set_shape(im_shape)\n",
    "    bboxes.set_shape(boxes_shape)\n",
    "    print(\"Imagen data type\",image.dtype)\n",
    "    print(\"Bboxes data type\",bboxes.dtype)\n",
    "    print(\"num_real_boxes\",num_real_boxes.dtype)\n",
    "\n",
    "    return image,bboxes,num_real_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen data type <dtype: 'uint8'>\n",
      "Bboxes data type <dtype: 'float32'>\n",
      "num_real_boxes <dtype: 'int64'>\n",
      "Tensor(\"ArgMax:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", shape=(None,), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "338\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "1352\n",
      "Tensor(\"ArgMax:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", dtype=int64)\n",
      "Tensor(\"add_18:0\", dtype=int64)\n",
      "338\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", dtype=int64)\n",
      "Tensor(\"add_30:0\", dtype=int64)\n",
      "1352\n"
     ]
    }
   ],
   "source": [
    "#USANDO TF.IMAGE MODULE\n",
    "anchors =tf.constant(np.array([[0,0,0.026,0.062],[0,0,0.067,0.183],[0,0,0.128,0.323],[0,0,0.343,0.650]]),dtype=tf.float32)\n",
    "\n",
    "#anchors =tf.constant(np.array([[0,0,0.015,0.037],[0,0,0.043,0.104],[0,0,0.11,0.278],[0,0,0.351,0.66]]),dtype=tf.float32)\n",
    "#anchors =tf.constant(np.array([[0,0,0.026,0.062],[0,0,0.067,0.183],[0,0,0.128,0.323],[0,0,0.343,0.650]]),dtype=tf.float32)\n",
    "#anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "os.chdir(root_path+\"/pedestrian_dataset_train_tfr\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(root_path+\"/pedestrian_dataset_val_tfr_fixed\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset_val =tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(root_path+\"/pedestrian_dataset_train_tfr\")\n",
    "#.shuffle(70000)\n",
    "train_dataset = raw_image_dataset.map(preprocessing,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(tf_numpy_albumentations_real,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "train_dataset = train_dataset.batch(16)\n",
    "\n",
    "val_dataset = raw_image_dataset_val.map(preprocessing_validation_set,num_parallel_calls=8)\n",
    "val_dataset = val_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "val_dataset = val_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Loss,BinaryCrossentropy,MeanSquaredError,MeanSquaredLogarithmicError\n",
    "'''\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tx_true-tx_pred))  \n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "'''\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "\n",
    "def loss_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_no_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    \n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n",
      "Pesos de la convolucion (432,)\n",
      "CONV SHAPE (16, 3, 3, 3)\n",
      "496\n",
      "Pesos de la convolucion (4608,)\n",
      "CONV SHAPE (32, 16, 3, 3)\n",
      "5232\n",
      "Pesos de la convolucion (18432,)\n",
      "CONV SHAPE (64, 32, 3, 3)\n",
      "23920\n",
      "Pesos de la convolucion (73728,)\n",
      "CONV SHAPE (128, 64, 3, 3)\n",
      "98160\n",
      "Pesos de la convolucion (294912,)\n",
      "CONV SHAPE (256, 128, 3, 3)\n",
      "394096\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "1575792\n",
      "Pesos de la convolucion (4718592,)\n",
      "CONV SHAPE (1024, 512, 3, 3)\n",
      "6298480\n",
      "Pesos de la convolucion (262144,)\n",
      "CONV SHAPE (256, 1024, 1, 1)\n",
      "6561648\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "7743344\n",
      "Pesos de la convolucion (130560,)\n",
      "CONV SHAPE (255, 512, 1, 1)\n",
      "7874159\n",
      "Pesos de la convolucion (32768,)\n",
      "CONV SHAPE (128, 256, 1, 1)\n",
      "7907439\n",
      "Pesos de la convolucion (884736,)\n",
      "CONV SHAPE (256, 384, 3, 3)\n",
      "8793199\n",
      "Pesos de la convolucion (65280,)\n",
      "CONV SHAPE (255, 256, 1, 1)\n",
      "8858734\n",
      "8858734\n",
      "8858734\n",
      "8858734\n",
      "8858734\n",
      "8858734\n",
      "8858734\n"
     ]
    }
   ],
   "source": [
    "anchors =tf.constant(np.array([[0.026,0.062],[0.067,0.183],[0.128,0.323],[0.343,0.650]]),dtype=tf.float32)\n",
    "#anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "model = TinyYOLOv3(1,anchor_boxes=anchors,train=True,mode = \"finetuning\")\n",
    "model.build(batch_input_shape=(None,416,416,3))\n",
    "print(model.load_weights_darknet(root_path+\"/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicBlock1 True\n",
      "BasicBlock2 True\n",
      "BasicBlock3 True\n",
      "BasicBlock4 True\n",
      "BasicBlock5 True\n",
      "BasicBlock6 True\n",
      "BasicBlock7 True\n",
      "BasicBlock8 True\n",
      "BasicBlock9 True\n",
      "FinalBlock1 True\n",
      "BasicBlock11 True\n",
      "BasicBlock12 True\n",
      "FinalBlock2 True\n",
      "Concatenate True\n",
      "Upsampling True\n",
      "Prediction1 True\n",
      "Prediction2 True\n",
      "Concatenate_BBOX True\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(l.name, l.trainable)#,l.weights[0].shape)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eager execution training (For debuging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugging = False\n",
    "\n",
    "if debugging:\n",
    "    model = TinyYOLOv3(1,anchor_boxes=anchors,train=True)\n",
    "    model.build(batch_input_shape=(None,416,416,3))\n",
    "    model.summary()\n",
    "    model.load_weights_darknet(root_path+\"/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\");\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    #model_loss = YOLOLoss()\n",
    "\n",
    "    for epochs in range(1,2,1):\n",
    "        for (images,y_true) in train_dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                outputs = model(images)\n",
    "                print(\"Tamaño de la etiqueta\",y_true[0].shape)\n",
    "                print(\"Salida\",outputs[0].shape)\n",
    "                loss_x_y = loss_xy(y_true[0],outputs[0])\n",
    "                loss_w_h = loss_wh(y_true[1],outputs[1])\n",
    "                loss_obj = loss_objectness(y_true[2],outputs[2])\n",
    "                loss_noobj = loss_no_objectness(y_true[3],outputs[3])\n",
    "\n",
    "                total_loss =loss_x_y+loss_w_h+loss_obj+loss_noobj\n",
    "            #print(epochs,(total_loss.numpy()))\n",
    "            grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "                #logging.info(\"{}_train_{}, {}, {}\".format(\n",
    "                #    epoch, batch, total_loss.numpy()))\n",
    "                \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=3e-4)\n",
    "\n",
    "losses = {\"output_1\": loss_xy,\n",
    "          \"output_2\": loss_wh,\n",
    "          \"output_3\":loss_objectness,\n",
    "          \"output_4\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"output_3\":[Precision(),Recall(),TrueNegatives(),TruePositives(),FalseNegatives(),FalsePositives()]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[1,4,4,1])\n",
    "os.chdir(root_path+\"/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 16, con pesos 1,4,4,1 with lr=0.0003 y usando mse para el (x,y) y usando msle de las exponenciales para (w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Modo entrenamiento\n",
      "Modo entrenamiento\n",
      "   4607/Unknown - 483s 105ms/step - loss: 29.7932 - output_1_loss: 6.6173 - output_2_loss: 0.1998 - output_3_loss: 0.0778 - output_4_loss: 22.0653 - output_3_precision_1: 0.1278 - output_3_recall_1: 0.0782 - output_3_true_negatives_1: 124137136.0000 - output_3_true_positives_1: 21031.0000 - output_3_false_negatives_1: 248075.0000 - output_3_false_positives_1: 143482.0000- 463s 105ms/step - loss: 30.3309 - output_1_loss: 6.6871 - output_2_loss: 0.2032 - output_3_loss: 0.0792 - output_4_loss: 22.5144 - output_3_precision_1: 0.1231 - output_3_recall_1: 0.0773 - output_3_true_negatives_1: 119195296.0000 - output_3_true_positives_1: 20075.0000 - output_3_false_negatives_1: 239666.00 - 468s 105ms/step - loss: 30.2460 - output_1_loss: 6.6866 - output_2_loss: 0.2028 - output_3_loss: 0.0790 - output_4_loss: 22.4319 - output_3_precision_1: 0.1246 - output_3_recall_1: 0.0776 - output_3_true_negatives_1Modo entrenamiento\n",
      "4607/4607 [==============================] - 489s 106ms/step - loss: 29.7932 - output_1_loss: 6.6173 - output_2_loss: 0.1998 - output_3_loss: 0.0778 - output_4_loss: 22.0653 - output_3_precision_1: 0.1278 - output_3_recall_1: 0.0782 - output_3_true_negatives_1: 124137136.0000 - output_3_true_positives_1: 21031.0000 - output_3_false_negatives_1: 248075.0000 - output_3_false_positives_1: 143482.0000 - val_loss: 21.6263 - val_output_1_loss: 5.4671 - val_output_2_loss: 0.1612 - val_output_3_loss: 0.0720 - val_output_4_loss: 15.2265 - val_output_3_precision_1: 0.7436 - val_output_3_recall_1: 0.0542 - val_output_3_true_negatives_1: 5058000.0000 - val_output_3_true_positives_1: 638.0000 - val_output_3_false_negatives_1: 11142.0000 - val_output_3_false_positives_1: 220.0000\n",
      "Epoch 2/20\n",
      "4607/4607 [==============================] - 490s 106ms/step - loss: 18.5350 - output_1_loss: 5.3941 - output_2_loss: 0.1368 - output_3_loss: 0.0540 - output_4_loss: 12.3776 - output_3_precision_1: 0.6557 - output_3_recall_1: 0.1249 - output_3_true_negatives_1: 124262768.0000 - output_3_true_positives_1: 33612.0000 - output_3_false_negatives_1: 235447.0000 - output_3_false_positives_1: 17651.0000 - val_loss: 20.6430 - val_output_1_loss: 5.1137 - val_output_2_loss: 0.1530 - val_output_3_loss: 0.0701 - val_output_4_loss: 14.6367 - val_output_3_precision_1: 0.8251 - val_output_3_recall_1: 0.0625 - val_output_3_true_negatives_1: 5058064.0000 - val_output_3_true_positives_1: 736.0000 - val_output_3_false_negatives_1: 11044.0000 - val_output_3_false_positives_1: 156.0000\n",
      "Epoch 3/20\n",
      "4607/4607 [==============================] - 481s 104ms/step - loss: 17.6613 - output_1_loss: 5.1160 - output_2_loss: 0.1263 - output_3_loss: 0.0519 - output_4_loss: 11.8324 - output_3_precision_1: 0.6633 - output_3_recall_1: 0.1533 - output_3_true_negatives_1: 124259272.0000 - output_3_true_positives_1: 41269.0000 - output_3_false_negatives_1: 227908.0000 - output_3_false_positives_1: 20953.0000 - val_loss: 19.7251 - val_output_1_loss: 4.8426 - val_output_2_loss: 0.1472 - val_output_3_loss: 0.0673 - val_output_4_loss: 14.0245 - val_output_3_precision_1: 0.8295 - val_output_3_recall_1: 0.0739 - val_output_3_true_negatives_1: 5058041.0000 - val_output_3_true_positives_1: 871.0000 - val_output_3_false_negatives_1: 10909.0000 - val_output_3_false_positives_1: 179.0000\n",
      "Epoch 4/20\n",
      "4607/4607 [==============================] - 474s 103ms/step - loss: 17.0226 - output_1_loss: 4.9113 - output_2_loss: 0.1208 - output_3_loss: 0.0503 - output_4_loss: 11.4267 - output_3_precision_1: 0.6708 - output_3_recall_1: 0.1741 - output_3_true_negatives_1: 124257568.0000 - output_3_true_positives_1: 46864.0000 - output_3_false_negatives_1: 222278.0000 - output_3_false_positives_1: 22994.0000 - val_loss: 18.5887 - val_output_1_loss: 4.6069 - val_output_2_loss: 0.1363 - val_output_3_loss: 0.0633 - val_output_4_loss: 13.1832 - val_output_3_precision_1: 0.8264 - val_output_3_recall_1: 0.0909 - val_output_3_true_negatives_1: 5057995.0000 - val_output_3_true_positives_1: 1071.0000 - val_output_3_false_negatives_1: 10709.0000 - val_output_3_false_positives_1: 225.0000\n",
      "Epoch 5/20\n",
      "4607/4607 [==============================] - 475s 103ms/step - loss: 16.5849 - output_1_loss: 4.8120 - output_2_loss: 0.1178 - output_3_loss: 0.0490 - output_4_loss: 11.1059 - output_3_precision_1: 0.6761 - output_3_recall_1: 0.1914 - output_3_true_negatives_1: 124255848.0000 - output_3_true_positives_1: 51514.0000 - output_3_false_negatives_1: 217638.0000 - output_3_false_positives_1: 24675.0000 - val_loss: 18.4064 - val_output_1_loss: 4.3659 - val_output_2_loss: 0.1379 - val_output_3_loss: 0.0639 - val_output_4_loss: 13.2334 - val_output_3_precision_1: 0.8290 - val_output_3_recall_1: 0.0984 - val_output_3_true_negatives_1: 5057981.0000 - val_output_3_true_positives_1: 1159.0000 - val_output_3_false_negatives_1: 10621.0000 - val_output_3_false_positives_1: 239.0000\n",
      "Epoch 6/20\n",
      "4607/4607 [==============================] - 482s 105ms/step - loss: 16.1317 - output_1_loss: 4.6635 - output_2_loss: 0.1143 - output_3_loss: 0.0479 - output_4_loss: 10.8197 - output_3_precision_1: 0.6837 - output_3_recall_1: 0.2094 - output_3_true_negatives_1: 124254512.0000 - output_3_true_positives_1: 56355.0000 - output_3_false_negatives_1: 212798.0000 - output_3_false_positives_1: 26067.0000 - val_loss: 17.6843 - val_output_1_loss: 4.1770 - val_output_2_loss: 0.1337 - val_output_3_loss: 0.0616 - val_output_4_loss: 12.7260 - val_output_3_precision_1: 0.8407 - val_output_3_recall_1: 0.1223 - val_output_3_true_negatives_1: 5057947.0000 - val_output_3_true_positives_1: 1441.0000 - val_output_3_false_negatives_1: 10339.0000 - val_output_3_false_positives_1: 273.0000\n",
      "Epoch 7/20\n",
      "4607/4607 [==============================] - 488s 106ms/step - loss: 15.7228 - output_1_loss: 4.5358 - output_2_loss: 0.1128 - output_3_loss: 0.0468 - output_4_loss: 10.5487 - output_3_precision_1: 0.6912 - output_3_recall_1: 0.2257 - output_3_true_negatives_1: 124253416.0000 - output_3_true_positives_1: 60713.0000 - output_3_false_negatives_1: 208340.0000 - output_3_false_positives_1: 27124.0000 - val_loss: 17.2873 - val_output_1_loss: 4.0303 - val_output_2_loss: 0.1282 - val_output_3_loss: 0.0610 - val_output_4_loss: 12.5001 - val_output_3_precision_1: 0.8491 - val_output_3_recall_1: 0.1251 - val_output_3_true_negatives_1: 5057958.0000 - val_output_3_true_positives_1: 1474.0000 - val_output_3_false_negatives_1: 10306.0000 - val_output_3_false_positives_1: 262.0000\n",
      "Epoch 8/20\n",
      "4607/4607 [==============================] - 490s 106ms/step - loss: 15.3790 - output_1_loss: 4.4129 - output_2_loss: 0.1111 - output_3_loss: 0.0460 - output_4_loss: 10.3379 - output_3_precision_1: 0.6948 - output_3_recall_1: 0.2382 - output_3_true_negatives_1: 124252288.0000 - output_3_true_positives_1: 64101.0000 - output_3_false_negatives_1: 205042.0000 - output_3_false_positives_1: 28152.0000 - val_loss: 16.5575 - val_output_1_loss: 3.8509 - val_output_2_loss: 0.1229 - val_output_3_loss: 0.0586 - val_output_4_loss: 11.9807 - val_output_3_precision_1: 0.8572 - val_output_3_recall_1: 0.1432 - val_output_3_true_negatives_1: 5057939.0000 - val_output_3_true_positives_1: 1687.0000 - val_output_3_false_negatives_1: 10093.0000 - val_output_3_false_positives_1: 281.0000\n",
      "Epoch 9/20\n",
      "4607/4607 [==============================] - 481s 104ms/step - loss: 14.9943 - output_1_loss: 4.2744 - output_2_loss: 0.1100 - output_3_loss: 0.0450 - output_4_loss: 10.0999 - output_3_precision_1: 0.7013 - output_3_recall_1: 0.2538 - output_3_true_negatives_1: 124251624.0000 - output_3_true_positives_1: 68312.0000 - output_3_false_negatives_1: 200834.0000 - output_3_false_positives_1: 29097.0000 - val_loss: 16.0414 - val_output_1_loss: 3.6533 - val_output_2_loss: 0.1267 - val_output_3_loss: 0.0572 - val_output_4_loss: 11.6527 - val_output_3_precision_1: 0.8624 - val_output_3_recall_1: 0.1543 - val_output_3_true_negatives_1: 5057930.0000 - val_output_3_true_positives_1: 1818.0000 - val_output_3_false_negatives_1: 9962.0000 - val_output_3_false_positives_1: 290.0000\n",
      "Epoch 10/20\n",
      "4607/4607 [==============================] - 481s 104ms/step - loss: 14.7026 - output_1_loss: 4.1823 - output_2_loss: 0.1089 - output_3_loss: 0.0442 - output_4_loss: 9.9079 - output_3_precision_1: 0.7069 - output_3_recall_1: 0.2684 - output_3_true_negatives_1: 124250496.0000 - output_3_true_positives_1: 72227.0000 - output_3_false_negatives_1: 196897.0000 - output_3_false_positives_1: 29949.0000 - val_loss: 15.7801 - val_output_1_loss: 3.6082 - val_output_2_loss: 0.1278 - val_output_3_loss: 0.0561 - val_output_4_loss: 11.4362 - val_output_3_precision_1: 0.8864 - val_output_3_recall_1: 0.1616 - val_output_3_true_negatives_1: 5057976.0000 - val_output_3_true_positives_1: 1904.0000 - val_output_3_false_negatives_1: 9876.0000 - val_output_3_false_positives_1: 244.0000\n",
      "Epoch 11/20\n",
      "4607/4607 [==============================] - 488s 106ms/step - loss: 14.4285 - output_1_loss: 4.1109 - output_2_loss: 0.1081 - output_3_loss: 0.0434 - output_4_loss: 9.7115 - output_3_precision_1: 0.7133 - output_3_recall_1: 0.2820 - output_3_true_negatives_1: 124249984.0000 - output_3_true_positives_1: 75879.0000 - output_3_false_negatives_1: 193227.0000 - output_3_false_positives_1: 30491.0000 - val_loss: 15.5579 - val_output_1_loss: 3.4420 - val_output_2_loss: 0.1242 - val_output_3_loss: 0.0566 - val_output_4_loss: 11.3928 - val_output_3_precision_1: 0.8594 - val_output_3_recall_1: 0.1884 - val_output_3_true_negatives_1: 5057857.0000 - val_output_3_true_positives_1: 2219.0000 - val_output_3_false_negatives_1: 9561.0000 - val_output_3_false_positives_1: 363.0000\n",
      "Epoch 12/20\n",
      "4607/4607 [==============================] - 475s 103ms/step - loss: 14.1089 - output_1_loss: 4.0129 - output_2_loss: 0.1070 - output_3_loss: 0.0427 - output_4_loss: 9.4972 - output_3_precision_1: 0.7206 - output_3_recall_1: 0.2986 - output_3_true_negatives_1: 124249280.0000 - output_3_true_positives_1: 80389.0000 - output_3_false_negatives_1: 188873.0000 - output_3_false_positives_1: 31168.0000 - val_loss: 14.7599 - val_output_1_loss: 3.3315 - val_output_2_loss: 0.1193 - val_output_3_loss: 0.0536 - val_output_4_loss: 10.7368 - val_output_3_precision_1: 0.8891 - val_output_3_recall_1: 0.2022 - val_output_3_true_negatives_1: 5057923.0000 - val_output_3_true_positives_1: 2382.0000 - val_output_3_false_negatives_1: 9398.0000 - val_output_3_false_positives_1: 297.0000\n",
      "Epoch 13/20\n",
      "4607/4607 [==============================] - 475s 103ms/step - loss: 13.8572 - output_1_loss: 3.9254 - output_2_loss: 0.1064 - output_3_loss: 0.0420 - output_4_loss: 9.3381 - output_3_precision_1: 0.7251 - output_3_recall_1: 0.3106 - output_3_true_negatives_1: 124248856.0000 - output_3_true_positives_1: 83582.0000 - output_3_false_negatives_1: 185551.0000 - output_3_false_positives_1: 31685.0000 - val_loss: 14.3838 - val_output_1_loss: 3.1901 - val_output_2_loss: 0.1168 - val_output_3_loss: 0.0526 - val_output_4_loss: 10.5160 - val_output_3_precision_1: 0.9017 - val_output_3_recall_1: 0.2025 - val_output_3_true_negatives_1: 5057960.0000 - val_output_3_true_positives_1: 2386.0000 - val_output_3_false_negatives_1: 9394.0000 - val_output_3_false_positives_1: 260.0000\n",
      "Epoch 14/20\n",
      "4607/4607 [==============================] - 494s 107ms/step - loss: 13.5513 - output_1_loss: 3.8326 - output_2_loss: 0.1056 - output_3_loss: 0.0412 - output_4_loss: 9.1315 - output_3_precision_1: 0.7312 - output_3_recall_1: 0.3266 - output_3_true_negatives_1: 124248152.0000 - output_3_true_positives_1: 87892.0000 - output_3_false_negatives_1: 181213.0000 - output_3_false_positives_1: 32309.0000 - val_loss: 13.9208 - val_output_1_loss: 3.0428 - val_output_2_loss: 0.1163 - val_output_3_loss: 0.0512 - val_output_4_loss: 10.2079 - val_output_3_precision_1: 0.8941 - val_output_3_recall_1: 0.2143 - val_output_3_true_negatives_1: 5057921.0000 - val_output_3_true_positives_1: 2525.0000 - val_output_3_false_negatives_1: 9255.0000 - val_output_3_false_positives_1: 299.0000\n",
      "Epoch 15/20\n",
      "4607/4607 [==============================] - 467s 101ms/step - loss: 13.3594 - output_1_loss: 3.7955 - output_2_loss: 0.1047 - output_3_loss: 0.0407 - output_4_loss: 8.9821 - output_3_precision_1: 0.7376 - output_3_recall_1: 0.3386 - output_3_true_negatives_1: 124248088.0000 - output_3_true_positives_1: 91162.0000 - output_3_false_negatives_1: 178033.0000 - output_3_false_positives_1: 32438.0000 - val_loss: 13.4454 - val_output_1_loss: 2.9334 - val_output_2_loss: 0.1133 - val_output_3_loss: 0.0496 - val_output_4_loss: 9.8603 - val_output_3_precision_1: 0.8998 - val_output_3_recall_1: 0.2424 - val_output_3_true_negatives_1: 5057902.0000 - val_output_3_true_positives_1: 2856.0000 - val_output_3_false_negatives_1: 8924.0000 - val_output_3_false_positives_1: 318.0000\n",
      "Epoch 16/20\n",
      "4607/4607 [==============================] - 470s 102ms/step - loss: 13.1579 - output_1_loss: 3.7456 - output_2_loss: 0.1051 - output_3_loss: 0.0401 - output_4_loss: 8.8315 - output_3_precision_1: 0.7449 - output_3_recall_1: 0.3519 - output_3_true_negatives_1: 124248048.0000 - output_3_true_positives_1: 94727.0000 - output_3_false_negatives_1: 174457.0000 - output_3_false_positives_1: 32432.0000 - val_loss: 13.2210 - val_output_1_loss: 2.8744 - val_output_2_loss: 0.1107 - val_output_3_loss: 0.0491 - val_output_4_loss: 9.7072 - val_output_3_precision_1: 0.9014 - val_output_3_recall_1: 0.2569 - val_output_3_true_negatives_1: 5057889.0000 - val_output_3_true_positives_1: 3026.0000 - val_output_3_false_negatives_1: 8754.0000 - val_output_3_false_positives_1: 331.0000\n",
      "Epoch 17/20\n",
      "4607/4607 [==============================] - 482s 105ms/step - loss: 12.9103 - output_1_loss: 3.6917 - output_2_loss: 0.1037 - output_3_loss: 0.0394 - output_4_loss: 8.6464 - output_3_precision_1: 0.7492 - output_3_recall_1: 0.3652 - output_3_true_negatives_1: 124247440.0000 - output_3_true_positives_1: 98291.0000 - output_3_false_negatives_1: 170829.0000 - output_3_false_positives_1: 32912.0000 - val_loss: 12.7704 - val_output_1_loss: 2.8422 - val_output_2_loss: 0.1166 - val_output_3_loss: 0.0467 - val_output_4_loss: 9.2750 - val_output_3_precision_1: 0.9184 - val_output_3_recall_1: 0.2647 - val_output_3_true_negatives_1: 5057943.0000 - val_output_3_true_positives_1: 3118.0000 - val_output_3_false_negatives_1: 8662.0000 - val_output_3_false_positives_1: 277.0000\n",
      "Epoch 18/20\n",
      "4607/4607 [==============================] - 473s 103ms/step - loss: 12.7183 - output_1_loss: 3.6376 - output_2_loss: 0.1028 - output_3_loss: 0.0388 - output_4_loss: 8.5142 - output_3_precision_1: 0.7547 - output_3_recall_1: 0.3773 - output_3_true_negatives_1: 124247456.0000 - output_3_true_positives_1: 101528.0000 - output_3_false_negatives_1: 167561.0000 - output_3_false_positives_1: 33005.0000 - val_loss: 12.4678 - val_output_1_loss: 2.7501 - val_output_2_loss: 0.1145 - val_output_3_loss: 0.0459 - val_output_4_loss: 9.0759 - val_output_3_precision_1: 0.9259 - val_output_3_recall_1: 0.2770 - val_output_3_true_negatives_1: 5057959.0000 - val_output_3_true_positives_1: 3263.0000 - val_output_3_false_negatives_1: 8517.0000 - val_output_3_false_positives_1: 261.0000\n",
      "Epoch 19/20\n",
      "4607/4607 [==============================] - 474s 103ms/step - loss: 12.5379 - output_1_loss: 3.5859 - output_2_loss: 0.1026 - output_3_loss: 0.0383 - output_4_loss: 8.3885 - output_3_precision_1: 0.7588 - output_3_recall_1: 0.3881 - output_3_true_negatives_1: 124247296.0000 - output_3_true_positives_1: 104441.0000 - output_3_false_negatives_1: 164641.0000 - output_3_false_positives_1: 33206.0000 - val_loss: 12.1963 - val_output_1_loss: 2.6604 - val_output_2_loss: 0.1087 - val_output_3_loss: 0.0456 - val_output_4_loss: 8.9187 - val_output_3_precision_1: 0.9253 - val_output_3_recall_1: 0.2893 - val_output_3_true_negatives_1: 5057945.0000 - val_output_3_true_positives_1: 3408.0000 - val_output_3_false_negatives_1: 8372.0000 - val_output_3_false_positives_1: 275.0000\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4607/4607 [==============================] - 474s 103ms/step - loss: 12.3284 - output_1_loss: 3.5342 - output_2_loss: 0.1022 - output_3_loss: 0.0377 - output_4_loss: 8.2345 - output_3_precision_1: 0.7650 - output_3_recall_1: 0.4011 - output_3_true_negatives_1: 124247432.0000 - output_3_true_positives_1: 107996.0000 - output_3_false_negatives_1: 161264.0000 - output_3_false_positives_1: 33171.0000 - val_loss: 12.1744 - val_output_1_loss: 2.6149 - val_output_2_loss: 0.1095 - val_output_3_loss: 0.0459 - val_output_4_loss: 8.9381 - val_output_3_precision_1: 0.9234 - val_output_3_recall_1: 0.2977 - val_output_3_true_negatives_1: 5057929.0000 - val_output_3_true_positives_1: 3507.0000 - val_output_3_false_negatives_1: 8273.0000 - val_output_3_false_positives_1: 291.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tf/home/sergio/Tesis/json_experiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4eea21b75a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/json_experiments\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#json.dumps(str(a))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history_finetuning_1441_20_epoch_nadam_0dot00003_mse_msle_4anchors.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tf/home/sergio/Tesis/json_experiments'"
     ]
    }
   ],
   "source": [
    "os.chdir(root_path+\"/json_experiments\")\n",
    "import json\n",
    "#json.dumps(str(a))\n",
    "with open('history_finetuning_1441_20_epoch_nadam_0dot00003_mse_msle_4anchors.json', 'w') as fp:\n",
    "    json.dump(str(history.history), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(root_path+'/weights_saved/pesos_1441_20_epoch_nadam_0dot00003_mse_msle_2anchors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1fe9f213c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors =tf.constant(np.array([[0.026,0.062],[0.067,0.183],[0.128,0.323],[0.343,0.650]]),dtype=tf.float32)\n",
    "#anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "model = TinyYOLOv3(1,anchor_boxes=anchors,train=True,mode = \"finetuning\")\n",
    "model.build(batch_input_shape=(None,416,416,3))\n",
    "#print(model.load_weights_darknet(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\"))\n",
    "model.load_weights(root_path+'/weights_saved/pesos_1441_20_epoch_nadam_0dot00003_mse_msle_2anchors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicBlock1 True\n",
      "BasicBlock2 True\n",
      "BasicBlock3 True\n",
      "BasicBlock4 True\n",
      "BasicBlock5 True\n",
      "BasicBlock6 True\n",
      "BasicBlock7 True\n",
      "BasicBlock8 True\n",
      "BasicBlock9 True\n",
      "FinalBlock1 True\n",
      "BasicBlock11 True\n",
      "BasicBlock12 True\n",
      "FinalBlock2 True\n",
      "Concatenate True\n",
      "Upsampling True\n",
      "Prediction1 True\n",
      "Prediction2 True\n",
      "Concatenate_BBOX True\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(l.name, l.trainable)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=3e-4)\n",
    "\n",
    "losses = {\"output_1\": loss_xy,\n",
    "          \"output_2\": loss_wh,\n",
    "          \"output_3\":loss_objectness,\n",
    "          \"output_4\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"output_3\":[Precision(),Recall(),TrueNegatives(),TruePositives(),FalseNegatives(),FalsePositives()]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[1,4,4,1])\n",
    "os.chdir(root_path+\"/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Modo entrenamiento\n",
      "Modo entrenamiento\n",
      "   4607/Unknown - 489s 106ms/step - loss: 12.1573 - output_1_loss: 3.4911 - output_2_loss: 0.1014 - output_3_loss: 0.0372 - output_4_loss: 8.1119 - output_3_precision: 0.7694 - output_3_recall: 0.4115 - output_3_true_negatives: 124247360.0000 - output_3_true_positives: 110759.0000 - output_3_false_negatives: 158378.0000 - output_3_false_positives: 33194.0000 395s 106ms/step - loss: 12.0418 - output_1_loss: 3.4 - 426s 106ms/s - 450s 106ms/step - loss: 12 - 467s 106ms/step - loss: 12.2169 - output_1_loss: 3.5109 - output_2_loss: 0.1020 - output_3_loss: 0.0374 - output_4_loss: 8.1485 - output_3_precision: 0.7694 - output_3_recall: 0.4115 - output_3_true_negatives: 118928 - 474s 106ms/step - loss: 12.2401 - output_1_loss: 3.5182 - output_2_loss:Modo entrenamiento\n",
      "4607/4607 [==============================] - 496s 108ms/step - loss: 12.1573 - output_1_loss: 3.4911 - output_2_loss: 0.1014 - output_3_loss: 0.0372 - output_4_loss: 8.1119 - output_3_precision: 0.7694 - output_3_recall: 0.4115 - output_3_true_negatives: 124247360.0000 - output_3_true_positives: 110759.0000 - output_3_false_negatives: 158378.0000 - output_3_false_positives: 33194.0000 - val_loss: 11.8187 - val_output_1_loss: 2.5095 - val_output_2_loss: 0.1096 - val_output_3_loss: 0.0442 - val_output_4_loss: 8.6939 - val_output_3_precision: 0.9259 - val_output_3_recall: 0.3035 - val_output_3_true_negatives: 5057934.0000 - val_output_3_true_positives: 3575.0000 - val_output_3_false_negatives: 8205.0000 - val_output_3_false_positives: 286.0000\n",
      "Epoch 2/20\n",
      "4607/4607 [==============================] - 485s 105ms/step - loss: 11.9871 - output_1_loss: 3.4586 - output_2_loss: 0.1008 - output_3_loss: 0.0365 - output_4_loss: 7.9789 - output_3_precision: 0.7718 - output_3_recall: 0.4215 - output_3_true_negatives: 124246904.0000 - output_3_true_positives: 113420.0000 - output_3_false_negatives: 155676.0000 - output_3_false_positives: 33538.0000 - val_loss: 11.3990 - val_output_1_loss: 2.5202 - val_output_2_loss: 0.1103 - val_output_3_loss: 0.0424 - val_output_4_loss: 8.2681 - val_output_3_precision: 0.9248 - val_output_3_recall: 0.3435 - val_output_3_true_negatives: 5057891.0000 - val_output_3_true_positives: 4047.0000 - val_output_3_false_negatives: 7733.0000 - val_output_3_false_positives: 329.0000\n",
      "Epoch 3/20\n",
      "4607/4607 [==============================] - 488s 106ms/step - loss: 11.8285 - output_1_loss: 3.4205 - output_2_loss: 0.1009 - output_3_loss: 0.0360 - output_4_loss: 7.8601 - output_3_precision: 0.7775 - output_3_recall: 0.4319 - output_3_true_negatives: 124247288.0000 - output_3_true_positives: 116264.0000 - output_3_false_negatives: 152911.0000 - output_3_false_positives: 33264.0000 - val_loss: 11.1199 - val_output_1_loss: 2.4186 - val_output_2_loss: 0.1084 - val_output_3_loss: 0.0418 - val_output_4_loss: 8.1006 - val_output_3_precision: 0.9433 - val_output_3_recall: 0.3392 - val_output_3_true_negatives: 5057980.0000 - val_output_3_true_positives: 3996.0000 - val_output_3_false_negatives: 7784.0000 - val_output_3_false_positives: 240.0000\n",
      "Epoch 4/20\n",
      "4607/4607 [==============================] - 492s 107ms/step - loss: 11.7242 - output_1_loss: 3.3935 - output_2_loss: 0.1001 - output_3_loss: 0.0358 - output_4_loss: 7.7872 - output_3_precision: 0.7833 - output_3_recall: 0.4394 - output_3_true_negatives: 124247888.0000 - output_3_true_positives: 118284.0000 - output_3_false_negatives: 150886.0000 - output_3_false_positives: 32724.0000 - val_loss: 10.5081 - val_output_1_loss: 2.3615 - val_output_2_loss: 0.1053 - val_output_3_loss: 0.0393 - val_output_4_loss: 7.5681 - val_output_3_precision: 0.9356 - val_output_3_recall: 0.3784 - val_output_3_true_negatives: 5057913.0000 - val_output_3_true_positives: 4458.0000 - val_output_3_false_negatives: 7322.0000 - val_output_3_false_positives: 307.0000\n",
      "Epoch 5/20\n",
      "4607/4607 [==============================] - 487s 106ms/step - loss: 11.5570 - output_1_loss: 3.3352 - output_2_loss: 0.0999 - output_3_loss: 0.0353 - output_4_loss: 7.6807 - output_3_precision: 0.7836 - output_3_recall: 0.4481 - output_3_true_negatives: 124247024.0000 - output_3_true_positives: 120617.0000 - output_3_false_negatives: 148533.0000 - output_3_false_positives: 33319.0000 - val_loss: 10.4952 - val_output_1_loss: 2.3060 - val_output_2_loss: 0.1097 - val_output_3_loss: 0.0391 - val_output_4_loss: 7.5937 - val_output_3_precision: 0.9352 - val_output_3_recall: 0.3689 - val_output_3_true_negatives: 5057919.0000 - val_output_3_true_positives: 4346.0000 - val_output_3_false_negatives: 7434.0000 - val_output_3_false_positives: 301.0000\n",
      "Epoch 6/20\n",
      "4607/4607 [==============================] - 485s 105ms/step - loss: 11.4451 - output_1_loss: 3.3046 - output_2_loss: 0.0996 - output_3_loss: 0.0350 - output_4_loss: 7.6019 - output_3_precision: 0.7887 - output_3_recall: 0.4556 - output_3_true_negatives: 124247696.0000 - output_3_true_positives: 122631.0000 - output_3_false_negatives: 146545.0000 - output_3_false_positives: 32850.0000 - val_loss: 10.7493 - val_output_1_loss: 2.3284 - val_output_2_loss: 0.1098 - val_output_3_loss: 0.0407 - val_output_4_loss: 7.8188 - val_output_3_precision: 0.9330 - val_output_3_recall: 0.3650 - val_output_3_true_negatives: 5057911.0000 - val_output_3_true_positives: 4300.0000 - val_output_3_false_negatives: 7480.0000 - val_output_3_false_positives: 309.0000\n",
      "Epoch 7/20\n",
      "4607/4607 [==============================] - 486s 105ms/step - loss: 11.3351 - output_1_loss: 3.2932 - output_2_loss: 0.0990 - output_3_loss: 0.0345 - output_4_loss: 7.5075 - output_3_precision: 0.7904 - output_3_recall: 0.4640 - output_3_true_negatives: 124247376.0000 - output_3_true_positives: 124856.0000 - output_3_false_negatives: 144228.0000 - output_3_false_positives: 33112.0000 - val_loss: 10.4471 - val_output_1_loss: 2.2247 - val_output_2_loss: 0.1049 - val_output_3_loss: 0.0396 - val_output_4_loss: 7.6443 - val_output_3_precision: 0.9438 - val_output_3_recall: 0.3665 - val_output_3_true_negatives: 5057963.0000 - val_output_3_true_positives: 4317.0000 - val_output_3_false_negatives: 7463.0000 - val_output_3_false_positives: 257.0000\n",
      "Epoch 8/20\n",
      "4607/4607 [==============================] - 485s 105ms/step - loss: 11.1692 - output_1_loss: 3.2444 - output_2_loss: 0.0988 - output_3_loss: 0.0341 - output_4_loss: 7.3934 - output_3_precision: 0.7958 - output_3_recall: 0.4722 - output_3_true_negatives: 124247768.0000 - output_3_true_positives: 127097.0000 - output_3_false_negatives: 142088.0000 - output_3_false_positives: 32619.0000 - val_loss: 9.9896 - val_output_1_loss: 2.1985 - val_output_2_loss: 0.1046 - val_output_3_loss: 0.0378 - val_output_4_loss: 7.2212 - val_output_3_precision: 0.9386 - val_output_3_recall: 0.4139 - val_output_3_true_negatives: 5057901.0000 - val_output_3_true_positives: 4876.0000 - val_output_3_false_negatives: 6904.0000 - val_output_3_false_positives: 319.0000\n",
      "Epoch 9/20\n",
      "4607/4607 [==============================] - 492s 107ms/step - loss: 11.1431 - output_1_loss: 3.2463 - output_2_loss: 0.0982 - output_3_loss: 0.0341 - output_4_loss: 7.3676 - output_3_precision: 0.7968 - output_3_recall: 0.4766 - output_3_true_negatives: 124247760.0000 - output_3_true_positives: 128259.0000 - output_3_false_negatives: 140853.0000 - output_3_false_positives: 32707.0000 - val_loss: 10.2081 - val_output_1_loss: 2.2198 - val_output_2_loss: 0.1016 - val_output_3_loss: 0.0392 - val_output_4_loss: 7.4251 - val_output_3_precision: 0.9371 - val_output_3_recall: 0.4132 - val_output_3_true_negatives: 5057893.0000 - val_output_3_true_positives: 4868.0000 - val_output_3_false_negatives: 6912.0000 - val_output_3_false_positives: 327.0000\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4607/4607 [==============================] - 492s 107ms/step - loss: 10.9832 - output_1_loss: 3.2072 - output_2_loss: 0.0985 - output_3_loss: 0.0336 - output_4_loss: 7.2477 - output_3_precision: 0.8005 - output_3_recall: 0.4869 - output_3_true_negatives: 124247728.0000 - output_3_true_positives: 131046.0000 - output_3_false_negatives: 138118.0000 - output_3_false_positives: 32655.0000 - val_loss: 9.7736 - val_output_1_loss: 2.1687 - val_output_2_loss: 0.1012 - val_output_3_loss: 0.0370 - val_output_4_loss: 7.0522 - val_output_3_precision: 0.9550 - val_output_3_recall: 0.3995 - val_output_3_true_negatives: 5057998.0000 - val_output_3_true_positives: 4706.0000 - val_output_3_false_negatives: 7074.0000 - val_output_3_false_positives: 222.0000\n",
      "Epoch 11/20\n",
      "4607/4607 [==============================] - 483s 105ms/step - loss: 10.8880 - output_1_loss: 3.1887 - output_2_loss: 0.0979 - output_3_loss: 0.0332 - output_4_loss: 7.1751 - output_3_precision: 0.8037 - output_3_recall: 0.4916 - output_3_true_negatives: 124248248.0000 - output_3_true_positives: 132309.0000 - output_3_false_negatives: 136834.0000 - output_3_false_positives: 32324.0000 - val_loss: 9.5705 - val_output_1_loss: 2.1206 - val_output_2_loss: 0.1041 - val_output_3_loss: 0.0365 - val_output_4_loss: 6.8873 - val_output_3_precision: 0.9552 - val_output_3_recall: 0.4269 - val_output_3_true_negatives: 5057984.0000 - val_output_3_true_positives: 5029.0000 - val_output_3_false_negatives: 6751.0000 - val_output_3_false_positives: 236.0000\n",
      "Epoch 12/20\n",
      "4607/4607 [==============================] - 486s 106ms/step - loss: 10.8605 - output_1_loss: 3.1848 - output_2_loss: 0.0981 - output_3_loss: 0.0331 - output_4_loss: 7.1513 - output_3_precision: 0.8053 - output_3_recall: 0.4947 - output_3_true_negatives: 124248448.0000 - output_3_true_positives: 133108.0000 - output_3_false_negatives: 135957.0000 - output_3_false_positives: 32183.0000 - val_loss: 9.3808 - val_output_1_loss: 2.0494 - val_output_2_loss: 0.1039 - val_output_3_loss: 0.0354 - val_output_4_loss: 6.7741 - val_output_3_precision: 0.9446 - val_output_3_recall: 0.4425 - val_output_3_true_negatives: 5057914.0000 - val_output_3_true_positives: 5213.0000 - val_output_3_false_negatives: 6567.0000 - val_output_3_false_positives: 306.0000\n",
      "Epoch 13/20\n",
      "4607/4607 [==============================] - 492s 107ms/step - loss: 10.6646 - output_1_loss: 3.1258 - output_2_loss: 0.0973 - output_3_loss: 0.0325 - output_4_loss: 7.0194 - output_3_precision: 0.8099 - output_3_recall: 0.5054 - output_3_true_negatives: 124248640.0000 - output_3_true_positives: 136031.0000 - output_3_false_negatives: 133136.0000 - output_3_false_positives: 31929.0000 - val_loss: 9.1031 - val_output_1_loss: 1.9988 - val_output_2_loss: 0.0994 - val_output_3_loss: 0.0344 - val_output_4_loss: 6.5694 - val_output_3_precision: 0.9565 - val_output_3_recall: 0.4382 - val_output_3_true_negatives: 5057985.0000 - val_output_3_true_positives: 5162.0000 - val_output_3_false_negatives: 6618.0000 - val_output_3_false_positives: 235.0000\n",
      "Epoch 14/20\n",
      "4607/4607 [==============================] - 498s 108ms/step - loss: 10.5717 - output_1_loss: 3.0984 - output_2_loss: 0.0972 - output_3_loss: 0.0322 - output_4_loss: 6.9560 - output_3_precision: 0.8124 - output_3_recall: 0.5120 - output_3_true_negatives: 124248760.0000 - output_3_true_positives: 137807.0000 - output_3_false_negatives: 131343.0000 - output_3_false_positives: 31820.0000 - val_loss: 8.9326 - val_output_1_loss: 1.9620 - val_output_2_loss: 0.1003 - val_output_3_loss: 0.0339 - val_output_4_loss: 6.4339 - val_output_3_precision: 0.9489 - val_output_3_recall: 0.4560 - val_output_3_true_negatives: 5057931.0000 - val_output_3_true_positives: 5372.0000 - val_output_3_false_negatives: 6408.0000 - val_output_3_false_positives: 289.0000\n",
      "Epoch 15/20\n",
      "4607/4607 [==============================] - 488s 106ms/step - loss: 10.4407 - output_1_loss: 3.0806 - output_2_loss: 0.0958 - output_3_loss: 0.0317 - output_4_loss: 6.8502 - output_3_precision: 0.8154 - output_3_recall: 0.5191 - output_3_true_negatives: 124248936.0000 - output_3_true_positives: 139676.0000 - output_3_false_negatives: 129407.0000 - output_3_false_positives: 31616.0000 - val_loss: 8.9074 - val_output_1_loss: 1.9528 - val_output_2_loss: 0.0995 - val_output_3_loss: 0.0339 - val_output_4_loss: 6.4209 - val_output_3_precision: 0.9529 - val_output_3_recall: 0.4619 - val_output_3_true_negatives: 5057951.0000 - val_output_3_true_positives: 5441.0000 - val_output_3_false_negatives: 6339.0000 - val_output_3_false_positives: 269.0000\n",
      "Epoch 16/20\n",
      "4607/4607 [==============================] - 483s 105ms/step - loss: 10.4338 - output_1_loss: 3.0618 - output_2_loss: 0.0964 - output_3_loss: 0.0317 - output_4_loss: 6.8598 - output_3_precision: 0.8164 - output_3_recall: 0.5204 - output_3_true_negatives: 124248960.0000 - output_3_true_positives: 140033.0000 - output_3_false_negatives: 129079.0000 - output_3_false_positives: 31495.0000 - val_loss: 8.8306 - val_output_1_loss: 1.9468 - val_output_2_loss: 0.0997 - val_output_3_loss: 0.0337 - val_output_4_loss: 6.3502 - val_output_3_precision: 0.9601 - val_output_3_recall: 0.4598 - val_output_3_true_negatives: 5057995.0000 - val_output_3_true_positives: 5417.0000 - val_output_3_false_negatives: 6363.0000 - val_output_3_false_positives: 225.0000\n",
      "Epoch 17/20\n",
      "4607/4607 [==============================] - 473s 103ms/step - loss: 10.3608 - output_1_loss: 3.0513 - output_2_loss: 0.0956 - output_3_loss: 0.0314 - output_4_loss: 6.8012 - output_3_precision: 0.8183 - output_3_recall: 0.5241 - output_3_true_negatives: 124249200.0000 - output_3_true_positives: 141016.0000 - output_3_false_negatives: 128027.0000 - output_3_false_positives: 31310.0000 - val_loss: 8.5818 - val_output_1_loss: 1.8927 - val_output_2_loss: 0.0987 - val_output_3_loss: 0.0329 - val_output_4_loss: 6.1627 - val_output_3_precision: 0.9626 - val_output_3_recall: 0.4695 - val_output_3_true_negatives: 5058005.0000 - val_output_3_true_positives: 5531.0000 - val_output_3_false_negatives: 6249.0000 - val_output_3_false_positives: 215.0000\n",
      "Epoch 18/20\n",
      "4607/4607 [==============================] - 483s 105ms/step - loss: 10.2766 - output_1_loss: 3.0420 - output_2_loss: 0.0956 - output_3_loss: 0.0312 - output_4_loss: 6.7274 - output_3_precision: 0.8211 - output_3_recall: 0.5314 - output_3_true_negatives: 124249728.0000 - output_3_true_positives: 142990.0000 - output_3_false_negatives: 126088.0000 - output_3_false_positives: 31148.0000 - val_loss: 8.7115 - val_output_1_loss: 1.9132 - val_output_2_loss: 0.1032 - val_output_3_loss: 0.0330 - val_output_4_loss: 6.2532 - val_output_3_precision: 0.9621 - val_output_3_recall: 0.4656 - val_output_3_true_negatives: 5058004.0000 - val_output_3_true_positives: 5485.0000 - val_output_3_false_negatives: 6295.0000 - val_output_3_false_positives: 216.0000\n",
      "Epoch 19/20\n",
      "4607/4607 [==============================] - 481s 104ms/step - loss: 10.1878 - output_1_loss: 3.0186 - output_2_loss: 0.0952 - output_3_loss: 0.0308 - output_4_loss: 6.6651 - output_3_precision: 0.8219 - output_3_recall: 0.5360 - output_3_true_negatives: 124249408.0000 - output_3_true_positives: 144247.0000 - output_3_false_negatives: 124873.0000 - output_3_false_positives: 31256.0000 - val_loss: 8.1820 - val_output_1_loss: 1.7915 - val_output_2_loss: 0.0981 - val_output_3_loss: 0.0312 - val_output_4_loss: 5.8734 - val_output_3_precision: 0.9642 - val_output_3_recall: 0.4866 - val_output_3_true_negatives: 5058007.0000 - val_output_3_true_positives: 5732.0000 - val_output_3_false_negatives: 6048.0000 - val_output_3_false_positives: 213.0000\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4607/4607 [==============================] - 482s 105ms/step - loss: 10.1292 - output_1_loss: 3.0134 - output_2_loss: 0.0950 - output_3_loss: 0.0306 - output_4_loss: 6.6136 - output_3_precision: 0.8255 - output_3_recall: 0.5398 - output_3_true_negatives: 124249880.0000 - output_3_true_positives: 145205.0000 - output_3_false_negatives: 123788.0000 - output_3_false_positives: 30701.0000 - val_loss: 8.3731 - val_output_1_loss: 1.8675 - val_output_2_loss: 0.0955 - val_output_3_loss: 0.0323 - val_output_4_loss: 5.9944 - val_output_3_precision: 0.9687 - val_output_3_recall: 0.4838 - val_output_3_true_negatives: 5058036.0000 - val_output_3_true_positives: 5699.0000 - val_output_3_false_negatives: 6081.0000 - val_output_3_false_positives: 184.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/sergio/Documents/json_experiments\")\n",
    "import json\n",
    "#json.dumps(str(a))\n",
    "with open('history_finetuning_1241_20_30_epoch_nadam_0dot00001_msle_exp_mse_3anchors.json', 'w') as fp:\n",
    "    json.dump(str(history.history), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(root_path+'/weights_saved/pesos_1441_20_30_epoch_nadam_0dot00003_mse_msle_2anchors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de 30 a 50 epocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f88b5d6fb00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "model = TinyYOLOv3(1,anchor_boxes=anchors,train=True,mode = \"finetuning\")\n",
    "model.build(batch_input_shape=(None,416,416,3))\n",
    "#print(model.load_weights_darknet(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\"))\n",
    "model.load_weights('/home/sergio/Documents/weights_saved/pesos_1241_20_30_epoch_nadam_0dot00001_msle_exp_mse_3anchors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicBlock1 True\n",
      "BasicBlock2 True\n",
      "BasicBlock3 True\n",
      "BasicBlock4 True\n",
      "BasicBlock5 True\n",
      "BasicBlock6 True\n",
      "BasicBlock7 True\n",
      "BasicBlock8 True\n",
      "BasicBlock9 True\n",
      "FinalBlock1 True\n",
      "BasicBlock11 True\n",
      "BasicBlock12 True\n",
      "FinalBlock2 True\n",
      "Concatenate True\n",
      "Upsampling True\n",
      "Prediction1 True\n",
      "Prediction2 True\n",
      "Concatenate_BBOX True\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(l.name, l.trainable)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=1e-4)\n",
    "\n",
    "losses = {\"output_1\": loss_xy,\n",
    "          \"output_2\": loss_wh,\n",
    "          \"output_3\":loss_objectness,\n",
    "          \"output_4\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"output_3\":[Precision(),Recall(),TrueNegatives(),TruePositives(),FalseNegatives(),FalsePositives()]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[1,2,4,1])\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   4607/Unknown - 588s 128ms/step - loss: 8.6157 - output_1_loss: 1.6266e-05 - output_2_loss: 0.3948 - output_3_loss: 0.0241 - output_4_loss: 7.7298 - output_3_precision: 0.8020 - output_3_recall: 0.4624 - output_3_true_negatives: 186523600.0000 - output_3_true_positives: 124918.0000 - output_3_false_negatives: 145254.0000 - output_3_false_positives: 30843.0000Modo entrenamiento\n",
      "4607/4607 [==============================] - 596s 129ms/step - loss: 8.6157 - output_1_loss: 1.6266e-05 - output_2_loss: 0.3948 - output_3_loss: 0.0241 - output_4_loss: 7.7298 - output_3_precision: 0.8020 - output_3_recall: 0.4624 - output_3_true_negatives: 186523600.0000 - output_3_true_positives: 124918.0000 - output_3_false_negatives: 145254.0000 - output_3_false_positives: 30843.0000 - val_loss: 5.5058 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.3041 - val_output_3_loss: 0.0166 - val_output_4_loss: 4.8310 - val_output_3_precision: 0.8610 - val_output_3_recall: 0.6684 - val_output_3_true_negatives: 7591900.0000 - val_output_3_true_positives: 7903.0000 - val_output_3_false_negatives: 3921.0000 - val_output_3_false_positives: 1276.0000\n",
      "Epoch 2/20\n",
      "4607/4607 [==============================] - 596s 129ms/step - loss: 8.5305 - output_1_loss: 1.0788e-06 - output_2_loss: 0.4010 - output_3_loss: 0.0238 - output_4_loss: 7.6333 - output_3_precision: 0.8053 - output_3_recall: 0.4698 - output_3_true_negatives: 186523072.0000 - output_3_true_positives: 126953.0000 - output_3_false_negatives: 143272.0000 - output_3_false_positives: 30696.0000 - val_loss: 5.5190 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.3086 - val_output_3_loss: 0.0165 - val_output_4_loss: 4.8358 - val_output_3_precision: 0.8774 - val_output_3_recall: 0.6584 - val_output_3_true_negatives: 7592088.0000 - val_output_3_true_positives: 7785.0000 - val_output_3_false_negatives: 4039.0000 - val_output_3_false_positives: 1088.0000\n",
      "Epoch 3/20\n",
      "4607/4607 [==============================] - 599s 130ms/step - loss: 8.4763 - output_1_loss: 3.3334e-07 - output_2_loss: 0.3978 - output_3_loss: 0.0236 - output_4_loss: 7.5864 - output_3_precision: 0.8076 - output_3_recall: 0.4753 - output_3_true_negatives: 186523392.0000 - output_3_true_positives: 128455.0000 - output_3_false_negatives: 141780.0000 - output_3_false_positives: 30610.0000 - val_loss: 5.2362 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.3008 - val_output_3_loss: 0.0157 - val_output_4_loss: 4.5721 - val_output_3_precision: 0.8737 - val_output_3_recall: 0.6872 - val_output_3_true_negatives: 7592001.0000 - val_output_3_true_positives: 8125.0000 - val_output_3_false_negatives: 3699.0000 - val_output_3_false_positives: 1175.0000\n",
      "Epoch 4/20\n",
      "4607/4607 [==============================] - 533s 116ms/step - loss: 8.4187 - output_1_loss: 1.3046e-06 - output_2_loss: 0.4121 - output_3_loss: 0.0234 - output_4_loss: 7.5007 - output_3_precision: 0.8098 - output_3_recall: 0.4820 - output_3_true_negatives: 186523744.0000 - output_3_true_positives: 130200.0000 - output_3_false_negatives: 139929.0000 - output_3_false_positives: 30590.0000 - val_loss: 5.2741 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.3064 - val_output_3_loss: 0.0158 - val_output_4_loss: 4.5980 - val_output_3_precision: 0.8809 - val_output_3_recall: 0.6733 - val_output_3_true_negatives: 7592100.0000 - val_output_3_true_positives: 7961.0000 - val_output_3_false_negatives: 3863.0000 - val_output_3_false_positives: 1076.0000\n",
      "Epoch 5/20\n",
      "4607/4607 [==============================] - 538s 117ms/step - loss: 8.2911 - output_1_loss: 4.2752e-07 - output_2_loss: 0.3965 - output_3_loss: 0.0231 - output_4_loss: 7.4054 - output_3_precision: 0.8125 - output_3_recall: 0.4901 - output_3_true_negatives: 186523840.0000 - output_3_true_positives: 132445.0000 - output_3_false_negatives: 137803.0000 - output_3_false_positives: 30574.0000 - val_loss: 5.0926 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2977 - val_output_3_loss: 0.0154 - val_output_4_loss: 4.4358 - val_output_3_precision: 0.8813 - val_output_3_recall: 0.6905 - val_output_3_true_negatives: 7592076.0000 - val_output_3_true_positives: 8164.0000 - val_output_3_false_negatives: 3660.0000 - val_output_3_false_positives: 1100.0000\n",
      "Epoch 6/20\n",
      "4607/4607 [==============================] - 544s 118ms/step - loss: 8.2258 - output_1_loss: 6.9685e-06 - output_2_loss: 0.3844 - output_3_loss: 0.0230 - output_4_loss: 7.3650 - output_3_precision: 0.8154 - output_3_recall: 0.4937 - output_3_true_negatives: 186524080.0000 - output_3_true_positives: 133383.0000 - output_3_false_negatives: 136786.0000 - output_3_false_positives: 30200.0000 - val_loss: 4.9042 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2963 - val_output_3_loss: 0.0146 - val_output_4_loss: 4.2529 - val_output_3_precision: 0.8788 - val_output_3_recall: 0.7128 - val_output_3_true_negatives: 7592014.0000 - val_output_3_true_positives: 8428.0000 - val_output_3_false_negatives: 3396.0000 - val_output_3_false_positives: 1162.0000\n",
      "Epoch 7/20\n",
      "4607/4607 [==============================] - 571s 124ms/step - loss: 8.1567 - output_1_loss: 9.9326e-07 - output_2_loss: 0.3885 - output_3_loss: 0.0228 - output_4_loss: 7.2883 - output_3_precision: 0.8178 - output_3_recall: 0.5016 - output_3_true_negatives: 186523648.0000 - output_3_true_positives: 135568.0000 - output_3_false_negatives: 134687.0000 - output_3_false_positives: 30194.0000 - val_loss: 4.9668 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2880 - val_output_3_loss: 0.0148 - val_output_4_loss: 4.3315 - val_output_3_precision: 0.8775 - val_output_3_recall: 0.7086 - val_output_3_true_negatives: 7592006.0000 - val_output_3_true_positives: 8378.0000 - val_output_3_false_negatives: 3446.0000 - val_output_3_false_positives: 1170.0000\n",
      "Epoch 8/20\n",
      "4607/4607 [==============================] - 574s 125ms/step - loss: 8.0570 - output_1_loss: 2.9247e-07 - output_2_loss: 0.3805 - output_3_loss: 0.0226 - output_4_loss: 7.2057 - output_3_precision: 0.8197 - output_3_recall: 0.5072 - output_3_true_negatives: 186523584.0000 - output_3_true_positives: 137099.0000 - output_3_false_negatives: 133198.0000 - output_3_false_positives: 30153.0000 - val_loss: 4.7874 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2927 - val_output_3_loss: 0.0144 - val_output_4_loss: 4.1444 - val_output_3_precision: 0.8873 - val_output_3_recall: 0.7130 - val_output_3_true_negatives: 7592105.0000 - val_output_3_true_positives: 8430.0000 - val_output_3_false_negatives: 3394.0000 - val_output_3_false_positives: 1071.0000\n",
      "Epoch 9/20\n",
      "4607/4607 [==============================] - 574s 125ms/step - loss: 7.9190 - output_1_loss: 1.1952e-06 - output_2_loss: 0.3653 - output_3_loss: 0.0222 - output_4_loss: 7.0995 - output_3_precision: 0.8241 - output_3_recall: 0.5170 - output_3_true_negatives: 186524528.0000 - output_3_true_positives: 139676.0000 - output_3_false_negatives: 130513.0000 - output_3_false_positives: 29820.0000 - val_loss: 4.5983 - val_output_1_loss: 1.5582e-05 - val_output_2_loss: 0.2816 - val_output_3_loss: 0.0138 - val_output_4_loss: 3.9800 - val_output_3_precision: 0.8817 - val_output_3_recall: 0.7427 - val_output_3_true_negatives: 7591998.0000 - val_output_3_true_positives: 8782.0000 - val_output_3_false_negatives: 3042.0000 - val_output_3_false_positives: 1178.0000\n",
      "Epoch 10/20\n",
      "4607/4607 [==============================] - 572s 124ms/step - loss: 7.9145 - output_1_loss: 4.5090e-06 - output_2_loss: 0.3736 - output_3_loss: 0.0222 - output_4_loss: 7.0787 - output_3_precision: 0.8245 - output_3_recall: 0.5193 - output_3_true_negatives: 186524080.0000 - output_3_true_positives: 140375.0000 - output_3_false_negatives: 129952.0000 - output_3_false_positives: 29878.0000 - val_loss: 4.5140 - val_output_1_loss: 4.0500e-06 - val_output_2_loss: 0.2882 - val_output_3_loss: 0.0134 - val_output_4_loss: 3.8840 - val_output_3_precision: 0.8892 - val_output_3_recall: 0.7400 - val_output_3_true_negatives: 7592086.0000 - val_output_3_true_positives: 8750.0000 - val_output_3_false_negatives: 3074.0000 - val_output_3_false_positives: 1090.0000\n",
      "Epoch 11/20\n",
      "4607/4607 [==============================] - 556s 121ms/step - loss: 7.8864 - output_1_loss: 6.9715e-06 - output_2_loss: 0.3891 - output_3_loss: 0.0219 - output_4_loss: 7.0207 - output_3_precision: 0.8279 - output_3_recall: 0.5232 - output_3_true_negatives: 186524640.0000 - output_3_true_positives: 141362.0000 - output_3_false_negatives: 128850.0000 - output_3_false_positives: 29384.0000 - val_loss: 4.5995 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2874 - val_output_3_loss: 0.0136 - val_output_4_loss: 3.9700 - val_output_3_precision: 0.8659 - val_output_3_recall: 0.7740 - val_output_3_true_negatives: 7591759.0000 - val_output_3_true_positives: 9152.0000 - val_output_3_false_negatives: 2672.0000 - val_output_3_false_positives: 1417.0000\n",
      "Epoch 12/20\n",
      "4607/4607 [==============================] - 507s 110ms/step - loss: 7.8653 - output_1_loss: 2.2719e-06 - output_2_loss: 0.3872 - output_3_loss: 0.0219 - output_4_loss: 7.0032 - output_3_precision: 0.8290 - output_3_recall: 0.5265 - output_3_true_negatives: 186525024.0000 - output_3_true_positives: 142276.0000 - output_3_false_negatives: 127934.0000 - output_3_false_positives: 29349.0000 - val_loss: 4.5534 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2850 - val_output_3_loss: 0.0134 - val_output_4_loss: 3.9298 - val_output_3_precision: 0.8902 - val_output_3_recall: 0.7373 - val_output_3_true_negatives: 7592101.0000 - val_output_3_true_positives: 8718.0000 - val_output_3_false_negatives: 3106.0000 - val_output_3_false_positives: 1075.0000\n",
      "Epoch 13/20\n",
      "4607/4607 [==============================] - 479s 104ms/step - loss: 7.7174 - output_1_loss: 3.7928e-06 - output_2_loss: 0.3726 - output_3_loss: 0.0215 - output_4_loss: 6.8862 - output_3_precision: 0.8315 - output_3_recall: 0.5354 - output_3_true_negatives: 186524816.0000 - output_3_true_positives: 144661.0000 - output_3_false_negatives: 125521.0000 - output_3_false_positives: 29323.0000 - val_loss: 4.2517 - val_output_1_loss: 1.3586e-06 - val_output_2_loss: 0.2859 - val_output_3_loss: 0.0125 - val_output_4_loss: 3.6299 - val_output_3_precision: 0.8990 - val_output_3_recall: 0.7640 - val_output_3_true_negatives: 7592161.0000 - val_output_3_true_positives: 9033.0000 - val_output_3_false_negatives: 2791.0000 - val_output_3_false_positives: 1015.0000\n",
      "Epoch 14/20\n",
      "4607/4607 [==============================] - 571s 124ms/step - loss: 7.6764 - output_1_loss: 2.8239e-06 - output_2_loss: 0.3726 - output_3_loss: 0.0213 - output_4_loss: 6.8458 - output_3_precision: 0.8341 - output_3_recall: 0.5380 - output_3_true_negatives: 186525152.0000 - output_3_true_positives: 145387.0000 - output_3_false_negatives: 124853.0000 - output_3_false_positives: 28922.0000 - val_loss: 4.1360 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2756 - val_output_3_loss: 0.0122 - val_output_4_loss: 3.5358 - val_output_3_precision: 0.8935 - val_output_3_recall: 0.7815 - val_output_3_true_negatives: 7592074.0000 - val_output_3_true_positives: 9241.0000 - val_output_3_false_negatives: 2583.0000 - val_output_3_false_positives: 1102.0000\n",
      "Epoch 15/20\n",
      "4607/4607 [==============================] - 590s 128ms/step - loss: 7.5933 - output_1_loss: 1.0039e-05 - output_2_loss: 0.3655 - output_3_loss: 0.0212 - output_4_loss: 6.7777 - output_3_precision: 0.8362 - output_3_recall: 0.5454 - output_3_true_negatives: 186525248.0000 - output_3_true_positives: 147374.0000 - output_3_false_negatives: 122833.0000 - output_3_false_positives: 28870.0000 - val_loss: 4.1303 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2762 - val_output_3_loss: 0.0122 - val_output_4_loss: 3.5293 - val_output_3_precision: 0.8965 - val_output_3_recall: 0.7776 - val_output_3_true_negatives: 7592115.0000 - val_output_3_true_positives: 9194.0000 - val_output_3_false_negatives: 2630.0000 - val_output_3_false_positives: 1061.0000\n",
      "Epoch 16/20\n",
      "4607/4607 [==============================] - 578s 125ms/step - loss: 7.5998 - output_1_loss: 1.1943e-05 - output_2_loss: 0.3707 - output_3_loss: 0.0211 - output_4_loss: 6.7742 - output_3_precision: 0.8384 - output_3_recall: 0.5459 - output_3_true_negatives: 186525344.0000 - output_3_true_positives: 147542.0000 - output_3_false_negatives: 122732.0000 - output_3_false_positives: 28431.0000 - val_loss: 4.0435 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2762 - val_output_3_loss: 0.0120 - val_output_4_loss: 3.4433 - val_output_3_precision: 0.8938 - val_output_3_recall: 0.7932 - val_output_3_true_negatives: 7592062.0000 - val_output_3_true_positives: 9379.0000 - val_output_3_false_negatives: 2445.0000 - val_output_3_false_positives: 1114.0000\n",
      "Epoch 17/20\n",
      "4607/4607 [==============================] - 582s 126ms/step - loss: 7.5935 - output_1_loss: 8.1900e-08 - output_2_loss: 0.3758 - output_3_loss: 0.0210 - output_4_loss: 6.7578 - output_3_precision: 0.8378 - output_3_recall: 0.5468 - output_3_true_negatives: 186525792.0000 - output_3_true_positives: 147737.0000 - output_3_false_negatives: 122450.0000 - output_3_false_positives: 28601.0000 - val_loss: 4.9642 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.3059 - val_output_3_loss: 0.0144 - val_output_4_loss: 4.2946 - val_output_3_precision: 0.8586 - val_output_3_recall: 0.7258 - val_output_3_true_negatives: 7591763.0000 - val_output_3_true_positives: 8582.0000 - val_output_3_false_negatives: 3242.0000 - val_output_3_false_positives: 1413.0000\n",
      "Epoch 18/20\n",
      "4607/4607 [==============================] - 631s 137ms/step - loss: 7.5037 - output_1_loss: 4.7386e-07 - output_2_loss: 0.3703 - output_3_loss: 0.0208 - output_4_loss: 6.6800 - output_3_precision: 0.8407 - output_3_recall: 0.5530 - output_3_true_negatives: 186526096.0000 - output_3_true_positives: 149424.0000 - output_3_false_negatives: 120759.0000 - output_3_false_positives: 28318.0000 - val_loss: 4.0220 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2741 - val_output_3_loss: 0.0118 - val_output_4_loss: 3.4265 - val_output_3_precision: 0.9069 - val_output_3_recall: 0.7881 - val_output_3_true_negatives: 7592219.0000 - val_output_3_true_positives: 9319.0000 - val_output_3_false_negatives: 2505.0000 - val_output_3_false_positives: 957.0000\n",
      "Epoch 19/20\n",
      "4607/4607 [==============================] - 584s 127ms/step - loss: 7.4457 - output_1_loss: 1.2259e-06 - output_2_loss: 0.3666 - output_3_loss: 0.0207 - output_4_loss: 6.6298 - output_3_precision: 0.8416 - output_3_recall: 0.5569 - output_3_true_negatives: 186525840.0000 - output_3_true_positives: 150506.0000 - output_3_false_negatives: 119747.0000 - output_3_false_positives: 28320.0000 - val_loss: 3.9099 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2708 - val_output_3_loss: 0.0115 - val_output_4_loss: 3.3223 - val_output_3_precision: 0.9026 - val_output_3_recall: 0.8051 - val_output_3_true_negatives: 7592149.0000 - val_output_3_true_positives: 9520.0000 - val_output_3_false_negatives: 2304.0000 - val_output_3_false_positives: 1027.0000\n",
      "Epoch 20/20\n",
      "4607/4607 [==============================] - 582s 126ms/step - loss: 7.4479 - output_1_loss: 3.1972e-07 - output_2_loss: 0.3799 - output_3_loss: 0.0206 - output_4_loss: 6.6056 - output_3_precision: 0.8436 - output_3_recall: 0.5579 - output_3_true_negatives: 186526032.0000 - output_3_true_positives: 150773.0000 - output_3_false_negatives: 119488.0000 - output_3_false_positives: 27948.0000 - val_loss: 3.7949 - val_output_1_loss: 0.0000e+00 - val_output_2_loss: 0.2720 - val_output_3_loss: 0.0109 - val_output_4_loss: 3.2073 - val_output_3_precision: 0.9140 - val_output_3_recall: 0.8021 - val_output_3_true_negatives: 7592284.0000 - val_output_3_true_positives: 9484.0000 - val_output_3_false_negatives: 2340.0000 - val_output_3_false_positives: 892.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/sergio/Documents/json_experiments\")\n",
    "import json\n",
    "#json.dumps(str(a))\n",
    "with open('history_finetuning_1241_30_50_epoch_nadam_0dot00001_msle_exp_mse_3anchors.json', 'w') as fp:\n",
    "    json.dump(str(history.history), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/sergio/Documents/weights_saved/pesos_1241_30_50_epoch_nadam_0dot00001_msle_exp_mse_3anchors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/tf/home/sergio/Tesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "import numpy as np\n",
    "from tensorflow.compat.v1 import InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yolo_Functional_to_TensorRT.ipynb',\n",
       " 'onnx2trt.py',\n",
       " 'saved_model_production',\n",
       " 'engine.py',\n",
       " 'TF-TRT to UFF-TRT.ipynb',\n",
       " 'saved_model_tensorrt_vectorized',\n",
       " 'pedestrians_example.jpg',\n",
       " 'weights_functional_one_class',\n",
       " '.ipynb_checkpoints',\n",
       " 'saved_model_vectorized',\n",
       " 'Save the model.ipynb',\n",
       " 'Get the ONNX model.ipynb',\n",
       " 'saved_model_tensorrt_production_with_NMS',\n",
       " 'test.py',\n",
       " 'yolov3-tiny.weights',\n",
       " 'converted_model.tflite',\n",
       " 'pedestrians.jpg',\n",
       " 'Testing_model in CPU.ipynb',\n",
       " 'saved_model_with_NMS',\n",
       " 'inference.py',\n",
       " 'saved_model_functional_production_with_NMS',\n",
       " '__pycache__',\n",
       " 'yolov3-tiny.cfg',\n",
       " 'Get the TensorRT model.ipynb',\n",
       " 'saved_model',\n",
       " 'Testing_functional_model_darknet_weights.ipynb',\n",
       " 'weights_fine_tuning_functional',\n",
       " 'saved_model_tensorrt_production',\n",
       " 'yolo_pedestrian.plan',\n",
       " 'model.onnx',\n",
       " 'saved_model_functional_tensorrt_production_with_NMS',\n",
       " 'saved_model_production_with_NMS',\n",
       " 'Tiny_YOLOv3_Functional.ipynb',\n",
       " 'saved_model_tensorrt',\n",
       " 'saved_model_tensorrt_with_NMS',\n",
       " 'YOLOproduction.ipynb',\n",
       " 'TF Lite conversion.ipynb',\n",
       " 'weights_functional']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'saved_model_functional_tensorrt_production_with_NMS/my_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (6, 0, 1)\n",
      "INFO:tensorflow:Loaded TensorRT version: (6, 0, 1)\n",
      "INFO:tensorflow:Assets written to: saved_model_functional_tensorrt_production_with_NMS/my_model/assets\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f29c31f7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f29c3239d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7f29c323b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS\n",
    "conversion_params = conversion_params._replace(max_workspace_size_bytes=(1<<32))\n",
    "conversion_params = conversion_params._replace(precision_mode=\"FP16\")\n",
    "conversion_params = conversion_params._replace(maximum_cached_engines=100)\n",
    "\n",
    "def my_input_fn():\n",
    "    for _ in range(1):\n",
    "        inp1 = tf.random.normal(shape=(1, 416, 416, 3),dtype=tf.dtypes.float32)#.astype(tf.float32)\n",
    "        #inp2 = np.random.normal(size=(1, 416, 416, 3)).astype(np.float32)\n",
    "        yield (inp1,)\n",
    "\n",
    "def getTrtGraphDef(tf_version):\n",
    "    if tf_version == 2:\n",
    "        converter = trt.TrtGraphConverterV2(\n",
    "            input_saved_model_dir='saved_model_functional_production_with_NMS/my_model',\n",
    "            conversion_params=conversion_params)\n",
    "        converter.convert()\n",
    "        converter.build(input_fn=my_input_fn)\n",
    "        converter.save('saved_model_functional_tensorrt_production_with_NMS/my_model')\n",
    "        \n",
    "        saved_model_loaded = tf.saved_model.load('saved_model_functional_tensorrt_production_with_NMS/my_model')\n",
    "        graph_func = saved_model_loaded.signatures[\"serving_default\"]\n",
    "        return graph_func.graph.as_graph_def()\n",
    "    elif tf_version == 1:\n",
    "        # only works if is_dynamic_op=False and precision_mode=”FP32” or “FP16”.\n",
    "        return create_inference_graph(...)\n",
    "\n",
    "trt_graph = getTrtGraphDef(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"input_1\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"_user_specified_name\"\n",
      "  value {\n",
      "    s: \"input_1\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: -1\n",
      "      }\n",
      "      dim {\n",
      "        size: 416\n",
      "      }\n",
      "      dim {\n",
      "        size: 416\n",
      "      }\n",
      "      dim {\n",
      "        size: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Exclude Node: Placeholder, input_1\n",
      "name: \"PartitionedCall\"\n",
      "op: \"PartitionedCall\"\n",
      "input: \"input_1\"\n",
      "attr {\n",
      "  key: \"Tin\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"Tout\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_read_only_resource_inputs\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"config_proto\"\n",
      "  value {\n",
      "    s: \"\\n\\007\\n\\003CPU\\020\\001\\n\\007\\n\\003GPU\\020\\0012\\007 \\001*\\0010J\\0008\\001\\202\\001\\000\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"executor_type\"\n",
      "  value {\n",
      "    s: \"\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_pruned_14989\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_debug_info {\n",
      "  original_node_names: \"PartitionedCall\"\n",
      "}\n",
      "\n",
      "Exclude Node: PartitionedCall, PartitionedCall\n",
      "name: \"Identity\"\n",
      "op: \"Identity\"\n",
      "input: \"PartitionedCall\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "experimental_debug_info {\n",
      "  original_node_names: \"Identity\"\n",
      "}\n",
      "\n",
      "Exclude Node: Identity, Identity\n"
     ]
    }
   ],
   "source": [
    "for n in trt_graph.node:\n",
    "    print(n)\n",
    "    if n.op == \"TRTEngineOp\":\n",
    "        print(\"Node: %s, %s\" % (n.op, n.name.replace(\"/\", \"_\")))\n",
    "        with tf.gfile.GFile(\"%s.plan\" % (n.name.replace(\"/\", \"_\")), 'wb') as f:\n",
    "            f.write(n.attr[\"serialized_segment\"].s)\n",
    "    else:\n",
    "        print(\"Exclude Node: %s, %s\" % (n.op, n.name.replace(\"/\", \"_\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

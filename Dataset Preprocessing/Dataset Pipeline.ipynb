{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0)\n",
    "TEXT_COLOR = (255, 255, 255)\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, color=BOX_COLOR, thickness=2):\n",
    "    \n",
    "    #x_center, y_center, width, height = bbox#*416\n",
    "    x_min,y_min,x_max,y_max=bbox\n",
    "    #x_min = int(x_center-(width//2))\n",
    "    #y_min = int(y_center-(height//2))\n",
    "    #x_max = int(x_center+(width//2))\n",
    "    #y_max = int(y_center+(height//2))\n",
    "    \n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    #class_name = class_idx_to_name[class_id]\n",
    "    #((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    #cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    #cv2.putText(img, class_name, (x_min, y_min - int(0.3 * text_height)), cv2.FONT_HERSHEY_SIMPLEX, 0.35,TEXT_COLOR, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def visualize(image,bboxes):\n",
    "    img = image.copy()\n",
    "    for idx, bbox in enumerate(bboxes):\n",
    "        img = visualize_bbox(img, bbox)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose,convert_bboxes_from_albumentations\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (RandomBrightness,HorizontalFlip,RandomBrightness,HueSaturationValue,Compose,BboxParams,ShiftScaleRotate,Equalize,Cutout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'bboxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5435730591528668"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USING IMGAUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "%matplotlib inline\n",
    "#ia.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'bboxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'num_real_boxes':tf.io.FixedLenFeature([], tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_augmentation(image,bboxes):\n",
    "    \n",
    "    formato = \"yolo\"\n",
    "    boxes = []\n",
    "    categories = []\n",
    "    for i in bboxes:\n",
    "        boxes.append(list(i))\n",
    "        categories.append(0)\n",
    "        \n",
    "    policy = np.random.randint(3)\n",
    "    \n",
    "    annotations = {\"image\":image,\"bboxes\":boxes,'category_id': categories}\n",
    "    \n",
    "    print(policy)\n",
    "    policy = 1\n",
    "    if policy == 0:    \n",
    "        aug = get_aug([ShiftScaleRotate(shift_limit=0.2, scale_limit=0, rotate_limit=0, interpolation=1, border_mode=0, value=0,p=1),\n",
    "                       Equalize(mode='cv', by_channels=True, mask=None, mask_params=(), always_apply=False, p=1)])\n",
    "        result  = aug(**annotations)\n",
    "        image = result[\"image\"]\n",
    "        bboxes = convert_bboxes_from_albumentations(result[\"bboxes\"],target_format= formato,rows=416,cols=416,check_validity=True)\n",
    "\n",
    "    elif policy == 1:\n",
    "        random_image_size=np.random.random()\n",
    "        aug = get_aug([ShiftScaleRotate(shift_limit=0.2, scale_limit=0, rotate_limit=0, interpolation=1, border_mode=0, value=0,p=1),\n",
    "                       Cutout(num_holes=1, max_h_size=int(random_image_size*120), max_w_size=int(random_image_size*120), fill_value=128, p=1)])\n",
    "        result  = aug(**annotations)\n",
    "        image = result[\"image\"]\n",
    "        bboxes = convert_bboxes_from_albumentations(result[\"bboxes\"],target_format= formato,rows=416,cols=416,check_validity=True)\n",
    "\n",
    "    elif policy ==2:\n",
    "        aug = get_aug([HueSaturationValue(hue_shift_limit =0, val_shift_limit=0,always_apply = True)])\n",
    "        result  = aug(**annotations)\n",
    "        image = result[\"image\"]\n",
    "        bboxes = convert_bboxes_from_albumentations(result[\"bboxes\"],target_format= formato,rows=416,cols=416,check_validity=True)    \n",
    "   \n",
    "    return [image,bboxes]\n",
    "\n",
    "\n",
    "def get_iou_matrix_tf(box_arr1, box_arr2):\n",
    "    \n",
    "    box_arr1 = box_arr1 -tf.tile(box_arr1[:,:2],[1,2])\n",
    "    #print(box_arr1)\n",
    "    x11, y11, x12, y12 = tf.split(box_arr1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = tf.split(box_arr2, 4, axis=1)\n",
    "    xA = tf.maximum(x11, tf.transpose(x21))\n",
    "    yA = tf.maximum(y11, tf.transpose(y21))\n",
    "    xB = tf.minimum(x12, tf.transpose(x22))\n",
    "    yB = tf.minimum(y12, tf.transpose(y22))\n",
    "    interArea = tf.maximum((xB - xA + 1e-9), 0) * tf.maximum((yB - yA + 1e-9), 0)\n",
    "    boxAArea = (x12 - x11 + 1e-9) * (y12 - y11 + 1e-9)\n",
    "    boxBArea = (x22 - x21 + 1e-9) * (y22 - y21 + 1e-9)\n",
    "    iou = interArea / (boxAArea + tf.transpose(boxBArea) - interArea)\n",
    "    return iou,tf.argmax(iou,axis=1)#[:,tf.newaxis]\n",
    "\n",
    "\n",
    "def fill_yolo_output(boxes,grid_size,num_anchors,which_anchor_box,which_anchor_box_index):\n",
    "    #print(boxes.shape)\n",
    "    #noobj_mask = tf.ones((1,grid_size*grid_size*num_anchors))\n",
    "    #print(noobj_mask.shape)\n",
    "    \n",
    "    x_min,y_min,x_max,y_max =tf.split(boxes,4,axis=1)\n",
    "\n",
    "    #Transforma las coordenadas de (xmin,ymin,xmax,ymax) --> (xcenter,ycenter,width,height)\n",
    "    width = x_max-x_min\n",
    "    height = y_max-y_min\n",
    "    x_global =x_min + tf.math.divide(x_max - x_min,2)\n",
    "    y_global =y_min + tf.math.divide(y_max - y_min,2)\n",
    "    \n",
    "    \n",
    "    x_min_anchor,y_min_anchor,x_max_anchor,y_max_anchor =tf.split(which_anchor_box,4,axis=1)\n",
    "    \n",
    "    width_anchor = x_max_anchor-x_min_anchor\n",
    "    height_anchor = y_max_anchor-y_min_anchor\n",
    "    x_global_anchor =x_min_anchor + tf.math.divide(x_max_anchor - x_min_anchor,2)\n",
    "    y_global_anchor =y_min_anchor + tf.math.divide(y_max_anchor - y_min_anchor,2)   \n",
    "\n",
    "    \n",
    "    #print(\"el x original\",x_global)\n",
    "    #print(\"el y original\",y_global)\n",
    "    #print(\"el w original\",width)\n",
    "    #print(\"el h original\",height)\n",
    "    \n",
    "    #porción de la imagen que hay en cada celda\n",
    "    pixel_per_grid = tf.math.divide(1.,grid_size)\n",
    "    #print(pixel_per_grid)\n",
    "    \n",
    "    #Obtenemos la coordenada de la celda donde están los boundingboxes\n",
    "    offset_grid_x = x_global//pixel_per_grid\n",
    "    offset_grid_y = y_global//pixel_per_grid\n",
    "    \n",
    "    #Obtenemos el el centro locacon referencia  al celda encontrada previamente\n",
    "    x_local =tf.math.floormod(x_global,pixel_per_grid)\n",
    "    y_local =tf.math.floormod(y_global,pixel_per_grid)\n",
    "    #print(x_local,y_local)\n",
    "    \n",
    "    #Valores tx e ty del groudtruth\n",
    "    tx = tf.math.log(x_local + 1e-07/(1-x_local))\n",
    "    ty = tf.math.log(y_local+1e-07/(1-y_local))\n",
    "    tw = tf.math.log(tf.math.divide(width+1e-07,width_anchor))\n",
    "    th = tf.math.log(tf.math.divide(height+1e-07,height_anchor))\n",
    "    tobj_mask = tf.ones_like(tx)\n",
    "    tobj = tf.concat([tobj_mask,tobj_mask],axis=0)\n",
    "    \n",
    "    #tnoobj = tf.zeros_like(tx)    \n",
    "    #tobj = tf.ones((grid_size*grid_size*num_anchors,1))\n",
    "    #tnoobj = tf.zeros((grid_size*grid_size*num_anchors,1))\n",
    "    #print(\"Lo que la red debe predecir\",tx.numpy(),ty.numpy(),tw.numpy(),th.numpy())\n",
    "    #x_global = (offset_grid_x * pixel_per_grid) + tf.math.sigmoid(tx)\n",
    "    #y_global = (offset_grid_y * pixel_per_grid) + tf.math.sigmoid(ty)\n",
    "    #w = width_anchor*tf.math.exp(tw)\n",
    "    #h = height_anchor*tf.math.exp(th)\n",
    "    #print(\"obtnemos el x_real\",x_global)\n",
    "    #print(\"obtenemos el y_real\",y_global)\n",
    "    #print(\"obtenemos el w real\",w)\n",
    "    #print(\"obtenemos el h real\",h)\n",
    "    \n",
    "    \n",
    "    #print(which_anchor_box_index)\n",
    "    residuo = tf.math.floormod(which_anchor_box_index,2)[:,tf.newaxis]\n",
    "    coord = tf.cast(2*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    \n",
    "    coord_objectness = tf.cast(2*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    coord_objectness2 = coord_objectness+1\n",
    "    coord_objectess_global = tf.concat([coord_objectness,coord_objectness2],axis=0)\n",
    "    \n",
    "    output_position = residuo+coord\n",
    "    print(\"tipo de aoutput_positivon\",output_position)\n",
    "    \n",
    "    print(output_position)\n",
    "    \n",
    "    dense_shape = grid_size*grid_size*num_anchors\n",
    "    tx_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tx[:,0], dense_shape=[dense_shape]))\n",
    "    ty_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=ty[:,0], dense_shape=[dense_shape]))\n",
    "    tw_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tw[:,0], dense_shape=[dense_shape]))\n",
    "    th_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=th[:,0], dense_shape=[dense_shape]))\n",
    "    obj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tobj_mask[:,0], dense_shape=[dense_shape]))\n",
    "    objectness_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=coord_objectess_global, values=tobj[:,0], dense_shape=[dense_shape]))\n",
    "    #noobj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tnoobj[:,0], dense_shape=[dense_shape]))\n",
    "    #obj_mask =tx_vector=ty_vector=tw_vector=th_vector = tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "    \n",
    "    tx_vector_dense = tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=False, name=\"Dense_tx\")\n",
    "    ty_vector_dense = tf.sparse.to_dense(ty_vector, default_value=0, validate_indices=False, name=\"Dense_ty\")\n",
    "    tw_vector_dense = tf.sparse.to_dense(tw_vector, default_value=0, validate_indices=False, name=\"Dense_tw\")\n",
    "    th_vector_dense = tf.sparse.to_dense(th_vector, default_value=0, validate_indices=False, name=\"Dense_th\")\n",
    "    obj_mask_dense =  tf.sparse.to_dense(obj_mask, default_value=0, validate_indices=False, name=\"Dense_obj\")\n",
    "    noobj_mask_dense = 1-obj_mask_dense\n",
    "    objectness_vector_dense =  tf.sparse.to_dense(objectness_vector, default_value=0, validate_indices=False)\n",
    "    \n",
    "    #noobj_mask_dense= tf.sparse.to_dense(noobj_mask, default_value=1, validate_indices=False, name=\"Dense_noobj\")\n",
    "    ##print(tx_vector.to_dense)\n",
    "    #print(tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=True, name=None)\n",
    "    #tx_vector=tx_vector[[3,2],]\n",
    "    #tx_vector[output_position[:,0]] = tx\n",
    "    #print(\"coordenada de la salida:\",output_position)\n",
    "    \n",
    "    return tx_vector_dense,ty_vector_dense,tw_vector_dense,th_vector_dense,obj_mask_dense,noobj_mask_dense,objectness_vector_dense\n",
    "\n",
    "def build_targets(image,image_bboxes,num_real_boxes,anchor_boxes):\n",
    "    \n",
    "    images_bboxes_original = image_bboxes\n",
    "    #Obtenemos los boduing boxes que son reales\n",
    "    image_bboxes = image_bboxes[:num_real_boxes,:]\n",
    "    #print(\"Bouding boxes de la imagen\",image_bboxes)\n",
    "    #Obteneos  la matriz de IoU , y el índice del anchor box que dió mejor resultado\n",
    "    \n",
    "    image_bboxes = tf.math.divide(image_bboxes,416)\n",
    "    iou_matrix,which_anchor_box_index = get_iou_matrix_tf(image_bboxes,anchor_boxes)\n",
    "    \n",
    "    print(which_anchor_box_index)\n",
    "\n",
    "    #Indices de los bouding boxes que irian en cada salida, index_best_ yolo nos dice que bouding boxes de la imagen van a la salida YOLO1,\n",
    "    #porque su mejor IoU fue con los dos anchor boxes mas grandes\n",
    "    index_best_yolo1 = tf.where(which_anchor_box_index>=2)[:,0]\n",
    "    index_best_yolo2 = tf.where(which_anchor_box_index<2)[:,0]\n",
    "    index_best_anchor_yolo1 = tf.gather(which_anchor_box_index,index_best_yolo1,axis=0)\n",
    "    index_best_anchor_yolo2 = tf.gather(which_anchor_box_index,index_best_yolo2,axis=0)\n",
    "    \n",
    "    print(index_best_yolo1)\n",
    "    print(index_best_anchor_yolo1)\n",
    "\n",
    "    print(index_best_yolo2)\n",
    "    print(index_best_anchor_yolo2)\n",
    "\n",
    "    \n",
    "    best_bboxes_yolo1 = tf.gather(image_bboxes,index_best_yolo1,axis =0)\n",
    "    best_anchors_yolo1 = tf.gather(anchor_boxes,index_best_anchor_yolo1, axis =0) #LOs dos anchor boxes grandes corrsponden a YOLO\n",
    "    best_bboxes_yolo2 = tf.gather(image_bboxes,index_best_yolo2,axis =0)\n",
    "    best_anchors_yolo2 = tf.gather(anchor_boxes,index_best_anchor_yolo2, axis =0) #Los dos anchor boxes pequeños corresponden a YOLO2\n",
    "    \n",
    "    \n",
    "    if best_anchors_yolo1.shape[0] !=0:\n",
    "        tx_vector_yolo1,ty_vector_yolo1,tw_vector_yolo1,th_vector_yolo1,obj_mask_yolo1,noobj_mask_yolo1,obj_vector_yolo1= fill_yolo_output(best_bboxes_yolo1,13,2,best_anchors_yolo1,index_best_anchor_yolo1)\n",
    "    else:\n",
    "        tx_vector_yolo1=ty_vector_yolo1=tw_vector_yolo1=th_vector_yolo1=obj_mask_yolo1= obj_vector_yolo1=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        noobj_mask_yolo1 = tf.ones((1,13*13*num_anchors))\n",
    "    \n",
    "    if best_anchors_yolo2.shape[0] != 0:\n",
    "        tx_vector_yolo2,ty_vector_yolo2,tw_vector_yolo2,th_vector_yolo2,obj_mask_yolo2,noobj_mask_yolo2,obj_vector_yolo2 = fill_yolo_output(best_bboxes_yolo2,26,2,best_anchors_yolo2,index_best_anchor_yolo2)\n",
    "    else:\n",
    "        tx_vector_yolo2=ty_vector_yolo2=tw_vector_yolo2=th_vector_yolo2=obj_mask_yolo2 = obj_vector_yolo2=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        noobj_mask_yolo2 = tf.ones((1,26*26*num_anchors))\n",
    "        \n",
    "    tx_vector = tf.concat([tx_vector_yolo1,tx_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    ty_vector = tf.concat([ty_vector_yolo1,ty_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    tw_vector = tf.concat([tw_vector_yolo1,tw_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    th_vector = tf.concat([th_vector_yolo1,th_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_mask = tf.concat([obj_mask_yolo1,obj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    noobj_mask = tf.concat([noobj_mask_yolo1,noobj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_vector = tf.concat([obj_vector_yolo1,obj_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    \n",
    "    output = tf.concat([tx_vector,ty_vector,tw_vector,th_vector,obj_mask,noobj_mask,obj_vector],axis=1)\n",
    "    \n",
    "    return image,images_bboxes_original,output\n",
    "\n",
    "\n",
    "def imgaug_data_augmentation(image,bboxes,num_real_boxes):\n",
    "    im_shape = image.shape\n",
    "    bbs = BoundingBoxesOnImage.from_xyxy_array(bboxes*416, shape=(416,416))\n",
    "    \n",
    "    policy = np.random.randint(5)\n",
    "    \n",
    "    #policy = 2\n",
    "    if policy == 0:\n",
    "        \n",
    "        p = np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateX(px=(-60, 60),cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "        p = np.random.random()\n",
    "        if p<=0.8:\n",
    "            aug = iaa.HistogramEqualization()\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "    elif policy==1:\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.2:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.8:\n",
    "            square_size = np.random.randint(48)\n",
    "            aug = iaa.Cutout(nb_iterations=1, size=square_size/416, squared=True)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    elif policy==2:\n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.ShearY(shear=(int(-0.06*416), int(0.06*416)), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "        p=np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "            \n",
    "    elif policy==3:\n",
    "        p=np.random.random()\n",
    "        if p<=0.6:    \n",
    "            aug = iaa.Rotate(rotate=(-30, 30), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs_aug.remove_out_of_image().clip_out_of_image()\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.MultiplySaturation((0.54, 1.54))\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    bbs.remove_out_of_image()\n",
    "    \n",
    "    return image,np.clip(bbs.to_xyxy_array(np.float32),1,415),num_real_boxes\n",
    "    \n",
    "    \n",
    "def preprocessing(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,num_real_boxes\n",
    "\n",
    "    \n",
    "@tf.function(input_signature=[tf.TensorSpec((416,416,3), tf.uint8),tf.TensorSpec((None,4), tf.float32),tf.TensorSpec((), tf.int64)]) \n",
    "def tf_numpy_albumentations_real(image,bboxes,num_real_boxes):\n",
    "    \n",
    "    boxes_shape = bboxes.shape\n",
    "    im_shape = image.shape\n",
    "\n",
    "    image,bboxes,num_real_boxes = tf.numpy_function(imgaug_data_augmentation,[image,bboxes,num_real_boxes],Tout =[tf.uint8,tf.float32,tf.int64])\n",
    " \n",
    "    image.set_shape(im_shape)\n",
    "    bboxes.set_shape(boxes_shape)\n",
    "    \n",
    "    #print(\"Imagen data type\",image.dtype)\n",
    "    #print(\"Bboxes data type\",bboxes.dtype)   \n",
    "\n",
    "    return image,bboxes,num_real_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", shape=(None,), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#USANDO TF.IMAGE MODULE\n",
    "anchors =tf.constant(np.array([[0,0,0.015,0.037],[0,0,0.043,0.104],[0,0,0.11,0.278],[0,0,0.351,0.66]]),dtype=tf.float32)\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames)\n",
    "#.shuffle(70000)\n",
    "parsed_image_dataset = raw_image_dataset.map(preprocessing,num_parallel_calls=8).map(tf_numpy_albumentations_real,num_parallel_calls=8).map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "188.1102409362793\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "inicio = time.time()\n",
    "counter=0\n",
    "for index,i in enumerate(parsed_image_dataset.batch(8).prefetch(8)):\n",
    "    if index%1000==0:\n",
    "        print(index)\n",
    "    counter+=1\n",
    "    \n",
    "fin = time.time()\n",
    "print(fin-inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1690, 7)\n"
     ]
    }
   ],
   "source": [
    "image,images_bboxes,labels =i\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1690)\n"
     ]
    }
   ],
   "source": [
    "objectness = labels[:,:,-1]\n",
    "print(objectness.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = image[1,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  0 166]\n",
      " [  0 167]\n",
      " [  0 170]\n",
      " [  0 171]\n",
      " [  1 142]\n",
      " [  1 143]\n",
      " [  1 226]\n",
      " [  1 227]\n",
      " [  1 432]\n",
      " [  1 433]], shape=(10, 2), dtype=int64)\n",
      "6\n",
      "7\n",
      "85\n",
      "192 224\n"
     ]
    }
   ],
   "source": [
    "print(tf.where(objectness==1))\n",
    "print(85//13)\n",
    "print(85%13)\n",
    "print(6*13+7)\n",
    "print(6*32,7*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[194.00452  130.17656  274.22452  277.47037 ]\n",
      "  [164.93195  171.3831   199.91245  238.9372  ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]\n",
      "  [168.66846  166.40001  208.       221.54948 ]]\n",
      "\n",
      " [[160.93376   19.138659 238.17664  321.09085 ]\n",
      "  [232.20287  157.52179  404.43518  411.06912 ]\n",
      "  [324.82114    1.       374.00064   40.39054 ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]\n",
      "  [166.40001  166.40001  208.       208.      ]]], shape=(2, 20, 4), dtype=float32)\n",
      "181.5\n",
      "204.5\n"
     ]
    }
   ],
   "source": [
    "print(images_bboxes)\n",
    "print((199-164)/2+(164))\n",
    "print((238-171)/2+(171))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "6.0\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Obtenemos la coordenada de la celda donde están los boundingboxes\n",
    "offset_grid_x = 181.5//32\n",
    "offset_grid_y = 204.5//32\n",
    "\n",
    "print(offset_grid_x)\n",
    "print(offset_grid_y)\n",
    "\n",
    "print(6*13+7)\n",
    "\n",
    "#Obtenemos el el centro locacon referencia  al celda encontrada previamente\n",
    "x_local =tf.math.floormod(181,32)\n",
    "y_local =tf.math.floormod(204.5,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes1_ = i[1][1,:3,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(image_1,boxes1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coor = tx_vector[1,:].numpy()\n",
    "y_coor = ty_vector[1,:].numpy()\n",
    "w_coor = tw_vector[1,:].numpy()\n",
    "h_coor = th_vector[1,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min,y_min,x_max,y_max =tf.split(boxes1_,4,axis=1)\n",
    "\n",
    "#Transforma las coordenadas de (xmin,ymin,xmax,ymax) --> (xcenter,ycenter,width,height)\n",
    "width = x_max-x_min\n",
    "height = y_max-y_min\n",
    "x_global =x_min + (x_max - x_min)/2\n",
    "y_global =y_min + (y_max - y_min)/2\n",
    "\n",
    "print(x_global)\n",
    "print(y_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(338/2)\n",
    "print(416/13) #65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(x_coor!=0))\n",
    "print(np.where(y_coor!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = x_coor[np.where(x_coor!=0)]\n",
    "ty = y_coor[np.where(y_coor!=0)]\n",
    "tw = w_coor[np.where(w_coor!=0)]\n",
    "th = h_coor[np.where(h_coor!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors =tf.constant(np.array([[0,0,0.015,0.037],[0,0,0.043,0.104],[0,0,0.11,0.278],[0,0,0.351,0.66]]),dtype=tf.float32).numpy()\n",
    "which_anchor_box = anchors[[3,3,1],:]\n",
    "\n",
    "print(which_anchor_box)\n",
    "x_min_anchor,y_min_anchor,x_max_anchor,y_max_anchor =tf.split(which_anchor_box,4,axis=1)\n",
    "\n",
    "width_anchor = x_max_anchor-x_min_anchor\n",
    "height_anchor = y_max_anchor-y_min_anchor\n",
    "x_global_anchor =x_min_anchor + (x_max_anchor - x_min_anchor)/2\n",
    "y_global_anchor =y_min_anchor + (y_max_anchor - y_min_anchor)/2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min,y_min,x_max,y_max =tf.split(boxes1_,4,axis=1)\n",
    "\n",
    "#Transforma las coordenadas de (xmin,ymin,xmax,ymax) --> (xcenter,ycenter,width,height)\n",
    "width = x_max-x_min\n",
    "height = y_max-y_min\n",
    "x_global =x_min + (x_max - x_min)/2\n",
    "y_global =y_min + (y_max - y_min)/2\n",
    "\n",
    "grid_size=26\n",
    "#porción de la imagen que hay en cada celda\n",
    "pixel_per_grid = 1/grid_size\n",
    "print(pixel_per_grid)\n",
    "\n",
    "#Obtenemos la coordenada de la celda donde están los boundingboxes\n",
    "offset_grid_x = x_global//pixel_per_grid\n",
    "offset_grid_y = y_global//pixel_per_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_global = (offset_grid_x * pixel_per_grid) + (tf.math.sigmoid(tx)[:,tf.newaxis])\n",
    "y_global = (offset_grid_y * pixel_per_grid) + (tf.math.sigmoid(ty)[:,tf.newaxis])\n",
    "\n",
    "print((offset_grid_x * pixel_per_grid) )\n",
    "print((offset_grid_y * pixel_per_grid))\n",
    "\n",
    "print(\"factor width\",tf.math.exp(tw))\n",
    "print(\"factor height\",tf.math.exp(th))\n",
    "print(\"anchor width\",width_anchor)\n",
    "print(\"anchor Height\",height_anchor)\n",
    "w = width_anchor*(tf.math.exp(tw)[:,tf.newaxis])\n",
    "h = height_anchor*(tf.math.exp(th)[:,tf.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w*416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h*416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = x_max-x_min\n",
    "height = y_max-y_min\n",
    "x_global =x_min + tf.math.divide(x_max - x_min,2)\n",
    "y_global =y_min + tf.math.divide(y_max - y_min,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_image_dataset = raw_image_dataset.map(preprocessing,num_parallel_calls=8)#.map(tf_numpy_albumentations_real,num_parallel_calls=8)\n",
    "for index,i in enumerate(parsed_image_dataset.batch(8).prefetch(8)):\n",
    "    if index == 1000:\n",
    "        good_batch = i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgaug_data_augmentation(image,bboxes,num_real_boxes,policy):\n",
    "    im_shape = image.shape\n",
    "    bbs = BoundingBoxesOnImage.from_xyxy_array(bboxes*416, shape=(416,416))\n",
    "    \n",
    "    #policy = np.random.randint(5)\n",
    "    \n",
    "    #policy = 2\n",
    "    if policy == 0:\n",
    "        \n",
    "        p = np.random.random()\n",
    "        if p<0.6:\n",
    "            aug = iaa.TranslateX(px=(-60, 60),cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "        p = np.random.random()\n",
    "        if p<0.8:\n",
    "            aug = iaa.HistogramEqualization()\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "    elif policy==1:\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<0.2:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<0.8:\n",
    "            square_size = np.random.randint(48)\n",
    "            aug = iaa.Cutout(nb_iterations=1, size=square_size/416, squared=True)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    elif policy==2:\n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.ShearY(shear=(int(-0.06*416), int(0.06*416)), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "            \n",
    "    elif policy==3:\n",
    "        p=np.random.random()\n",
    "        if p<=0.6:    \n",
    "            aug = iaa.Rotate(rotate=(-30, 30), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs_aug.remove_out_of_image().clip_out_of_image()\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.MultiplySaturation((0.54, 1.54))\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "    else:\n",
    "        image = image\n",
    "        bb == bbs\n",
    "        \n",
    "        \n",
    "    return image,bbs.to_xyxy_array(np.int32),num_real_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_image = 6\n",
    "\n",
    "image = good_batch[0][which_image,:].numpy()\n",
    "boxes = good_batch[1][which_image,:good_batch[2][which_image].numpy(),:].numpy()\n",
    "print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "for policy in range(4):\n",
    "    print(policy)\n",
    "    for iteration in range(5):\n",
    "        print((iteration+1)+(policy)*5)\n",
    "        image_aug,boxes_aug,num_real_boxes = imgaug_data_augmentation(image,boxes,good_batch[2][3].numpy(),policy)\n",
    "        plt.subplot(4,5,(iteration+1)+(policy)*5)\n",
    "        boxes_aug = np.clip(boxes_aug,1,415)\n",
    "        visualize(image_aug,boxes_aug)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgaug_data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "num_example = 2\n",
    "    #plt.figure(figsize=(12, 12))\n",
    "    #plt.imshow(img)\n",
    "for i in range(8):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    image = good_batch[0][i,:].numpy()\n",
    "    boxes = np.clip(good_batch[1][i,:good_batch[2][i].numpy(),:].numpy(),1,415)\n",
    "    visualize(image,boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs = BoundingBoxesOnImage.from_xyxy_array(sample_boxes, shape=(416,416))\n",
    "ia.imshow(bbs.draw_on_image(sample_image, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.TranslateX(px=(-20, 20),cval=128)\n",
    "image_aug, bbs_aug = aug(image=sample_image, bounding_boxes=bbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs_aug.remove_out_of_image().clip_out_of_image().to_xyxy_array(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs_aug.draw_on_image(image_aug, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.HistogramEqualization()\n",
    "image_aug, bbs_aug = aug(image=image_aug, bounding_boxes=bbs_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs_aug.draw_on_image(image_aug, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.Cutout(nb_iterations=1, size=0.15, squared=True)\n",
    "image_aug, bbs_aug = aug(image=image_aug, bounding_boxes=bbs_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs_aug.draw_on_image(image_aug, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.ShearY(shear=(-50, 50), order=1, cval=128)\n",
    "image_aug, bbs_aug = aug(image=image_aug, bounding_boxes=bbs_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs_aug.draw_on_image(image_aug, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.Rotate(rotate=(-30, 30), order=1, cval=128)\n",
    "image_aug, bbs_aug = aug(image=image_aug, bounding_boxes=bbs_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs_aug.draw_on_image(image_aug, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = iaa.MultiplySaturation((1.5, 1.5))\n",
    "image_aug, bbs_aug = aug(image=image_aug, bounding_boxes=bbs_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs_aug.draw_on_image(image_aug, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs_aug.draw_on_image(image_aug, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in parsed_image_dataset.batch(16):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_aug = i[0][2,:].numpy()\n",
    "print(sample_image.shape)\n",
    "boxes_aug = i[1][2,:].numpy()\n",
    "print(sample_boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs = BoundingBoxesOnImage.from_xyxy_array(boxes_aug[:2,:], shape=(416,416)).remove_out_of_image().clip_out_of_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "aug = iaa.TranslateY(px=(-50, 50),cval=128)\n",
    "for i in bbs.to_xyxy_array(np.int32)[:2]:\n",
    "    print(i)\n",
    "    aux = image_aug[i[1]:i[3],i[0]:i[2]]\n",
    "    print(aux.shape)\n",
    "    image = aug(image=aux)\n",
    "    print(image.shape)\n",
    "    ia.imshow(image)\n",
    "    image_aug[i[1]:i[3],i[0]:i[2]] = image\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs.draw_on_image(image_aug, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6%3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection\")\n",
    "\n",
    "from YOLOblocks import TinyYOLOv3,BasicBlock,PredictionLayer#,YOLOLossBasicBlock\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "#from tensorflow.python.tools import freeze_graph\n",
    "#from skimage.io import imread,imshow\n",
    "#from skimage.transform import resize \n",
    "import time\n",
    "#from tensorflow.compat.v1.image import decode_image\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'bboxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'num_real_boxes':tf.io.FixedLenFeature([], tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_matrix_tf(box_arr1, box_arr2):\n",
    "    \n",
    "    box_arr1 = box_arr1 -tf.tile(box_arr1[:,:2],[1,2])\n",
    "    #print(box_arr1)\n",
    "    x11, y11, x12, y12 = tf.split(box_arr1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = tf.split(box_arr2, 4, axis=1)\n",
    "    xA = tf.maximum(x11, tf.transpose(x21))\n",
    "    yA = tf.maximum(y11, tf.transpose(y21))\n",
    "    xB = tf.minimum(x12, tf.transpose(x22))\n",
    "    yB = tf.minimum(y12, tf.transpose(y22))\n",
    "    interArea = tf.maximum((xB - xA + 1e-9), 0) * tf.maximum((yB - yA + 1e-9), 0)\n",
    "    boxAArea = (x12 - x11 + 1e-9) * (y12 - y11 + 1e-9)\n",
    "    boxBArea = (x22 - x21 + 1e-9) * (y22 - y21 + 1e-9)\n",
    "    iou = interArea / (boxAArea + tf.transpose(boxBArea) - interArea)\n",
    "    return iou,tf.argmax(iou,axis=1)#[:,tf.newaxis]\n",
    "\n",
    "\n",
    "def fill_yolo_output(boxes,grid_size,num_anchors,which_anchor_box,which_anchor_box_index):\n",
    "    #print(boxes.shape)\n",
    "    #noobj_mask = tf.ones((1,grid_size*grid_size*num_anchors))\n",
    "    #print(noobj_mask.shape)\n",
    "    \n",
    "    x_min,y_min,x_max,y_max =tf.split(boxes,4,axis=1)\n",
    "\n",
    "    #Transforma las coordenadas de (xmin,ymin,xmax,ymax) --> (xcenter,ycenter,width,height)\n",
    "    width = x_max-x_min\n",
    "    height = y_max-y_min\n",
    "    x_global =x_min + tf.math.divide(x_max - x_min,2)\n",
    "    y_global =y_min + tf.math.divide(y_max - y_min,2)\n",
    "    \n",
    "    \n",
    "    x_min_anchor,y_min_anchor,x_max_anchor,y_max_anchor =tf.split(which_anchor_box,4,axis=1)\n",
    "    \n",
    "    width_anchor = x_max_anchor-x_min_anchor\n",
    "    height_anchor = y_max_anchor-y_min_anchor\n",
    "    x_global_anchor =x_min_anchor + tf.math.divide(x_max_anchor - x_min_anchor,2)\n",
    "    y_global_anchor =y_min_anchor + tf.math.divide(y_max_anchor - y_min_anchor,2)   \n",
    "\n",
    "    \n",
    "    #print(\"el x original\",x_global)\n",
    "    #print(\"el y original\",y_global)\n",
    "    #print(\"el w original\",width)\n",
    "    #print(\"el h original\",height)\n",
    "    \n",
    "    #porción de la imagen que hay en cada celda\n",
    "    pixel_per_grid = tf.math.divide(1.,grid_size)\n",
    "    #print(pixel_per_grid)\n",
    "    \n",
    "    #Obtenemos la coordenada de la celda donde están los boundingboxes\n",
    "    offset_grid_x = x_global//pixel_per_grid\n",
    "    offset_grid_y = y_global//pixel_per_grid\n",
    "    \n",
    "    #Obtenemos el el centro locacon referencia  al celda encontrada previamente\n",
    "    x_local =tf.math.floormod(x_global,pixel_per_grid)\n",
    "    y_local =tf.math.floormod(y_global,pixel_per_grid)\n",
    "    #print(x_local,y_local)\n",
    "    \n",
    "    #Valores tx e ty del groudtruth\n",
    "    tx = tf.math.log(x_local + 1e-07/(1-x_local))\n",
    "    ty = tf.math.log(y_local+1e-07/(1-y_local))\n",
    "    tw = tf.math.log(tf.math.divide(width+1e-07,width_anchor))\n",
    "    th = tf.math.log(tf.math.divide(height+1e-07,height_anchor))\n",
    "    tobj_mask = tf.ones_like(tx)\n",
    "    tobj = tf.concat([tobj_mask,tobj_mask],axis=0)\n",
    "    \n",
    "    #tnoobj = tf.zeros_like(tx)    \n",
    "    #tobj = tf.ones((grid_size*grid_size*num_anchors,1))\n",
    "    #tnoobj = tf.zeros((grid_size*grid_size*num_anchors,1))\n",
    "    #print(\"Lo que la red debe predecir\",tx.numpy(),ty.numpy(),tw.numpy(),th.numpy())\n",
    "    #x_global = (offset_grid_x * pixel_per_grid) + tf.math.sigmoid(tx)\n",
    "    #y_global = (offset_grid_y * pixel_per_grid) + tf.math.sigmoid(ty)\n",
    "    #w = width_anchor*tf.math.exp(tw)\n",
    "    #h = height_anchor*tf.math.exp(th)\n",
    "    #print(\"obtnemos el x_real\",x_global)\n",
    "    #print(\"obtenemos el y_real\",y_global)\n",
    "    #print(\"obtenemos el w real\",w)\n",
    "    #print(\"obtenemos el h real\",h)\n",
    "    \n",
    "    #anchor_boxes_per_output = num_anchors//2\n",
    "\n",
    "    #Residuo indica cual de los 3 anchor boxes de la coordenada es la que llevara el 1\n",
    "    #Coord representa la coordenada del grid\n",
    "    \n",
    "    residuo = tf.math.floormod(which_anchor_box_index,num_anchors)[:,tf.newaxis]\n",
    "    coord = tf.cast(num_anchors*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    \n",
    "    coord_objectness = tf.cast(2*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    coord_objectness2 = coord_objectness+1\n",
    "    coord_objectess_global = tf.concat([coord_objectness,coord_objectness2],axis=0)\n",
    "    \n",
    "    output_position = residuo+coord\n",
    "    print(\"tipo de aoutput_positivon\",output_position)\n",
    "    \n",
    "    print(output_position)\n",
    "    \n",
    "    dense_shape = grid_size*grid_size*num_anchors\n",
    "    print(dense_shape)\n",
    "    tx_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tx[:,0], dense_shape=[dense_shape]))\n",
    "    ty_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=ty[:,0], dense_shape=[dense_shape]))\n",
    "    tw_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tw[:,0], dense_shape=[dense_shape]))\n",
    "    th_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=th[:,0], dense_shape=[dense_shape]))\n",
    "    obj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tobj_mask[:,0], dense_shape=[dense_shape]))\n",
    "    objectness_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=coord_objectess_global, values=tobj[:,0], dense_shape=[dense_shape]))\n",
    "    #noobj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tnoobj[:,0], dense_shape=[dense_shape]))\n",
    "    #obj_mask =tx_vector=ty_vector=tw_vector=th_vector = tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "    \n",
    "    tx_vector_dense = tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=False, name=\"Dense_tx\")\n",
    "    ty_vector_dense = tf.sparse.to_dense(ty_vector, default_value=0, validate_indices=False, name=\"Dense_ty\")\n",
    "    tw_vector_dense = tf.sparse.to_dense(tw_vector, default_value=0, validate_indices=False, name=\"Dense_tw\")\n",
    "    th_vector_dense = tf.sparse.to_dense(th_vector, default_value=0, validate_indices=False, name=\"Dense_th\")\n",
    "    obj_mask_dense =  tf.sparse.to_dense(obj_mask, default_value=0, validate_indices=False, name=\"Dense_obj\")\n",
    "    #noobj_mask_dense = 1-obj_mask_dense\n",
    "    objectness_vector_dense =  tf.sparse.to_dense(objectness_vector, default_value=0, validate_indices=False)\n",
    "    \n",
    "    #noobj_mask_dense= tf.sparse.to_dense(noobj_mask, default_value=1, validate_indices=False, name=\"Dense_noobj\")\n",
    "    ##print(tx_vector.to_dense)\n",
    "    #print(tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=True, name=None)\n",
    "    #tx_vector=tx_vector[[3,2],]\n",
    "    #tx_vector[output_position[:,0]] = tx\n",
    "    #print(\"coordenada de la salida:\",output_position)\n",
    "    \n",
    "    #return ((tx_vector_dense,ty_vector_dense,obj_mask_dense),(tw_vector_dense,th_vector_dense,obj_mask_dense),(objectness),(objectness))\n",
    "    \n",
    "    return tx_vector_dense,ty_vector_dense,tw_vector_dense,th_vector_dense,obj_mask_dense,objectness_vector_dense\n",
    "\n",
    "def build_targets(image,image_bboxes,num_real_boxes,anchor_boxes):\n",
    "    \n",
    "    images_bboxes_original = image_bboxes\n",
    "    #Obtenemos los boduing boxes que son reales\n",
    "    image_bboxes = image_bboxes[:num_real_boxes,:]\n",
    "    #print(\"Bouding boxes de la imagen\",image_bboxes)\n",
    "    #Obteneos  la matriz de IoU , y el índice del anchor box que dió mejor resultado\n",
    "    \n",
    "    #Nprmalizamos con respecto al tamaño de la imagen y obtenemos la Iou con los anchor boxes\n",
    "    image_bboxes = tf.math.divide(image_bboxes,416)\n",
    "    iou_matrix,which_anchor_box_index = get_iou_matrix_tf(image_bboxes,anchor_boxes)\n",
    "    \n",
    "    print(which_anchor_box_index)\n",
    "\n",
    "    anchor_boxes_per_output = len(anchor_boxes)//2\n",
    "    #Indices de los bouding boxes que irian en cada salida, index_best_ yolo nos dice que bouding boxes de la imagen van a la salida YOLO1,\n",
    "    #porque su mejor IoU fue con los len(anchor_boxes)//2 anchor boxes mas grandes\n",
    "    index_best_yolo1 = tf.where(which_anchor_box_index>=anchor_boxes_per_output)[:,0]\n",
    "    index_best_yolo2 = tf.where(which_anchor_box_index<anchor_boxes_per_output)[:,0]\n",
    "    index_best_anchor_yolo1 = tf.gather(which_anchor_box_index,index_best_yolo1,axis=0)\n",
    "    index_best_anchor_yolo2 = tf.gather(which_anchor_box_index,index_best_yolo2,axis=0)\n",
    "    \n",
    "    print(index_best_yolo1)\n",
    "    print(index_best_anchor_yolo1)\n",
    "\n",
    "    print(index_best_yolo2)\n",
    "    print(index_best_anchor_yolo2)\n",
    "\n",
    "    \n",
    "    best_bboxes_yolo1 = tf.gather(image_bboxes,index_best_yolo1,axis =0)\n",
    "    best_anchors_yolo1 = tf.gather(anchor_boxes,index_best_anchor_yolo1, axis =0) #LOs dos anchor boxes grandes corrsponden a YOLO1\n",
    "    best_bboxes_yolo2 = tf.gather(image_bboxes,index_best_yolo2,axis =0)\n",
    "    best_anchors_yolo2 = tf.gather(anchor_boxes,index_best_anchor_yolo2, axis =0) #Los dos anchor boxes pequeños corresponden a YOLO2\n",
    "    \n",
    "    \n",
    "    if best_anchors_yolo1.shape[0] !=0:\n",
    "        tx_vector_yolo1,ty_vector_yolo1,tw_vector_yolo1,th_vector_yolo1,obj_mask_yolo1,obj_vector_yolo1= fill_yolo_output(best_bboxes_yolo1,13,anchor_boxes_per_output,best_anchors_yolo1,index_best_anchor_yolo1)\n",
    "    else:\n",
    "        tx_vector_yolo1=ty_vector_yolo1=tw_vector_yolo1=th_vector_yolo1=obj_mask_yolo1= obj_vector_yolo1=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo1 = tf.ones((1,13*13*num_anchors))\n",
    "    \n",
    "    if best_anchors_yolo2.shape[0] != 0:\n",
    "        tx_vector_yolo2,ty_vector_yolo2,tw_vector_yolo2,th_vector_yolo2,obj_mask_yolo2,obj_vector_yolo2 = fill_yolo_output(best_bboxes_yolo2,26,anchor_boxes_per_output,best_anchors_yolo2,index_best_anchor_yolo2)\n",
    "    else:\n",
    "        tx_vector_yolo2=ty_vector_yolo2=tw_vector_yolo2=th_vector_yolo2=obj_mask_yolo2 = obj_vector_yolo2=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo2 = tf.ones((1,26*26*num_anchors))\n",
    "        \n",
    "    tx_vector = tf.concat([tx_vector_yolo1,tx_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    ty_vector = tf.concat([ty_vector_yolo1,ty_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    tw_vector = tf.concat([tw_vector_yolo1,tw_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    th_vector = tf.concat([th_vector_yolo1,th_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_mask = tf.concat([obj_mask_yolo1,obj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    #noobj_mask = tf.concat([noobj_mask_yolo1,noobj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_vector = tf.concat([obj_vector_yolo1,obj_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    \n",
    "    #output = tf.concat([tx_vector,ty_vector,tw_vector,th_vector,obj_mask,noobj_mask,obj_vector],axis=1)\n",
    "    #images_bboxes_original\n",
    "    #return image,output\n",
    "    #Vamos a regresar obj mask que es 1 cuando hay objeto en grid y el anchor box especifico\n",
    "    return tf.cast(image,tf.float32)/255,(tf.concat([tx_vector,ty_vector,obj_mask],axis=1),tf.concat([tw_vector,th_vector,obj_mask],axis=1),(obj_mask),(obj_mask))\n",
    "\n",
    "def imgaug_data_augmentation(image,bboxes,num_real_boxes):\n",
    "    im_shape = image.shape\n",
    "    bbs = BoundingBoxesOnImage.from_xyxy_array(bboxes*416, shape=(416,416))\n",
    "    \n",
    "    policy = np.random.randint(5)\n",
    "    \n",
    "    #policy = 2\n",
    "    if policy == 0:\n",
    "        \n",
    "        p = np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateX(px=(-60, 60),cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "        p = np.random.random()\n",
    "        if p<=0.8:\n",
    "            aug = iaa.HistogramEqualization()\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "    elif policy==1:\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.2:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.8:\n",
    "            square_size = np.random.randint(48)\n",
    "            aug = iaa.Cutout(nb_iterations=1, size=square_size/416, squared=True)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    elif policy==2:\n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.ShearY(shear=(int(-0.06*416), int(0.06*416)), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "        p=np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "            \n",
    "    elif policy==3:\n",
    "        p=np.random.random()\n",
    "        if p<=0.6:    \n",
    "            aug = iaa.Rotate(rotate=(-30, 30), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs_aug.remove_out_of_image().clip_out_of_image()\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.MultiplySaturation((0.54, 1.54))\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    bbs.remove_out_of_image()\n",
    "    \n",
    "    return image,np.clip(bbs.to_xyxy_array(np.float32),1,415),num_real_boxes\n",
    "    \n",
    "    \n",
    "def preprocessing(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,num_real_boxes\n",
    "\n",
    "def preprocessing_validation_set(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    bboxes = tf.clip_by_value(bboxes*416,1,415)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,tf.cast(num_real_boxes,tf.int64)\n",
    "    \n",
    "@tf.function(input_signature=[tf.TensorSpec((416,416,3), tf.uint8),tf.TensorSpec((None,4), tf.float32),tf.TensorSpec((), tf.int64)]) \n",
    "def tf_numpy_albumentations_real(image,bboxes,num_real_boxes):\n",
    "    \n",
    "    boxes_shape = bboxes.shape\n",
    "    im_shape = image.shape\n",
    "\n",
    "    image,bboxes,num_real_boxes = tf.numpy_function(imgaug_data_augmentation,[image,bboxes,num_real_boxes],Tout =[tf.uint8,tf.float32,tf.int64])\n",
    " \n",
    "    image.set_shape(im_shape)\n",
    "    bboxes.set_shape(boxes_shape)\n",
    "    print(\"Imagen data type\",image.dtype)\n",
    "    print(\"Bboxes data type\",bboxes.dtype)\n",
    "    print(\"num_real_boxes\",num_real_boxes.dtype)\n",
    "\n",
    "    return image,bboxes,num_real_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tranfer Learning without Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comentamos la operacion de map en la función de tf_numpy_albumentations y ademas usamos la función preprocessing_validation, esto nos permitirá leer los datos sin data augmentatio, además usaremos la la opcion de mode=\"transfer\" para hacer No entrenables todas las capas menos las de detección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", dtype=int64)\n",
      "Tensor(\"add_18:0\", dtype=int64)\n",
      "338\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", dtype=int64)\n",
      "Tensor(\"add_30:0\", dtype=int64)\n",
      "1352\n",
      "Tensor(\"ArgMax:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", dtype=int64)\n",
      "Tensor(\"add_18:0\", dtype=int64)\n",
      "338\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", dtype=int64)\n",
      "Tensor(\"add_30:0\", dtype=int64)\n",
      "1352\n"
     ]
    }
   ],
   "source": [
    "#USANDO TF.IMAGE MODULE\n",
    "anchors =tf.constant(np.array([[0,0,0.026,0.062],[0,0,0.067,0.183],[0,0,0.128,0.323],[0,0,0.343,0.650]]),dtype=tf.float32)\n",
    "#anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_val_tfr_fixed\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset_val =tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")\n",
    "#.shuffle(70000)\n",
    "train_dataset = raw_image_dataset.map(preprocessing_validation_set,num_parallel_calls=8)\n",
    "#train_dataset = train_dataset.map(tf_numpy_albumentations_real,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "train_dataset = train_dataset.batch(16)\n",
    "\n",
    "val_dataset = raw_image_dataset_val.map(preprocessing_validation_set,num_parallel_calls=8)\n",
    "val_dataset = val_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "val_dataset = val_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef loss_bce_objectness(y_true,y_pred):\\n    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\\n    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\\n    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \\n    \\n    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*tf.math.log(y_pred+1e-7)[:,tf.newaxis],axis=1))\\n    \\n    return loss_obj\\n\\ndef loss_bce_no_objectness(y_true,y_pred):\\n    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\\n    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*tf.math.log(1-y_pred+1e-7)[:,tf.newaxis],axis=1))\\n    \\n    return loss_noobj\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import Loss,BinaryCrossentropy,MeanSquaredError,MeanSquaredLogarithmicError\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "'''\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tx_true-tx_pred))  \n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tx_true-tx_pred))  \n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tf.math.exp(tw_true),tf.math.exp(tw_pred))[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tf.math.exp(th_true),tf.math.exp(th_pred))[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "'''\n",
    "\n",
    "def loss_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_no_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    \n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj\n",
    "'''\n",
    "def loss_bce_objectness(y_true,y_pred):\n",
    "    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*tf.math.log(y_pred+1e-7)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_bce_no_objectness(y_true,y_pred):\n",
    "    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*tf.math.log(1-y_pred+1e-7)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n",
      "Pesos de la convolucion (432,)\n",
      "CONV SHAPE (16, 3, 3, 3)\n",
      "Pesos de la convolucion (4608,)\n",
      "CONV SHAPE (32, 16, 3, 3)\n",
      "Pesos de la convolucion (18432,)\n",
      "CONV SHAPE (64, 32, 3, 3)\n",
      "Pesos de la convolucion (73728,)\n",
      "CONV SHAPE (128, 64, 3, 3)\n",
      "Pesos de la convolucion (294912,)\n",
      "CONV SHAPE (256, 128, 3, 3)\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "Pesos de la convolucion (4718592,)\n",
      "CONV SHAPE (1024, 512, 3, 3)\n",
      "Pesos de la convolucion (262144,)\n",
      "CONV SHAPE (256, 1024, 1, 1)\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "Pesos de la convolucion (130560,)\n",
      "CONV SHAPE (255, 512, 1, 1)\n",
      "Pesos de la convolucion (32768,)\n",
      "CONV SHAPE (128, 256, 1, 1)\n",
      "Pesos de la convolucion (884736,)\n",
      "CONV SHAPE (256, 384, 3, 3)\n",
      "Pesos de la convolucion (65280,)\n",
      "CONV SHAPE (255, 256, 1, 1)\n",
      "8858734\n"
     ]
    }
   ],
   "source": [
    "anchors =tf.constant(np.array([[0.026,0.062],[0.067,0.183],[0.128,0.323],[0.343,0.650]]),dtype=tf.float32)\n",
    "#anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "model = TinyYOLOv3(1,anchor_boxes=anchors,train=True,mode = \"transfer\")\n",
    "model.build(batch_input_shape=(None,416,416,3))\n",
    "print(model.load_weights_darknet(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicBlock1 False\n",
      "BasicBlock2 False\n",
      "BasicBlock3 False\n",
      "BasicBlock4 False\n",
      "BasicBlock5 False\n",
      "BasicBlock6 False\n",
      "BasicBlock7 False\n",
      "BasicBlock8 False\n",
      "BasicBlock9 False\n",
      "FinalBlock1 True\n",
      "BasicBlock11 False\n",
      "BasicBlock12 False\n",
      "FinalBlock2 True\n",
      "Concatenate True\n",
      "Upsampling True\n",
      "Prediction1 True\n",
      "Prediction2 True\n",
      "Concatenate_BBOX True\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(l.name, l.trainable)#,l.weights[0].shape)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=1e-4)\n",
    "\n",
    "losses = {\"output_1\": loss_xy,\n",
    "          \"output_2\": loss_wh,\n",
    "          \"output_3\":loss_objectness,\n",
    "          \"output_4\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"output_3\":[Precision(0.5),Recall(0.5),TrueNegatives(0.5),TruePositives(0.5),FalseNegatives(0.5),FalsePositives(0.5)]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[5,5,2,1])\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento tipo transfer learning con lr = 0.0001 y por 20 epocas, la función de costo será con mse normal y sin Data Augmentation y ahora con 4 anchors totales, no con 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n",
      "Epoch 1/20\n",
      "Modo entrenamiento\n",
      "Modo entrenamiento\n",
      "   4607/Unknown - 189s 41ms/step - loss: 154.4877 - output_1_loss: 14.9517 - output_2_loss: 2.7908 - output_3_loss: 0.1695 - output_4_loss: 65.4361 - output_3_precision: 0.0065 - output_3_recall: 0.0264 - output_3_true_negatives: 123189080.0000 - output_3_true_positives: 7129.0000 - output_3_false_negatives: 262435.0000 - output_3_false_positives: 1091003.0000 175s 41ms/st - 182s 41ms/step - loss: 158.0786 - outp - 188s 41ms/step - loss: 154.9713 - output_1_loss: 14.9899 - output_2_loss: 2.7981 - output_3_loss: 0.1700 - output_4_loss: 65.6910 - output_3_precision: 0.0064 - output_3_recall: 0.0262 - output_3_true_negatives: 122538368.0000 - output_3_true_positives: 7031.0000 - output_3_false_negatives: 26Modo entrenamiento\n",
      "4607/4607 [==============================] - 196s 43ms/step - loss: 154.4877 - output_1_loss: 14.9517 - output_2_loss: 2.7908 - output_3_loss: 0.1695 - output_4_loss: 65.4361 - output_3_precision: 0.0065 - output_3_recall: 0.0264 - output_3_true_negatives: 123189080.0000 - output_3_true_positives: 7129.0000 - output_3_false_negatives: 262435.0000 - output_3_false_positives: 1091003.0000 - val_loss: 64.2858 - val_output_1_loss: 7.8328 - val_output_2_loss: 1.3932 - val_output_3_loss: 0.0791 - val_output_4_loss: 17.9981 - val_output_3_precision: 0.6248 - val_output_3_recall: 0.0531 - val_output_3_true_negatives: 5057844.0000 - val_output_3_true_positives: 626.0000 - val_output_3_false_negatives: 11154.0000 - val_output_3_false_positives: 376.0000\n",
      "Epoch 2/20\n",
      "4607/4607 [==============================] - 183s 40ms/step - loss: 53.5219 - output_1_loss: 6.7980 - output_2_loss: 0.9455 - output_3_loss: 0.0629 - output_4_loss: 14.6783 - output_3_precision: 0.5891 - output_3_recall: 0.0874 - output_3_true_negatives: 124263560.0000 - output_3_true_positives: 23563.0000 - output_3_false_negatives: 246001.0000 - output_3_false_positives: 16437.0000 - val_loss: 50.7811 - val_output_1_loss: 6.5279 - val_output_2_loss: 0.8321 - val_output_3_loss: 0.0623 - val_output_4_loss: 13.8567 - val_output_3_precision: 0.6097 - val_output_3_recall: 0.1373 - val_output_3_true_negatives: 5057185.0000 - val_output_3_true_positives: 1617.0000 - val_output_3_false_negatives: 10163.0000 - val_output_3_false_positives: 1035.0000\n",
      "Epoch 3/20\n",
      "4607/4607 [==============================] - 187s 41ms/step - loss: 46.8805 - output_1_loss: 6.1371 - output_2_loss: 0.6714 - output_3_loss: 0.0553 - output_4_loss: 12.7274 - output_3_precision: 0.5911 - output_3_recall: 0.1434 - output_3_true_negatives: 124253464.0000 - output_3_true_positives: 38646.0000 - output_3_false_negatives: 230918.0000 - output_3_false_positives: 26729.0000 - val_loss: 47.1808 - val_output_1_loss: 6.1334 - val_output_2_loss: 0.6941 - val_output_3_loss: 0.0584 - val_output_4_loss: 12.9267 - val_output_3_precision: 0.6191 - val_output_3_recall: 0.1704 - val_output_3_true_negatives: 5056985.0000 - val_output_3_true_positives: 2007.0000 - val_output_3_false_negatives: 9773.0000 - val_output_3_false_positives: 1235.0000\n",
      "Epoch 4/20\n",
      "4607/4607 [==============================] - 185s 40ms/step - loss: 44.7785 - output_1_loss: 5.8884 - output_2_loss: 0.5980 - output_3_loss: 0.0532 - output_4_loss: 12.2398 - output_3_precision: 0.6109 - output_3_recall: 0.1582 - output_3_true_negatives: 124253000.0000 - output_3_true_positives: 42648.0000 - output_3_false_negatives: 226916.0000 - output_3_false_positives: 27160.0000 - val_loss: 45.7832 - val_output_1_loss: 5.9527 - val_output_2_loss: 0.6527 - val_output_3_loss: 0.0571 - val_output_4_loss: 12.6417 - val_output_3_precision: 0.6313 - val_output_3_recall: 0.1794 - val_output_3_true_negatives: 5056986.0000 - val_output_3_true_positives: 2113.0000 - val_output_3_false_negatives: 9667.0000 - val_output_3_false_positives: 1234.0000\n",
      "Epoch 5/20\n",
      "4607/4607 [==============================] - 186s 40ms/step - loss: 43.8674 - output_1_loss: 5.7623 - output_2_loss: 0.5743 - output_3_loss: 0.0525 - output_4_loss: 12.0793 - output_3_precision: 0.6203 - output_3_recall: 0.1631 - output_3_true_negatives: 124253208.0000 - output_3_true_positives: 43970.0000 - output_3_false_negatives: 225594.0000 - output_3_false_positives: 26914.0000 - val_loss: 45.0973 - val_output_1_loss: 5.8540 - val_output_2_loss: 0.6375 - val_output_3_loss: 0.0566 - val_output_4_loss: 12.5263 - val_output_3_precision: 0.6397 - val_output_3_recall: 0.1827 - val_output_3_true_negatives: 5057008.0000 - val_output_3_true_positives: 2152.0000 - val_output_3_false_negatives: 9628.0000 - val_output_3_false_positives: 1212.0000\n",
      "Epoch 6/20\n",
      "4607/4607 [==============================] - 187s 41ms/step - loss: 43.3810 - output_1_loss: 5.6891 - output_2_loss: 0.5651 - output_3_loss: 0.0521 - output_4_loss: 12.0060 - output_3_precision: 0.6254 - output_3_recall: 0.1657 - output_3_true_negatives: 124253384.0000 - output_3_true_positives: 44674.0000 - output_3_false_negatives: 224890.0000 - output_3_false_positives: 26754.0000 - val_loss: 44.7019 - val_output_1_loss: 5.7939 - val_output_2_loss: 0.6309 - val_output_3_loss: 0.0563 - val_output_4_loss: 12.4657 - val_output_3_precision: 0.6455 - val_output_3_recall: 0.1844 - val_output_3_true_negatives: 5057027.0000 - val_output_3_true_positives: 2172.0000 - val_output_3_false_negatives: 9608.0000 - val_output_3_false_positives: 1193.0000\n",
      "Epoch 7/20\n",
      "4607/4607 [==============================] - 188s 41ms/step - loss: 43.0855 - output_1_loss: 5.6425 - output_2_loss: 0.5609 - output_3_loss: 0.0520 - output_4_loss: 11.9647 - output_3_precision: 0.6269 - output_3_recall: 0.1672 - output_3_true_negatives: 124253208.0000 - output_3_true_positives: 45083.0000 - output_3_false_negatives: 224481.0000 - output_3_false_positives: 26831.0000 - val_loss: 44.4489 - val_output_1_loss: 5.7540 - val_output_2_loss: 0.6275 - val_output_3_loss: 0.0562 - val_output_4_loss: 12.4291 - val_output_3_precision: 0.6462 - val_output_3_recall: 0.1850 - val_output_3_true_negatives: 5057027.0000 - val_output_3_true_positives: 2179.0000 - val_output_3_false_negatives: 9601.0000 - val_output_3_false_positives: 1193.0000\n",
      "Epoch 8/20\n",
      "4607/4607 [==============================] - 184s 40ms/step - loss: 42.8894 - output_1_loss: 5.6107 - output_2_loss: 0.5587 - output_3_loss: 0.0519 - output_4_loss: 11.9388 - output_3_precision: 0.6280 - output_3_recall: 0.1681 - output_3_true_negatives: 124253224.0000 - output_3_true_positives: 45313.0000 - output_3_false_negatives: 224251.0000 - output_3_false_positives: 26841.0000 - val_loss: 44.2742 - val_output_1_loss: 5.7258 - val_output_2_loss: 0.6256 - val_output_3_loss: 0.0561 - val_output_4_loss: 12.4050 - val_output_3_precision: 0.6508 - val_output_3_recall: 0.1865 - val_output_3_true_negatives: 5057041.0000 - val_output_3_true_positives: 2197.0000 - val_output_3_false_negatives: 9583.0000 - val_output_3_false_positives: 1179.0000\n",
      "Epoch 9/20\n",
      "4607/4607 [==============================] - 181s 39ms/step - loss: 42.7502 - output_1_loss: 5.5876 - output_2_loss: 0.5575 - output_3_loss: 0.0518 - output_4_loss: 11.9212 - output_3_precision: 0.6289 - output_3_recall: 0.1688 - output_3_true_negatives: 124253160.0000 - output_3_true_positives: 45489.0000 - output_3_false_negatives: 224075.0000 - output_3_false_positives: 26837.0000 - val_loss: 44.1459 - val_output_1_loss: 5.7047 - val_output_2_loss: 0.6244 - val_output_3_loss: 0.0560 - val_output_4_loss: 12.3883 - val_output_3_precision: 0.6500 - val_output_3_recall: 0.1865 - val_output_3_true_negatives: 5057037.0000 - val_output_3_true_positives: 2197.0000 - val_output_3_false_negatives: 9583.0000 - val_output_3_false_positives: 1183.0000\n",
      "Epoch 10/20\n",
      "4607/4607 [==============================] - 181s 39ms/step - loss: 42.6457 - output_1_loss: 5.5699 - output_2_loss: 0.5568 - output_3_loss: 0.0517 - output_4_loss: 11.9088 - output_3_precision: 0.6297 - output_3_recall: 0.1692 - output_3_true_negatives: 124253240.0000 - output_3_true_positives: 45607.0000 - output_3_false_negatives: 223957.0000 - output_3_false_positives: 26821.0000 - val_loss: 44.0469 - val_output_1_loss: 5.6882 - val_output_2_loss: 0.6236 - val_output_3_loss: 0.0559 - val_output_4_loss: 12.3762 - val_output_3_precision: 0.6521 - val_output_3_recall: 0.1874 - val_output_3_true_negatives: 5057042.0000 - val_output_3_true_positives: 2208.0000 - val_output_3_false_negatives: 9572.0000 - val_output_3_false_positives: 1178.0000\n",
      "Epoch 11/20\n",
      "4607/4607 [==============================] - 183s 40ms/step - loss: 42.5637 - output_1_loss: 5.5558 - output_2_loss: 0.5563 - output_3_loss: 0.0517 - output_4_loss: 11.8996 - output_3_precision: 0.6298 - output_3_recall: 0.1695 - output_3_true_negatives: 124253224.0000 - output_3_true_positives: 45701.0000 - output_3_false_negatives: 223863.0000 - output_3_false_positives: 26865.0000 - val_loss: 43.9672 - val_output_1_loss: 5.6746 - val_output_2_loss: 0.6231 - val_output_3_loss: 0.0559 - val_output_4_loss: 12.3672 - val_output_3_precision: 0.6515 - val_output_3_recall: 0.1874 - val_output_3_true_negatives: 5057039.0000 - val_output_3_true_positives: 2208.0000 - val_output_3_false_negatives: 9572.0000 - val_output_3_false_positives: 1181.0000\n",
      "Epoch 12/20\n",
      "4607/4607 [==============================] - 184s 40ms/step - loss: 42.4966 - output_1_loss: 5.5441 - output_2_loss: 0.5560 - output_3_loss: 0.0517 - output_4_loss: 11.8927 - output_3_precision: 0.6303 - output_3_recall: 0.1699 - output_3_true_negatives: 124253320.0000 - output_3_true_positives: 45792.0000 - output_3_false_negatives: 223772.0000 - output_3_false_positives: 26858.0000 - val_loss: 43.9006 - val_output_1_loss: 5.6630 - val_output_2_loss: 0.6227 - val_output_3_loss: 0.0559 - val_output_4_loss: 12.3603 - val_output_3_precision: 0.6500 - val_output_3_recall: 0.1870 - val_output_3_true_negatives: 5057034.0000 - val_output_3_true_positives: 2203.0000 - val_output_3_false_negatives: 9577.0000 - val_output_3_false_positives: 1186.0000\n",
      "Epoch 13/20\n",
      "4607/4607 [==============================] - 184s 40ms/step - loss: 42.4400 - output_1_loss: 5.5341 - output_2_loss: 0.5558 - output_3_loss: 0.0516 - output_4_loss: 11.8873 - output_3_precision: 0.6304 - output_3_recall: 0.1702 - output_3_true_negatives: 124253288.0000 - output_3_true_positives: 45870.0000 - output_3_false_negatives: 223694.0000 - output_3_false_positives: 26893.0000 - val_loss: 43.8434 - val_output_1_loss: 5.6530 - val_output_2_loss: 0.6224 - val_output_3_loss: 0.0558 - val_output_4_loss: 12.3549 - val_output_3_precision: 0.6493 - val_output_3_recall: 0.1866 - val_output_3_true_negatives: 5057033.0000 - val_output_3_true_positives: 2198.0000 - val_output_3_false_negatives: 9582.0000 - val_output_3_false_positives: 1187.0000\n",
      "Epoch 14/20\n",
      "4607/4607 [==============================] - 184s 40ms/step - loss: 42.3908 - output_1_loss: 5.5253 - output_2_loss: 0.5556 - output_3_loss: 0.0516 - output_4_loss: 11.8830 - output_3_precision: 0.6310 - output_3_recall: 0.1705 - output_3_true_negatives: 124253256.0000 - output_3_true_positives: 45959.0000 - output_3_false_negatives: 223605.0000 - output_3_false_positives: 26877.0000 - val_loss: 43.7930 - val_output_1_loss: 5.6440 - val_output_2_loss: 0.6222 - val_output_3_loss: 0.0558 - val_output_4_loss: 12.3505 - val_output_3_precision: 0.6489 - val_output_3_recall: 0.1862 - val_output_3_true_negatives: 5057033.0000 - val_output_3_true_positives: 2194.0000 - val_output_3_false_negatives: 9586.0000 - val_output_3_false_positives: 1187.0000\n",
      "Epoch 15/20\n",
      "4607/4607 [==============================] - 193s 42ms/step - loss: 42.3471 - output_1_loss: 5.5174 - output_2_loss: 0.5555 - output_3_loss: 0.0516 - output_4_loss: 11.8796 - output_3_precision: 0.6311 - output_3_recall: 0.1707 - output_3_true_negatives: 124253304.0000 - output_3_true_positives: 46026.0000 - output_3_false_negatives: 223538.0000 - output_3_false_positives: 26904.0000 - val_loss: 43.7477 - val_output_1_loss: 5.6358 - val_output_2_loss: 0.6220 - val_output_3_loss: 0.0558 - val_output_4_loss: 12.3470 - val_output_3_precision: 0.6482 - val_output_3_recall: 0.1862 - val_output_3_true_negatives: 5057029.0000 - val_output_3_true_positives: 2194.0000 - val_output_3_false_negatives: 9586.0000 - val_output_3_false_positives: 1191.0000\n",
      "Epoch 16/20\n",
      "4607/4607 [==============================] - 192s 42ms/step - loss: 42.3075 - output_1_loss: 5.5101 - output_2_loss: 0.5554 - output_3_loss: 0.0516 - output_4_loss: 11.8767 - output_3_precision: 0.6311 - output_3_recall: 0.1708 - output_3_true_negatives: 124253208.0000 - output_3_true_positives: 46045.0000 - output_3_false_negatives: 223519.0000 - output_3_false_positives: 26914.0000 - val_loss: 43.7063 - val_output_1_loss: 5.6283 - val_output_2_loss: 0.6218 - val_output_3_loss: 0.0558 - val_output_4_loss: 12.3440 - val_output_3_precision: 0.6467 - val_output_3_recall: 0.1862 - val_output_3_true_negatives: 5057022.0000 - val_output_3_true_positives: 2193.0000 - val_output_3_false_negatives: 9587.0000 - val_output_3_false_positives: 1198.0000\n",
      "Epoch 17/20\n",
      "4607/4607 [==============================] - 192s 42ms/step - loss: 42.2711 - output_1_loss: 5.5034 - output_2_loss: 0.5553 - output_3_loss: 0.0516 - output_4_loss: 11.8744 - output_3_precision: 0.6311 - output_3_recall: 0.1710 - output_3_true_negatives: 124253224.0000 - output_3_true_positives: 46084.0000 - output_3_false_negatives: 223480.0000 - output_3_false_positives: 26939.0000 - val_loss: 43.6680 - val_output_1_loss: 5.6212 - val_output_2_loss: 0.6217 - val_output_3_loss: 0.0558 - val_output_4_loss: 12.3416 - val_output_3_precision: 0.6471 - val_output_3_recall: 0.1860 - val_output_3_true_negatives: 5057025.0000 - val_output_3_true_positives: 2191.0000 - val_output_3_false_negatives: 9589.0000 - val_output_3_false_positives: 1195.0000\n",
      "Epoch 18/20\n",
      "4607/4607 [==============================] - 190s 41ms/step - loss: 42.2373 - output_1_loss: 5.4971 - output_2_loss: 0.5553 - output_3_loss: 0.0516 - output_4_loss: 11.8723 - output_3_precision: 0.6311 - output_3_recall: 0.1710 - output_3_true_negatives: 124253248.0000 - output_3_true_positives: 46098.0000 - output_3_false_negatives: 223466.0000 - output_3_false_positives: 26946.0000 - val_loss: 43.6321 - val_output_1_loss: 5.6146 - val_output_2_loss: 0.6216 - val_output_3_loss: 0.0558 - val_output_4_loss: 12.3395 - val_output_3_precision: 0.6473 - val_output_3_recall: 0.1860 - val_output_3_true_negatives: 5057026.0000 - val_output_3_true_positives: 2191.0000 - val_output_3_false_negatives: 9589.0000 - val_output_3_false_positives: 1194.0000\n",
      "Epoch 19/20\n",
      "4607/4607 [==============================] - 186s 40ms/step - loss: 42.2055 - output_1_loss: 5.4911 - output_2_loss: 0.5552 - output_3_loss: 0.0516 - output_4_loss: 11.8706 - output_3_precision: 0.6311 - output_3_recall: 0.1711 - output_3_true_negatives: 124253152.0000 - output_3_true_positives: 46116.0000 - output_3_false_negatives: 223448.0000 - output_3_false_positives: 26953.0000 - val_loss: 43.5983 - val_output_1_loss: 5.6083 - val_output_2_loss: 0.6215 - val_output_3_loss: 0.0558 - val_output_4_loss: 12.3376 - val_output_3_precision: 0.6470 - val_output_3_recall: 0.1864 - val_output_3_true_negatives: 5057022.0000 - val_output_3_true_positives: 2196.0000 - val_output_3_false_negatives: 9584.0000 - val_output_3_false_positives: 1198.0000\n",
      "Epoch 20/20\n",
      "4607/4607 [==============================] - 183s 40ms/step - loss: 42.1753 - output_1_loss: 5.4855 - output_2_loss: 0.5552 - output_3_loss: 0.0516 - output_4_loss: 11.8691 - output_3_precision: 0.6312 - output_3_recall: 0.1711 - output_3_true_negatives: 124253152.0000 - output_3_true_positives: 46134.0000 - output_3_false_negatives: 223430.0000 - output_3_false_positives: 26957.0000 - val_loss: 43.5662 - val_output_1_loss: 5.6023 - val_output_2_loss: 0.6215 - val_output_3_loss: 0.0558 - val_output_4_loss: 12.3361 - val_output_3_precision: 0.6471 - val_output_3_recall: 0.1865 - val_output_3_true_negatives: 5057022.0000 - val_output_3_true_positives: 2197.0000 - val_output_3_false_negatives: 9583.0000 - val_output_3_false_positives: 1198.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/sergio/Documents/json_experiments\")\n",
    "import json\n",
    "#json.dumps(str(a))\n",
    "with open('history_transfer_5521_20_epoch_nadam_0dot00001_mse_2anchors.json', 'w') as fp:\n",
    "    json.dump(str(history.history), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/sergio/Documents/weights_saved/pesos_5521_20_epoch_nadam_0dot00001_mse_2anchors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ME FALTA PROBAR 2 ANCHORS CON DATA AUGMENTATIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning with Data Augmentation 20 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento tipo transfer learning con lr = 0.00001 y por 10 epocas, la función de costo será con mse normal y sin Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la opcion de mode=\"transfer\" para hacer No entrenables todas las capas menos las de detección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", shape=(None,), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "507\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "2028\n",
      "Tensor(\"ArgMax:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", dtype=int64)\n",
      "Tensor(\"add_18:0\", dtype=int64)\n",
      "507\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", dtype=int64)\n",
      "Tensor(\"add_30:0\", dtype=int64)\n",
      "2028\n"
     ]
    }
   ],
   "source": [
    "#USANDO TF.IMAGE MODULE\n",
    "#anchors =tf.constant(np.array([[0,0,0.015,0.037],[0,0,0.043,0.104],[0,0,0.11,0.278],[0,0,0.351,0.66]]),dtype=tf.float32)\n",
    "#anchors =tf.constant(np.array([[0,0,0.026,0.062],[0,0,0.067,0.183],[0,0,0.128,0.323],[0,0,0.343,0.650]]),dtype=tf.float32)\n",
    "anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_val_tfr_fixed\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset_val =tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")\n",
    "#.shuffle(70000)\n",
    "train_dataset = raw_image_dataset.map(preprocessing,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(tf_numpy_albumentations_real,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "train_dataset = train_dataset.batch(16)\n",
    "\n",
    "val_dataset = raw_image_dataset_val.map(preprocessing_validation_set,num_parallel_calls=8)\n",
    "val_dataset = val_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "val_dataset = val_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef loss_bce_objectness(y_true,y_pred):\\n    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\\n    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\\n    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \\n    \\n    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*tf.math.log(y_pred+1e-7)[:,tf.newaxis],axis=1))\\n    \\n    return loss_obj\\n\\ndef loss_bce_no_objectness(y_true,y_pred):\\n    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\\n    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*tf.math.log(1-y_pred+1e-7)[:,tf.newaxis],axis=1))\\n    \\n    return loss_noobj\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import Loss,BinaryCrossentropy,MeanSquaredError,MeanSquaredLogarithmicError\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "'''\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tx_true-tx_pred))  \n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tx_true-tx_pred))  \n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tf.math.exp(tw_true),tf.math.exp(tw_pred))[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tf.math.exp(th_true),tf.math.exp(th_pred))[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "'''\n",
    "\n",
    "def loss_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_no_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    \n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj\n",
    "'''\n",
    "def loss_bce_objectness(y_true,y_pred):\n",
    "    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*tf.math.log(y_pred+1e-7)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_bce_no_objectness(y_true,y_pred):\n",
    "    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*tf.math.log(1-y_pred+1e-7)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n",
      "Pesos de la convolucion (432,)\n",
      "CONV SHAPE (16, 3, 3, 3)\n",
      "Pesos de la convolucion (4608,)\n",
      "CONV SHAPE (32, 16, 3, 3)\n",
      "Pesos de la convolucion (18432,)\n",
      "CONV SHAPE (64, 32, 3, 3)\n",
      "Pesos de la convolucion (73728,)\n",
      "CONV SHAPE (128, 64, 3, 3)\n",
      "Pesos de la convolucion (294912,)\n",
      "CONV SHAPE (256, 128, 3, 3)\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "Pesos de la convolucion (4718592,)\n",
      "CONV SHAPE (1024, 512, 3, 3)\n",
      "Pesos de la convolucion (262144,)\n",
      "CONV SHAPE (256, 1024, 1, 1)\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "Pesos de la convolucion (130560,)\n",
      "CONV SHAPE (255, 512, 1, 1)\n",
      "Pesos de la convolucion (32768,)\n",
      "CONV SHAPE (128, 256, 1, 1)\n",
      "Pesos de la convolucion (884736,)\n",
      "CONV SHAPE (256, 384, 3, 3)\n",
      "Pesos de la convolucion (65280,)\n",
      "CONV SHAPE (255, 256, 1, 1)\n",
      "8858734\n"
     ]
    }
   ],
   "source": [
    "#anchors =tf.constant(np.array([[0.026,0.062],[0.067,0.183],[0.128,0.323],[0.343,0.650]]),dtype=tf.float32)\n",
    "anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "model = TinyYOLOv3(1,anchor_boxes=anchors,train=True,mode = \"transfer\")\n",
    "model.build(batch_input_shape=(None,416,416,3))\n",
    "print(model.load_weights_darknet(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicBlock1 False\n",
      "BasicBlock2 False\n",
      "BasicBlock3 False\n",
      "BasicBlock4 False\n",
      "BasicBlock5 False\n",
      "BasicBlock6 False\n",
      "BasicBlock7 False\n",
      "BasicBlock8 False\n",
      "BasicBlock9 False\n",
      "FinalBlock1 True\n",
      "BasicBlock11 False\n",
      "BasicBlock12 False\n",
      "FinalBlock2 True\n",
      "Concatenate True\n",
      "Upsampling True\n",
      "Prediction1 True\n",
      "Prediction2 True\n",
      "Concatenate_BBOX True\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(l.name, l.trainable)#,l.weights[0].shape)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=1e-4)\n",
    "\n",
    "losses = {\"output_1\": loss_xy,\n",
    "          \"output_2\": loss_wh,\n",
    "          \"output_3\":loss_objectness,\n",
    "          \"output_4\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"output_3\":[Precision(0.5),Recall(0.5),TrueNegatives(0.5),TruePositives(0.5),FalseNegatives(0.5),FalsePositives(0.5)]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[5,5,2,1])\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n",
      "Epoch 1/20\n",
      "Modo entrenamiento\n",
      "Modo entrenamiento\n",
      "   4607/Unknown - 258s 56ms/step - loss: 208.7107 - output_1_loss: 15.5679 - output_2_loss: 5.2651 - output_3_loss: 0.1672 - output_4_loss: 104.2111 - output_3_precision_2: 0.0020 - output_3_recall_2: 0.0150 - output_3_true_negatives_2: 184550240.0000 - output_3_true_positives_2: 4045.0000 - output_3_false_negatives_2: 266137.0000 - output_3_false_positives_2: 2004241.0000- 257s 56ms/step - loss: 209.0696 - output_1_loss: 15.5862 - output_2_loss: 5.2699 - output_3_loss: 0.1675 - output_4_loss: 104.4539 - output_3_precision_2: 0.0020 - output_3_recall_2: 0.0150 - output_3_true_negatives_2: 184018800.0000 - output_3_true_positives_2: 4031.0000 - output_3_false_negatives_2: 265266.0000 - output_3_false_positives_2Modo entrenamiento\n",
      "4607/4607 [==============================] - 265s 57ms/step - loss: 208.7107 - output_1_loss: 15.5679 - output_2_loss: 5.2651 - output_3_loss: 0.1672 - output_4_loss: 104.2111 - output_3_precision_2: 0.0020 - output_3_recall_2: 0.0150 - output_3_true_negatives_2: 184550240.0000 - output_3_true_positives_2: 4045.0000 - output_3_false_negatives_2: 266137.0000 - output_3_false_positives_2: 2004241.0000 - val_loss: 70.3257 - val_output_1_loss: 8.0451 - val_output_2_loss: 1.6328 - val_output_3_loss: 0.0633 - val_output_4_loss: 21.8092 - val_output_3_precision_2: 0.6327 - val_output_3_recall_2: 0.0200 - val_output_3_true_negatives_2: 7593039.0000 - val_output_3_true_positives_2: 236.0000 - val_output_3_false_negatives_2: 11588.0000 - val_output_3_false_positives_2: 137.0000\n",
      "Epoch 2/20\n",
      "4607/4607 [==============================] - 266s 58ms/step - loss: 70.6035 - output_1_loss: 7.3572 - output_2_loss: 3.0439 - output_3_loss: 0.0531 - output_4_loss: 18.4915 - output_3_precision_2: 0.5534 - output_3_recall_2: 0.0358 - output_3_true_negatives_2: 186546528.0000 - output_3_true_positives_2: 9663.0000 - output_3_false_negatives_2: 260533.0000 - output_3_false_positives_2: 7799.0000 - val_loss: 54.7817 - val_output_1_loss: 6.6834 - val_output_2_loss: 1.1203 - val_output_3_loss: 0.0468 - val_output_4_loss: 15.6699 - val_output_3_precision_2: 0.6177 - val_output_3_recall_2: 0.0719 - val_output_3_true_negatives_2: 7592650.0000 - val_output_3_true_positives_2: 850.0000 - val_output_3_false_negatives_2: 10974.0000 - val_output_3_false_positives_2: 526.0000\n",
      "Epoch 3/20\n",
      "4607/4607 [==============================] - 266s 58ms/step - loss: 62.4088 - output_1_loss: 6.7014 - output_2_loss: 2.6110 - output_3_loss: 0.0461 - output_4_loss: 15.7542 - output_3_precision_2: 0.5467 - output_3_recall_2: 0.0681 - output_3_true_negatives_2: 186539072.0000 - output_3_true_positives_2: 18386.0000 - output_3_false_negatives_2: 251789.0000 - output_3_false_positives_2: 15247.0000 - val_loss: 50.8067 - val_output_1_loss: 6.2644 - val_output_2_loss: 0.9906 - val_output_3_loss: 0.0435 - val_output_4_loss: 14.4447 - val_output_3_precision_2: 0.6068 - val_output_3_recall_2: 0.1048 - val_output_3_true_negatives_2: 7592373.0000 - val_output_3_true_positives_2: 1239.0000 - val_output_3_false_negatives_2: 10585.0000 - val_output_3_false_positives_2: 803.0000\n",
      "Epoch 4/20\n",
      "4607/4607 [==============================] - 266s 58ms/step - loss: 59.3148 - output_1_loss: 6.4119 - output_2_loss: 2.4289 - output_3_loss: 0.0440 - output_4_loss: 15.0231 - output_3_precision_2: 0.5555 - output_3_recall_2: 0.0788 - output_3_true_negatives_2: 186537136.0000 - output_3_true_positives_2: 21287.0000 - output_3_false_negatives_2: 248987.0000 - output_3_false_positives_2: 17030.0000 - val_loss: 49.1144 - val_output_1_loss: 6.0657 - val_output_2_loss: 0.9219 - val_output_3_loss: 0.0424 - val_output_4_loss: 14.0919 - val_output_3_precision_2: 0.6295 - val_output_3_recall_2: 0.1071 - val_output_3_true_negatives_2: 7592431.0000 - val_output_3_true_positives_2: 1266.0000 - val_output_3_false_negatives_2: 10558.0000 - val_output_3_false_positives_2: 745.0000\n",
      "Epoch 5/20\n",
      "4607/4607 [==============================] - 267s 58ms/step - loss: 57.9875 - output_1_loss: 6.2543 - output_2_loss: 2.3588 - output_3_loss: 0.0435 - output_4_loss: 14.8347 - output_3_precision_2: 0.5689 - output_3_recall_2: 0.0816 - output_3_true_negatives_2: 186537472.0000 - output_3_true_positives_2: 22066.0000 - output_3_false_negatives_2: 248190.0000 - output_3_false_positives_2: 16723.0000 - val_loss: 48.4812 - val_output_1_loss: 5.9579 - val_output_2_loss: 0.9285 - val_output_3_loss: 0.0420 - val_output_4_loss: 13.9655 - val_output_3_precision_2: 0.6429 - val_output_3_recall_2: 0.1105 - val_output_3_true_negatives_2: 7592450.0000 - val_output_3_true_positives_2: 1307.0000 - val_output_3_false_negatives_2: 10517.0000 - val_output_3_false_positives_2: 726.0000\n",
      "Epoch 6/20\n",
      "4607/4607 [==============================] - 270s 59ms/step - loss: 57.2561 - output_1_loss: 6.1166 - output_2_loss: 2.3867 - output_3_loss: 0.0429 - output_4_loss: 14.6539 - output_3_precision_2: 0.5722 - output_3_recall_2: 0.0845 - output_3_true_negatives_2: 186537200.0000 - output_3_true_positives_2: 22831.0000 - output_3_false_negatives_2: 247385.0000 - output_3_false_positives_2: 17070.0000 - val_loss: 48.0324 - val_output_1_loss: 5.8869 - val_output_2_loss: 0.9326 - val_output_3_loss: 0.0417 - val_output_4_loss: 13.8512 - val_output_3_precision_2: 0.6389 - val_output_3_recall_2: 0.1154 - val_output_3_true_negatives_2: 7592405.0000 - val_output_3_true_positives_2: 1364.0000 - val_output_3_false_negatives_2: 10460.0000 - val_output_3_false_positives_2: 771.0000\n",
      "Epoch 7/20\n",
      "4607/4607 [==============================] - 271s 59ms/step - loss: 57.1967 - output_1_loss: 6.1004 - output_2_loss: 2.3987 - output_3_loss: 0.0429 - output_4_loss: 14.6152 - output_3_precision_2: 0.5728 - output_3_recall_2: 0.0846 - output_3_true_negatives_2: 186536800.0000 - output_3_true_positives_2: 22855.0000 - output_3_false_negatives_2: 247386.0000 - output_3_false_positives_2: 17043.0000 - val_loss: 47.7714 - val_output_1_loss: 5.8297 - val_output_2_loss: 0.9454 - val_output_3_loss: 0.0416 - val_output_4_loss: 13.8128 - val_output_3_precision_2: 0.6408 - val_output_3_recall_2: 0.1172 - val_output_3_true_negatives_2: 7592399.0000 - val_output_3_true_positives_2: 1386.0000 - val_output_3_false_negatives_2: 10438.0000 - val_output_3_false_positives_2: 777.0000\n",
      "Epoch 8/20\n",
      "4607/4607 [==============================] - 274s 59ms/step - loss: 56.5074 - output_1_loss: 6.0634 - output_2_loss: 2.3114 - output_3_loss: 0.0426 - output_4_loss: 14.5478 - output_3_precision_2: 0.5788 - output_3_recall_2: 0.0863 - output_3_true_negatives_2: 186537024.0000 - output_3_true_positives_2: 23320.0000 - output_3_false_negatives_2: 246866.0000 - output_3_false_positives_2: 16969.0000 - val_loss: 47.4268 - val_output_1_loss: 5.8125 - val_output_2_loss: 0.8983 - val_output_3_loss: 0.0415 - val_output_4_loss: 13.7898 - val_output_3_precision_2: 0.6460 - val_output_3_recall_2: 0.1164 - val_output_3_true_negatives_2: 7592422.0000 - val_output_3_true_positives_2: 1376.0000 - val_output_3_false_negatives_2: 10448.0000 - val_output_3_false_positives_2: 754.0000\n",
      "Epoch 9/20\n",
      "4607/4607 [==============================] - 273s 59ms/step - loss: 56.8517 - output_1_loss: 6.0268 - output_2_loss: 2.4210 - output_3_loss: 0.0426 - output_4_loss: 14.5277 - output_3_precision_2: 0.5781 - output_3_recall_2: 0.0871 - output_3_true_negatives_2: 186536576.0000 - output_3_true_positives_2: 23539.0000 - output_3_false_negatives_2: 246680.0000 - output_3_false_positives_2: 17178.0000 - val_loss: 47.3572 - val_output_1_loss: 5.7764 - val_output_2_loss: 0.9252 - val_output_3_loss: 0.0414 - val_output_4_loss: 13.7667 - val_output_3_precision_2: 0.6471 - val_output_3_recall_2: 0.1165 - val_output_3_true_negatives_2: 7592425.0000 - val_output_3_true_positives_2: 1377.0000 - val_output_3_false_negatives_2: 10447.0000 - val_output_3_false_positives_2: 751.0000\n",
      "Epoch 10/20\n",
      "4607/4607 [==============================] - 274s 59ms/step - loss: 56.2563 - output_1_loss: 5.9974 - output_2_loss: 2.3343 - output_3_loss: 0.0425 - output_4_loss: 14.5130 - output_3_precision_2: 0.5776 - output_3_recall_2: 0.0869 - output_3_true_negatives_2: 186537280.0000 - output_3_true_positives_2: 23478.0000 - output_3_false_negatives_2: 246723.0000 - output_3_false_positives_2: 17171.0000 - val_loss: 47.2087 - val_output_1_loss: 5.7583 - val_output_2_loss: 0.9175 - val_output_3_loss: 0.0414 - val_output_4_loss: 13.7471 - val_output_3_precision_2: 0.6466 - val_output_3_recall_2: 0.1170 - val_output_3_true_negatives_2: 7592420.0000 - val_output_3_true_positives_2: 1383.0000 - val_output_3_false_negatives_2: 10441.0000 - val_output_3_false_positives_2: 756.0000\n",
      "Epoch 11/20\n",
      "4607/4607 [==============================] - 272s 59ms/step - loss: 56.7027 - output_1_loss: 5.9978 - output_2_loss: 2.4260 - output_3_loss: 0.0425 - output_4_loss: 14.4991 - output_3_precision_2: 0.5773 - output_3_recall_2: 0.0864 - output_3_true_negatives_2: 186537136.0000 - output_3_true_positives_2: 23360.0000 - output_3_false_negatives_2: 246868.0000 - output_3_false_positives_2: 17102.0000 - val_loss: 47.2142 - val_output_1_loss: 5.7383 - val_output_2_loss: 0.9430 - val_output_3_loss: 0.0413 - val_output_4_loss: 13.7252 - val_output_3_precision_2: 0.6395 - val_output_3_recall_2: 0.1188 - val_output_3_true_negatives_2: 7592384.0000 - val_output_3_true_positives_2: 1405.0000 - val_output_3_false_negatives_2: 10419.0000 - val_output_3_false_positives_2: 792.0000\n",
      "Epoch 12/20\n",
      "4607/4607 [==============================] - 270s 59ms/step - loss: 56.0088 - output_1_loss: 5.9709 - output_2_loss: 2.3176 - output_3_loss: 0.0425 - output_4_loss: 14.4815 - output_3_precision_2: 0.5794 - output_3_recall_2: 0.0876 - output_3_true_negatives_2: 186536464.0000 - output_3_true_positives_2: 23672.0000 - output_3_false_negatives_2: 246687.0000 - output_3_false_positives_2: 17182.0000 - val_loss: 46.9006 - val_output_1_loss: 5.7236 - val_output_2_loss: 0.8968 - val_output_3_loss: 0.0413 - val_output_4_loss: 13.7161 - val_output_3_precision_2: 0.6422 - val_output_3_recall_2: 0.1186 - val_output_3_true_negatives_2: 7592395.0000 - val_output_3_true_positives_2: 1402.0000 - val_output_3_false_negatives_2: 10422.0000 - val_output_3_false_positives_2: 781.0000\n",
      "Epoch 13/20\n",
      "4607/4607 [==============================] - 271s 59ms/step - loss: 55.9493 - output_1_loss: 5.9648 - output_2_loss: 2.3078 - output_3_loss: 0.0425 - output_4_loss: 14.5011 - output_3_precision_2: 0.5796 - output_3_recall_2: 0.0875 - output_3_true_negatives_2: 186536816.0000 - output_3_true_positives_2: 23651.0000 - output_3_false_negatives_2: 246629.0000 - output_3_false_positives_2: 17158.0000 - val_loss: 46.9584 - val_output_1_loss: 5.7258 - val_output_2_loss: 0.9045 - val_output_3_loss: 0.0413 - val_output_4_loss: 13.7241 - val_output_3_precision_2: 0.6419 - val_output_3_recall_2: 0.1193 - val_output_3_true_negatives_2: 7592389.0000 - val_output_3_true_positives_2: 1411.0000 - val_output_3_false_negatives_2: 10413.0000 - val_output_3_false_positives_2: 787.0000\n",
      "Epoch 14/20\n",
      "4607/4607 [==============================] - 269s 58ms/step - loss: 56.2724 - output_1_loss: 5.9847 - output_2_loss: 2.3664 - output_3_loss: 0.0423 - output_4_loss: 14.4321 - output_3_precision_2: 0.5831 - output_3_recall_2: 0.0890 - output_3_true_negatives_2: 186537216.0000 - output_3_true_positives_2: 24038.0000 - output_3_false_negatives_2: 246122.0000 - output_3_false_positives_2: 17187.0000 - val_loss: 46.8380 - val_output_1_loss: 5.7026 - val_output_2_loss: 0.9067 - val_output_3_loss: 0.0413 - val_output_4_loss: 13.7090 - val_output_3_precision_2: 0.6478 - val_output_3_recall_2: 0.1170 - val_output_3_true_negatives_2: 7592424.0000 - val_output_3_true_positives_2: 1383.0000 - val_output_3_false_negatives_2: 10441.0000 - val_output_3_false_positives_2: 752.0000\n",
      "Epoch 15/20\n",
      "4607/4607 [==============================] - 269s 58ms/step - loss: 55.7312 - output_1_loss: 5.9277 - output_2_loss: 2.3108 - output_3_loss: 0.0423 - output_4_loss: 14.4543 - output_3_precision_2: 0.5750 - output_3_recall_2: 0.0877 - output_3_true_negatives_2: 186536064.0000 - output_3_true_positives_2: 23704.0000 - output_3_false_negatives_2: 246597.0000 - output_3_false_positives_2: 17521.0000 - val_loss: 46.6612 - val_output_1_loss: 5.6928 - val_output_2_loss: 0.8836 - val_output_3_loss: 0.0412 - val_output_4_loss: 13.6966 - val_output_3_precision_2: 0.6392 - val_output_3_recall_2: 0.1202 - val_output_3_true_negatives_2: 7592374.0000 - val_output_3_true_positives_2: 1421.0000 - val_output_3_false_negatives_2: 10403.0000 - val_output_3_false_positives_2: 802.0000\n",
      "Epoch 16/20\n",
      "4607/4607 [==============================] - 274s 60ms/step - loss: 55.4448 - output_1_loss: 5.9371 - output_2_loss: 2.2460 - output_3_loss: 0.0423 - output_4_loss: 14.4446 - output_3_precision_2: 0.5801 - output_3_recall_2: 0.0890 - output_3_true_negatives_2: 186536704.0000 - output_3_true_positives_2: 24052.0000 - output_3_false_negatives_2: 246154.0000 - output_3_false_positives_2: 17413.0000 - val_loss: 46.6560 - val_output_1_loss: 5.6878 - val_output_2_loss: 0.8836 - val_output_3_loss: 0.0413 - val_output_4_loss: 13.7166 - val_output_3_precision_2: 0.6453 - val_output_3_recall_2: 0.1177 - val_output_3_true_negatives_2: 7592411.0000 - val_output_3_true_positives_2: 1392.0000 - val_output_3_false_negatives_2: 10432.0000 - val_output_3_false_positives_2: 765.0000\n",
      "Epoch 17/20\n",
      "4607/4607 [==============================] - 275s 60ms/step - loss: 55.6784 - output_1_loss: 5.9128 - output_2_loss: 2.3159 - output_3_loss: 0.0423 - output_4_loss: 14.4502 - output_3_precision_2: 0.5766 - output_3_recall_2: 0.0882 - output_3_true_negatives_2: 186536624.0000 - output_3_true_positives_2: 23824.0000 - output_3_false_negatives_2: 246428.0000 - output_3_false_positives_2: 17496.0000 - val_loss: 46.7041 - val_output_1_loss: 5.6841 - val_output_2_loss: 0.8993 - val_output_3_loss: 0.0412 - val_output_4_loss: 13.7048 - val_output_3_precision_2: 0.6446 - val_output_3_recall_2: 0.1167 - val_output_3_true_negatives_2: 7592415.0000 - val_output_3_true_positives_2: 1380.0000 - val_output_3_false_negatives_2: 10444.0000 - val_output_3_false_positives_2: 761.0000\n",
      "Epoch 18/20\n",
      "4607/4607 [==============================] - 273s 59ms/step - loss: 55.6803 - output_1_loss: 5.9283 - output_2_loss: 2.2959 - output_3_loss: 0.0425 - output_4_loss: 14.4745 - output_3_precision_2: 0.5803 - output_3_recall_2: 0.0879 - output_3_true_negatives_2: 186536928.0000 - output_3_true_positives_2: 23758.0000 - output_3_false_negatives_2: 246392.0000 - output_3_false_positives_2: 17185.0000 - val_loss: 46.5611 - val_output_1_loss: 5.6658 - val_output_2_loss: 0.8919 - val_output_3_loss: 0.0412 - val_output_4_loss: 13.6900 - val_output_3_precision_2: 0.6436 - val_output_3_recall_2: 0.1182 - val_output_3_true_negatives_2: 7592402.0000 - val_output_3_true_positives_2: 1398.0000 - val_output_3_false_negatives_2: 10426.0000 - val_output_3_false_positives_2: 774.0000\n",
      "Epoch 19/20\n",
      "4607/4607 [==============================] - 274s 59ms/step - loss: 55.6307 - output_1_loss: 5.9132 - output_2_loss: 2.3043 - output_3_loss: 0.0423 - output_4_loss: 14.4587 - output_3_precision_2: 0.5780 - output_3_recall_2: 0.0883 - output_3_true_negatives_2: 186536608.0000 - output_3_true_positives_2: 23853.0000 - output_3_false_negatives_2: 246368.0000 - output_3_false_positives_2: 17414.0000 - val_loss: 46.5747 - val_output_1_loss: 5.6715 - val_output_2_loss: 0.8896 - val_output_3_loss: 0.0412 - val_output_4_loss: 13.6870 - val_output_3_precision_2: 0.6430 - val_output_3_recall_2: 0.1164 - val_output_3_true_negatives_2: 7592412.0000 - val_output_3_true_positives_2: 1376.0000 - val_output_3_false_negatives_2: 10448.0000 - val_output_3_false_positives_2: 764.0000\n",
      "Epoch 20/20\n",
      "4607/4607 [==============================] - 274s 59ms/step - loss: 55.1985 - output_1_loss: 5.9351 - output_2_loss: 2.2029 - output_3_loss: 0.0422 - output_4_loss: 14.4241 - output_3_precision_2: 0.5778 - output_3_recall_2: 0.0881 - output_3_true_negatives_2: 186536800.0000 - output_3_true_positives_2: 23807.0000 - output_3_false_negatives_2: 246408.0000 - output_3_false_positives_2: 17396.0000 - val_loss: 46.5229 - val_output_1_loss: 5.6578 - val_output_2_loss: 0.8928 - val_output_3_loss: 0.0412 - val_output_4_loss: 13.6880 - val_output_3_precision_2: 0.6395 - val_output_3_recall_2: 0.1176 - val_output_3_true_negatives_2: 7592392.0000 - val_output_3_true_positives_2: 1391.0000 - val_output_3_false_negatives_2: 10433.0000 - val_output_3_false_positives_2: 784.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/sergio/Documents/json_experiments\")\n",
    "import json\n",
    "#json.dumps(str(a))\n",
    "with open('history_finetuning_5521_20_epoch_nadam_0dot00001_mse_3anchors.json', 'w') as fp:\n",
    "    json.dump(str(history.history), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guardo como Fine tunning pero es TRansfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/sergio/Documents/weights_saved/pesos_finetuning_5521_20_epoch_nadam_0dot00001_mse_3anchors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection\")\n",
    "\n",
    "from YOLOblocks import TinyYOLOv3,BasicBlock,PredictionLayer#,YOLOLossBasicBlock\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "#from tensorflow.python.tools import freeze_graph\n",
    "#from skimage.io import imread,imshow\n",
    "#from skimage.transform import resize \n",
    "import time\n",
    "#from tensorflow.compat.v1.image import decode_image\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'bboxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'num_real_boxes':tf.io.FixedLenFeature([], tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_matrix_tf(box_arr1, box_arr2):\n",
    "    \n",
    "    box_arr1 = box_arr1 -tf.tile(box_arr1[:,:2],[1,2])\n",
    "    #print(box_arr1)\n",
    "    x11, y11, x12, y12 = tf.split(box_arr1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = tf.split(box_arr2, 4, axis=1)\n",
    "    xA = tf.maximum(x11, tf.transpose(x21))\n",
    "    yA = tf.maximum(y11, tf.transpose(y21))\n",
    "    xB = tf.minimum(x12, tf.transpose(x22))\n",
    "    yB = tf.minimum(y12, tf.transpose(y22))\n",
    "    interArea = tf.maximum((xB - xA + 1e-9), 0) * tf.maximum((yB - yA + 1e-9), 0)\n",
    "    boxAArea = (x12 - x11 + 1e-9) * (y12 - y11 + 1e-9)\n",
    "    boxBArea = (x22 - x21 + 1e-9) * (y22 - y21 + 1e-9)\n",
    "    iou = interArea / (boxAArea + tf.transpose(boxBArea) - interArea)\n",
    "    return iou,tf.argmax(iou,axis=1)#[:,tf.newaxis]\n",
    "\n",
    "\n",
    "def fill_yolo_output(boxes,grid_size,num_anchors,which_anchor_box,which_anchor_box_index):\n",
    "    #print(boxes.shape)\n",
    "    #noobj_mask = tf.ones((1,grid_size*grid_size*num_anchors))\n",
    "    #print(noobj_mask.shape)\n",
    "    \n",
    "    x_min,y_min,x_max,y_max =tf.split(boxes,4,axis=1)\n",
    "\n",
    "    #Transforma las coordenadas de (xmin,ymin,xmax,ymax) --> (xcenter,ycenter,width,height)\n",
    "    width = x_max-x_min\n",
    "    height = y_max-y_min\n",
    "    x_global =x_min + tf.math.divide(x_max - x_min,2)\n",
    "    y_global =y_min + tf.math.divide(y_max - y_min,2)\n",
    "    \n",
    "    \n",
    "    x_min_anchor,y_min_anchor,x_max_anchor,y_max_anchor =tf.split(which_anchor_box,4,axis=1)\n",
    "    \n",
    "    width_anchor = x_max_anchor-x_min_anchor\n",
    "    height_anchor = y_max_anchor-y_min_anchor\n",
    "    x_global_anchor =x_min_anchor + tf.math.divide(x_max_anchor - x_min_anchor,2)\n",
    "    y_global_anchor =y_min_anchor + tf.math.divide(y_max_anchor - y_min_anchor,2)   \n",
    "\n",
    "    \n",
    "    #print(\"el x original\",x_global)\n",
    "    #print(\"el y original\",y_global)\n",
    "    #print(\"el w original\",width)\n",
    "    #print(\"el h original\",height)\n",
    "    \n",
    "    #porción de la imagen que hay en cada celda\n",
    "    pixel_per_grid = tf.math.divide(1.,grid_size)\n",
    "    #print(pixel_per_grid)\n",
    "    \n",
    "    #Obtenemos la coordenada de la celda donde están los boundingboxes\n",
    "    offset_grid_x = x_global//pixel_per_grid\n",
    "    offset_grid_y = y_global//pixel_per_grid\n",
    "    \n",
    "    #Obtenemos el el centro locacon referencia  al celda encontrada previamente\n",
    "    x_local =tf.math.floormod(x_global,pixel_per_grid)\n",
    "    y_local =tf.math.floormod(y_global,pixel_per_grid)\n",
    "    #print(x_local,y_local)\n",
    "    \n",
    "    #Valores tx e ty del groudtruth\n",
    "    tx = tf.math.log(x_local + 1e-07/(1-x_local))\n",
    "    ty = tf.math.log(y_local+1e-07/(1-y_local))\n",
    "    tw = tf.math.log(tf.math.divide(width+1e-07,width_anchor))\n",
    "    th = tf.math.log(tf.math.divide(height+1e-07,height_anchor))\n",
    "    tobj_mask = tf.ones_like(tx)\n",
    "    tobj = tf.concat([tobj_mask,tobj_mask,tobj_mask],axis=0)\n",
    "    \n",
    "    #tnoobj = tf.zeros_like(tx)    \n",
    "    #tobj = tf.ones((grid_size*grid_size*num_anchors,1))\n",
    "    #tnoobj = tf.zeros((grid_size*grid_size*num_anchors,1))\n",
    "    #print(\"Lo que la red debe predecir\",tx.numpy(),ty.numpy(),tw.numpy(),th.numpy())\n",
    "    #x_global = (offset_grid_x * pixel_per_grid) + tf.math.sigmoid(tx)\n",
    "    #y_global = (offset_grid_y * pixel_per_grid) + tf.math.sigmoid(ty)\n",
    "    #w = width_anchor*tf.math.exp(tw)\n",
    "    #h = height_anchor*tf.math.exp(th)\n",
    "    #print(\"obtnemos el x_real\",x_global)\n",
    "    #print(\"obtenemos el y_real\",y_global)\n",
    "    #print(\"obtenemos el w real\",w)\n",
    "    #print(\"obtenemos el h real\",h)\n",
    "    \n",
    "    #anchor_boxes_per_output = num_anchors//2\n",
    "\n",
    "    #Residuo indica cual de los 3 anchor boxes de la coordenada es la que llevara el 1\n",
    "    #Coord representa la coordenada del grid\n",
    "    \n",
    "    residuo = tf.math.floormod(which_anchor_box_index,num_anchors)[:,tf.newaxis]\n",
    "    coord = tf.cast(num_anchors*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    \n",
    "    coord_objectness = tf.cast(num_anchors*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    coord_objectness2 = coord_objectness+1\n",
    "    coord_objectness3 = coord_objectness+2\n",
    "    coord_objectess_global = tf.concat([coord_objectness,coord_objectness2,coord_objectness3],axis=0)\n",
    "    \n",
    "    output_position = residuo+coord\n",
    "    print(\"tipo de aoutput_positivon\",output_position)\n",
    "    \n",
    "    print(output_position)\n",
    "    \n",
    "    dense_shape = grid_size*grid_size*num_anchors\n",
    "    print(dense_shape)\n",
    "    tx_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tx[:,0], dense_shape=[dense_shape]))\n",
    "    ty_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=ty[:,0], dense_shape=[dense_shape]))\n",
    "    tw_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tw[:,0], dense_shape=[dense_shape]))\n",
    "    th_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=th[:,0], dense_shape=[dense_shape]))\n",
    "    obj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tobj_mask[:,0], dense_shape=[dense_shape]))\n",
    "    objectness_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=coord_objectess_global, values=tobj[:,0], dense_shape=[dense_shape]))\n",
    "    #noobj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tnoobj[:,0], dense_shape=[dense_shape]))\n",
    "    #obj_mask =tx_vector=ty_vector=tw_vector=th_vector = tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "    \n",
    "    tx_vector_dense = tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=False, name=\"Dense_tx\")\n",
    "    ty_vector_dense = tf.sparse.to_dense(ty_vector, default_value=0, validate_indices=False, name=\"Dense_ty\")\n",
    "    tw_vector_dense = tf.sparse.to_dense(tw_vector, default_value=0, validate_indices=False, name=\"Dense_tw\")\n",
    "    th_vector_dense = tf.sparse.to_dense(th_vector, default_value=0, validate_indices=False, name=\"Dense_th\")\n",
    "    obj_mask_dense =  tf.sparse.to_dense(obj_mask, default_value=0, validate_indices=False, name=\"Dense_obj\")\n",
    "    #noobj_mask_dense = 1-obj_mask_dense\n",
    "    objectness_vector_dense =  tf.sparse.to_dense(objectness_vector, default_value=0, validate_indices=False)\n",
    "    \n",
    "    #noobj_mask_dense= tf.sparse.to_dense(noobj_mask, default_value=1, validate_indices=False, name=\"Dense_noobj\")\n",
    "    ##print(tx_vector.to_dense)\n",
    "    #print(tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=True, name=None)\n",
    "    #tx_vector=tx_vector[[3,2],]\n",
    "    #tx_vector[output_position[:,0]] = tx\n",
    "    #print(\"coordenada de la salida:\",output_position)\n",
    "    \n",
    "    #return ((tx_vector_dense,ty_vector_dense,obj_mask_dense),(tw_vector_dense,th_vector_dense,obj_mask_dense),(objectness),(objectness))\n",
    "    \n",
    "    return tx_vector_dense,ty_vector_dense,tw_vector_dense,th_vector_dense,obj_mask_dense,objectness_vector_dense\n",
    "\n",
    "def build_targets(image,image_bboxes,num_real_boxes,anchor_boxes):\n",
    "    \n",
    "    images_bboxes_original = image_bboxes\n",
    "    #Obtenemos los boduing boxes que son reales\n",
    "    image_bboxes = image_bboxes[:num_real_boxes,:]\n",
    "    #print(\"Bouding boxes de la imagen\",image_bboxes)\n",
    "    #Obteneos  la matriz de IoU , y el índice del anchor box que dió mejor resultado\n",
    "    \n",
    "    #Nprmalizamos con respecto al tamaño de la imagen y obtenemos la Iou con los anchor boxes\n",
    "    image_bboxes = tf.math.divide(image_bboxes,416)\n",
    "    iou_matrix,which_anchor_box_index = get_iou_matrix_tf(image_bboxes,anchor_boxes)\n",
    "    \n",
    "    print(which_anchor_box_index)\n",
    "\n",
    "    anchor_boxes_per_output = len(anchor_boxes)//2\n",
    "    #Indices de los bouding boxes que irian en cada salida, index_best_ yolo nos dice que bouding boxes de la imagen van a la salida YOLO1,\n",
    "    #porque su mejor IoU fue con los len(anchor_boxes)//2 anchor boxes mas grandes\n",
    "    index_best_yolo1 = tf.where(which_anchor_box_index>=anchor_boxes_per_output)[:,0]\n",
    "    index_best_yolo2 = tf.where(which_anchor_box_index<anchor_boxes_per_output)[:,0]\n",
    "    index_best_anchor_yolo1 = tf.gather(which_anchor_box_index,index_best_yolo1,axis=0)\n",
    "    index_best_anchor_yolo2 = tf.gather(which_anchor_box_index,index_best_yolo2,axis=0)\n",
    "    \n",
    "    print(index_best_yolo1)\n",
    "    print(index_best_anchor_yolo1)\n",
    "\n",
    "    print(index_best_yolo2)\n",
    "    print(index_best_anchor_yolo2)\n",
    "\n",
    "    \n",
    "    best_bboxes_yolo1 = tf.gather(image_bboxes,index_best_yolo1,axis =0)\n",
    "    best_anchors_yolo1 = tf.gather(anchor_boxes,index_best_anchor_yolo1, axis =0) #LOs dos anchor boxes grandes corrsponden a YOLO1\n",
    "    best_bboxes_yolo2 = tf.gather(image_bboxes,index_best_yolo2,axis =0)\n",
    "    best_anchors_yolo2 = tf.gather(anchor_boxes,index_best_anchor_yolo2, axis =0) #Los dos anchor boxes pequeños corresponden a YOLO2\n",
    "    \n",
    "    \n",
    "    if best_anchors_yolo1.shape[0] !=0:\n",
    "        tx_vector_yolo1,ty_vector_yolo1,tw_vector_yolo1,th_vector_yolo1,obj_mask_yolo1,obj_vector_yolo1= fill_yolo_output(best_bboxes_yolo1,13,anchor_boxes_per_output,best_anchors_yolo1,index_best_anchor_yolo1)\n",
    "    else:\n",
    "        tx_vector_yolo1=ty_vector_yolo1=tw_vector_yolo1=th_vector_yolo1=obj_mask_yolo1= obj_vector_yolo1=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo1 = tf.ones((1,13*13*num_anchors))\n",
    "    \n",
    "    if best_anchors_yolo2.shape[0] != 0:\n",
    "        tx_vector_yolo2,ty_vector_yolo2,tw_vector_yolo2,th_vector_yolo2,obj_mask_yolo2,obj_vector_yolo2 = fill_yolo_output(best_bboxes_yolo2,26,anchor_boxes_per_output,best_anchors_yolo2,index_best_anchor_yolo2)\n",
    "    else:\n",
    "        tx_vector_yolo2=ty_vector_yolo2=tw_vector_yolo2=th_vector_yolo2=obj_mask_yolo2 = obj_vector_yolo2=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo2 = tf.ones((1,26*26*num_anchors))\n",
    "        \n",
    "    tx_vector = tf.concat([tx_vector_yolo1,tx_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    ty_vector = tf.concat([ty_vector_yolo1,ty_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    tw_vector = tf.concat([tw_vector_yolo1,tw_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    th_vector = tf.concat([th_vector_yolo1,th_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_mask = tf.concat([obj_mask_yolo1,obj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    #noobj_mask = tf.concat([noobj_mask_yolo1,noobj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_vector = tf.concat([obj_vector_yolo1,obj_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    \n",
    "    #output = tf.concat([tx_vector,ty_vector,tw_vector,th_vector,obj_mask,noobj_mask,obj_vector],axis=1)\n",
    "    #images_bboxes_original\n",
    "    #return image,output\n",
    "    #Vamos a regresar obj mask que es 1 cuando hay objeto en grid y el anchor box especifico\n",
    "    #return tf.cast(image,tf.float32)/255,(tf.concat([tx_vector,ty_vector,obj_mask],axis=1),tf.concat([tw_vector,th_vector,obj_mask],axis=1),(obj_mask),(obj_mask))\n",
    "    return tf.cast(image,tf.float32)/255,(tf.concat([tx_vector,ty_vector,obj_mask],axis=1),tf.concat([tw_vector,th_vector,obj_mask],axis=1),(obj_vector),(obj_vector))\n",
    "\n",
    "\n",
    "def imgaug_data_augmentation(image,bboxes,num_real_boxes):\n",
    "    im_shape = image.shape\n",
    "    bbs = BoundingBoxesOnImage.from_xyxy_array(bboxes*416, shape=(416,416))\n",
    "    \n",
    "    policy = np.random.randint(5)\n",
    "    \n",
    "    #policy = 2\n",
    "    if policy == 0:\n",
    "        \n",
    "        p = np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateX(px=(-60, 60),cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "        p = np.random.random()\n",
    "        if p<=0.8:\n",
    "            aug = iaa.HistogramEqualization()\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "    elif policy==1:\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.2:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=0.8:\n",
    "            square_size = np.random.randint(48)\n",
    "            aug = iaa.Cutout(nb_iterations=1, size=square_size/416, squared=True)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    elif policy==2:\n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.ShearY(shear=(int(-0.06*416), int(0.06*416)), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "        p=np.random.random()\n",
    "        if p<=0.6:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "            \n",
    "    elif policy==3:\n",
    "        p=np.random.random()\n",
    "        if p<=0.6:    \n",
    "            aug = iaa.Rotate(rotate=(-30, 30), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs_aug.remove_out_of_image().clip_out_of_image()\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.MultiplySaturation((0.54, 1.54))\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    bbs.remove_out_of_image()\n",
    "    \n",
    "    return image,np.clip(bbs.to_xyxy_array(np.float32),1,415),num_real_boxes\n",
    "    \n",
    "    \n",
    "def preprocessing(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,num_real_boxes\n",
    "\n",
    "def preprocessing_validation_set(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    bboxes = tf.clip_by_value(bboxes*416,1,415)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,tf.cast(num_real_boxes,tf.int64)\n",
    "    \n",
    "@tf.function(input_signature=[tf.TensorSpec((416,416,3), tf.uint8),tf.TensorSpec((None,4), tf.float32),tf.TensorSpec((), tf.int64)]) \n",
    "def tf_numpy_albumentations_real(image,bboxes,num_real_boxes):\n",
    "    \n",
    "    boxes_shape = bboxes.shape\n",
    "    im_shape = image.shape\n",
    "\n",
    "    image,bboxes,num_real_boxes = tf.numpy_function(imgaug_data_augmentation,[image,bboxes,num_real_boxes],Tout =[tf.uint8,tf.float32,tf.int64])\n",
    " \n",
    "    image.set_shape(im_shape)\n",
    "    bboxes.set_shape(boxes_shape)\n",
    "    print(\"Imagen data type\",image.dtype)\n",
    "    print(\"Bboxes data type\",bboxes.dtype)\n",
    "    print(\"num_real_boxes\",num_real_boxes.dtype)\n",
    "\n",
    "    return image,bboxes,num_real_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen data type <dtype: 'uint8'>\n",
      "Bboxes data type <dtype: 'float32'>\n",
      "num_real_boxes <dtype: 'int64'>\n",
      "Tensor(\"ArgMax:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", shape=(None,), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_19:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_19:0\", shape=(None, 1), dtype=int64)\n",
      "507\n",
      "tipo de aoutput_positivon Tensor(\"add_32:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_32:0\", shape=(None, 1), dtype=int64)\n",
      "2028\n",
      "Tensor(\"ArgMax:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_19:0\", dtype=int64)\n",
      "Tensor(\"add_19:0\", dtype=int64)\n",
      "507\n",
      "tipo de aoutput_positivon Tensor(\"add_32:0\", dtype=int64)\n",
      "Tensor(\"add_32:0\", dtype=int64)\n",
      "2028\n"
     ]
    }
   ],
   "source": [
    "#USANDO TF.IMAGE MODULE\n",
    "#anchors =tf.constant(np.array([[0,0,0.015,0.037],[0,0,0.043,0.104],[0,0,0.11,0.278],[0,0,0.351,0.66]]),dtype=tf.float32)\n",
    "#anchors =tf.constant(np.array([[0,0,0.026,0.062],[0,0,0.067,0.183],[0,0,0.128,0.323],[0,0,0.343,0.650]]),dtype=tf.float32)\n",
    "anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_val_tfr\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset_val =tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")\n",
    "#.shuffle(70000)\n",
    "train_dataset = raw_image_dataset.map(preprocessing,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(tf_numpy_albumentations_real,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "train_dataset = train_dataset.batch(16)\n",
    "\n",
    "val_dataset = raw_image_dataset_val.map(preprocessing_validation_set,num_parallel_calls=8)\n",
    "val_dataset = val_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "val_dataset = val_dataset.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef loss_bce_objectness(y_true,y_pred):\\n    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\\n    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\\n    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \\n    \\n    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*tf.math.log(y_pred+1e-7)[:,tf.newaxis],axis=1))\\n    \\n    return loss_obj\\n\\ndef loss_bce_no_objectness(y_true,y_pred):\\n    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\\n    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*tf.math.log(1-y_pred+1e-7)[:,tf.newaxis],axis=1))\\n    \\n    return loss_noobj\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.losses import Loss,BinaryCrossentropy,MeanSquaredError,MeanSquaredLogarithmicError\n",
    "'''\n",
    "\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tx_true-tx_pred))  \n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    msle = MeanSquaredLogarithmicError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tx_true-tx_pred))  \n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(msle(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "'''\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "\n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    #print(tf.math.square(tw_true-tw_pred))\n",
    "\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tf.math.exp(tw_true),tf.math.exp(tw_pred))[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tf.math.exp(th_true),tf.math.exp(th_pred))[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "\n",
    "def loss_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_no_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    \n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj\n",
    "'''\n",
    "def loss_bce_objectness(y_true,y_pred):\n",
    "    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*tf.math.log(y_pred+1e-7)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_bce_no_objectness(y_true,y_pred):\n",
    "    #bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*tf.math.log(1-y_pred+1e-7)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with Model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n",
      "Pesos de la convolucion (432,)\n",
      "CONV SHAPE (16, 3, 3, 3)\n",
      "Pesos de la convolucion (4608,)\n",
      "CONV SHAPE (32, 16, 3, 3)\n",
      "Pesos de la convolucion (18432,)\n",
      "CONV SHAPE (64, 32, 3, 3)\n",
      "Pesos de la convolucion (73728,)\n",
      "CONV SHAPE (128, 64, 3, 3)\n",
      "Pesos de la convolucion (294912,)\n",
      "CONV SHAPE (256, 128, 3, 3)\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "Pesos de la convolucion (4718592,)\n",
      "CONV SHAPE (1024, 512, 3, 3)\n",
      "Pesos de la convolucion (262144,)\n",
      "CONV SHAPE (256, 1024, 1, 1)\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "Pesos de la convolucion (130560,)\n",
      "CONV SHAPE (255, 512, 1, 1)\n",
      "Pesos de la convolucion (32768,)\n",
      "CONV SHAPE (128, 256, 1, 1)\n",
      "Pesos de la convolucion (884736,)\n",
      "CONV SHAPE (256, 384, 3, 3)\n",
      "Pesos de la convolucion (65280,)\n",
      "CONV SHAPE (255, 256, 1, 1)\n",
      "8858734\n"
     ]
    }
   ],
   "source": [
    "#anchors =tf.constant(np.array([[0.026,0.062],[0.067,0.183],[0.128,0.323],[0.343,0.650]]),dtype=tf.float32)\n",
    "anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "model = TinyYOLOv3(1,anchor_boxes=anchors,train=True,mode = \"finetuning\")\n",
    "model.build(batch_input_shape=(None,416,416,3))\n",
    "print(model.load_weights_darknet(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=1e-4)\n",
    "\n",
    "losses = {\"output_1\": loss_xy,\n",
    "          \"output_2\": loss_wh,\n",
    "          \"output_3\":loss_objectness,\n",
    "          \"output_4\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"output_3\":[Precision(),Recall(),TrueNegatives(),TruePositives(),FalseNegatives(),FalsePositives()]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[5,5,2,1])\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 16, con pesos 5521 with lr=0.0003 y usando msle para el (x,y) y usando mse de las exponenciales para (w,h)con el loss usando OBJECNESS VECTOR NO OBJECTNESS MASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n",
      "Epoch 1/30\n",
      "Modo entrenamiento\n",
      "Modo entrenamiento\n",
      "      1/Unknown - 5s 5s/step"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-71d3227d96dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=30,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "os.chdir(\"/home/sergio/Documents/json_experiments\")\n",
    "import json\n",
    "#json.dumps(str(a))\n",
    "with open('history_finetuning_5521_20_epoch_nadam_0dot00001_mse_exp_mse_3anchors_full_obj.json', 'w') as fp:\n",
    "    json.dump(str(history.history), fp)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('/home/sergio/Documents/weights_saved/pesos_finetuning_5521_20_epoch_nadam_0dot00001_mse_exp_mse_3anchors_full_obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTINUACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3d4405e6d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#anchors =tf.constant(np.array([[0.026,0.062],[0.067,0.183],[0.128,0.323],[0.343,0.650]]),dtype=tf.float32)\n",
    "anchors =tf.constant(np.array([[0,0,0.02078,0.049],[0,0,0.0426,0.128],[0,0,0.08523,0.19356],[0,0,0.1506,0.4163],[0,0,0.27835,0.58651],[0,0,0.5632,0.78614]]),dtype=tf.float32)\n",
    "\n",
    "model = TinyYOLOv3(1,anchor_boxes=anchors,train=True,mode = \"finetuning\")\n",
    "model.build(batch_input_shape=(None,416,416,3))\n",
    "#print(model.load_weights_darknet(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\"))\n",
    "model.load_weights('/home/sergio/Documents/weights_saved/pesos_finetuning_5521_20_epoch_nadam_0dot00001_mse_exp_mse_3anchors_full_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "from tensorflow.keras.metrics import TrueNegatives,TruePositives,FalseNegatives,FalsePositives,Precision,Recall\n",
    "\n",
    "opt = tf.keras.optimizers.Nadam(learning_rate=1e-4)\n",
    "\n",
    "losses = {\"output_1\": loss_xy,\n",
    "          \"output_2\": loss_wh,\n",
    "          \"output_3\":loss_objectness,\n",
    "          \"output_4\":loss_no_objectness  \n",
    "}\n",
    "\n",
    "metrics = {\"output_3\":[Precision(),Recall(),TrueNegatives(),TruePositives(),FalseNegatives(),FalsePositives()]}\n",
    "model.compile(optimizer=opt, loss=losses,metrics=metrics,loss_weights=[5,5,2,1])\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modo entrenamiento\n",
      "Epoch 1/20\n",
      "Modo entrenamiento\n",
      "Modo entrenamiento\n",
      "   4607/Unknown - 592s 128ms/step - loss: 44.0466 - output_1_loss: 3.2577 - output_2_loss: 0.4369 - output_3_loss: 0.2246 - output_4_loss: 25.1246 - output_3_precision: 0.7331 - output_3_recall: 0.3509 - output_3_true_negatives: 185917664.0000 - output_3_true_positives: 282166.0000 - output_3_false_negatives: 521861.0000 - output_3_false_positives: 102715.0000 578s 128ms/step - loss: 43.9467 - output_1_loss: 3.2498 - output_2_loss: 0.4353 - output_3_loss: 0.2240 - output_4_loss: 25.0731 -Modo entrenamiento\n",
      "4607/4607 [==============================] - 599s 130ms/step - loss: 44.0466 - output_1_loss: 3.2577 - output_2_loss: 0.4369 - output_3_loss: 0.2246 - output_4_loss: 25.1246 - output_3_precision: 0.7331 - output_3_recall: 0.3509 - output_3_true_negatives: 185917664.0000 - output_3_true_positives: 282166.0000 - output_3_false_negatives: 521861.0000 - output_3_false_positives: 102715.0000 - val_loss: 33.5034 - val_output_1_loss: 2.0152 - val_output_2_loss: 0.3683 - val_output_3_loss: 0.1998 - val_output_4_loss: 21.1862 - val_output_3_precision: 0.8064 - val_output_3_recall: 0.4360 - val_output_3_true_negatives: 7566129.0000 - val_output_3_true_positives: 15342.0000 - val_output_3_false_negatives: 19845.0000 - val_output_3_false_positives: 3684.0000\n",
      "Epoch 2/20\n",
      "4607/4607 [==============================] - 608s 132ms/step - loss: 43.6876 - output_1_loss: 3.2310 - output_2_loss: 0.4526 - output_3_loss: 0.2222 - output_4_loss: 24.8253 - output_3_precision: 0.7359 - output_3_recall: 0.3593 - output_3_true_negatives: 185916592.0000 - output_3_true_positives: 288920.0000 - output_3_false_negatives: 515278.0000 - output_3_false_positives: 103695.0000 - val_loss: 32.6752 - val_output_1_loss: 1.9502 - val_output_2_loss: 0.3707 - val_output_3_loss: 0.1960 - val_output_4_loss: 20.6789 - val_output_3_precision: 0.7913 - val_output_3_recall: 0.4818 - val_output_3_true_negatives: 7565341.0000 - val_output_3_true_positives: 16954.0000 - val_output_3_false_negatives: 18233.0000 - val_output_3_false_positives: 4472.0000\n",
      "Epoch 3/20\n",
      "4607/4607 [==============================] - 607s 132ms/step - loss: 43.0173 - output_1_loss: 3.1832 - output_2_loss: 0.4526 - output_3_loss: 0.2187 - output_4_loss: 24.4008 - output_3_precision: 0.7406 - output_3_recall: 0.3719 - output_3_true_negatives: 185916144.0000 - output_3_true_positives: 298941.0000 - output_3_false_negatives: 504804.0000 - output_3_false_positives: 104730.0000 - val_loss: 31.9742 - val_output_1_loss: 1.9132 - val_output_2_loss: 0.3744 - val_output_3_loss: 0.1915 - val_output_4_loss: 20.1535 - val_output_3_precision: 0.7955 - val_output_3_recall: 0.4915 - val_output_3_true_negatives: 7565367.0000 - val_output_3_true_positives: 17293.0000 - val_output_3_false_negatives: 17894.0000 - val_output_3_false_positives: 4446.0000\n",
      "Epoch 4/20\n",
      "4607/4607 [==============================] - 611s 133ms/step - loss: 42.4637 - output_1_loss: 3.1333 - output_2_loss: 0.4479 - output_3_loss: 0.2170 - output_4_loss: 24.1237 - output_3_precision: 0.7460 - output_3_recall: 0.3814 - output_3_true_negatives: 185915600.0000 - output_3_true_positives: 306730.0000 - output_3_false_negatives: 497426.0000 - output_3_false_positives: 104462.0000 - val_loss: 31.2714 - val_output_1_loss: 1.8751 - val_output_2_loss: 0.3625 - val_output_3_loss: 0.1885 - val_output_4_loss: 19.7065 - val_output_3_precision: 0.8208 - val_output_3_recall: 0.4870 - val_output_3_true_negatives: 7566072.0000 - val_output_3_true_positives: 17135.0000 - val_output_3_false_negatives: 18052.0000 - val_output_3_false_positives: 3741.0000\n",
      "Epoch 5/20\n",
      "4607/4607 [==============================] - 586s 127ms/step - loss: 42.1738 - output_1_loss: 3.1291 - output_2_loss: 0.4481 - output_3_loss: 0.2148 - output_4_loss: 23.8583 - output_3_precision: 0.7489 - output_3_recall: 0.3892 - output_3_true_negatives: 185915568.0000 - output_3_true_positives: 312864.0000 - output_3_false_negatives: 490968.0000 - output_3_false_positives: 104876.0000 - val_loss: 30.5804 - val_output_1_loss: 1.8158 - val_output_2_loss: 0.3544 - val_output_3_loss: 0.1854 - val_output_4_loss: 19.3586 - val_output_3_precision: 0.8164 - val_output_3_recall: 0.5082 - val_output_3_true_negatives: 7565792.0000 - val_output_3_true_positives: 17882.0000 - val_output_3_false_negatives: 17305.0000 - val_output_3_false_positives: 4021.0000\n",
      "Epoch 6/20\n",
      "4607/4607 [==============================] - 590s 128ms/step - loss: 41.7110 - output_1_loss: 3.1063 - output_2_loss: 0.4437 - output_3_loss: 0.2122 - output_4_loss: 23.5367 - output_3_precision: 0.7529 - output_3_recall: 0.3985 - output_3_true_negatives: 185915760.0000 - output_3_true_positives: 320385.0000 - output_3_false_negatives: 483603.0000 - output_3_false_positives: 105135.0000 - val_loss: 29.7037 - val_output_1_loss: 1.7670 - val_output_2_loss: 0.3527 - val_output_3_loss: 0.1799 - val_output_4_loss: 18.7454 - val_output_3_precision: 0.8148 - val_output_3_recall: 0.5303 - val_output_3_true_negatives: 7565572.0000 - val_output_3_true_positives: 18660.0000 - val_output_3_false_negatives: 16527.0000 - val_output_3_false_positives: 4241.0000\n",
      "Epoch 7/20\n",
      "4607/4607 [==============================] - 587s 127ms/step - loss: 41.1366 - output_1_loss: 3.0470 - output_2_loss: 0.4272 - output_3_loss: 0.2108 - output_4_loss: 23.3440 - output_3_precision: 0.7558 - output_3_recall: 0.4075 - output_3_true_negatives: 185914096.0000 - output_3_true_positives: 327645.0000 - output_3_false_negatives: 476445.0000 - output_3_false_positives: 105877.0000 - val_loss: 29.0903 - val_output_1_loss: 1.7048 - val_output_2_loss: 0.3566 - val_output_3_loss: 0.1774 - val_output_4_loss: 18.4285 - val_output_3_precision: 0.8195 - val_output_3_recall: 0.5332 - val_output_3_true_negatives: 7565682.0000 - val_output_3_true_positives: 18760.0000 - val_output_3_false_negatives: 16427.0000 - val_output_3_false_positives: 4131.0000\n",
      "Epoch 8/20\n",
      "4607/4607 [==============================] - 603s 131ms/step - loss: 40.7187 - output_1_loss: 3.0389 - output_2_loss: 0.4222 - output_3_loss: 0.2079 - output_4_loss: 22.9978 - output_3_precision: 0.7612 - output_3_recall: 0.4167 - output_3_true_negatives: 185915792.0000 - output_3_true_positives: 334984.0000 - output_3_false_negatives: 468956.0000 - output_3_false_positives: 105107.0000 - val_loss: 28.0981 - val_output_1_loss: 1.6438 - val_output_2_loss: 0.3506 - val_output_3_loss: 0.1720 - val_output_4_loss: 17.7820 - val_output_3_precision: 0.8329 - val_output_3_recall: 0.5386 - val_output_3_true_negatives: 7566010.0000 - val_output_3_true_positives: 18950.0000 - val_output_3_false_negatives: 16237.0000 - val_output_3_false_positives: 3803.0000\n",
      "Epoch 9/20\n",
      "4607/4607 [==============================] - 597s 130ms/step - loss: 40.2514 - output_1_loss: 3.0064 - output_2_loss: 0.4223 - output_3_loss: 0.2052 - output_4_loss: 22.6972 - output_3_precision: 0.7643 - output_3_recall: 0.4244 - output_3_true_negatives: 185915440.0000 - output_3_true_positives: 341124.0000 - output_3_false_negatives: 462645.0000 - output_3_false_positives: 105191.0000 - val_loss: 28.2201 - val_output_1_loss: 1.6833 - val_output_2_loss: 0.3467 - val_output_3_loss: 0.1717 - val_output_4_loss: 17.7269 - val_output_3_precision: 0.8348 - val_output_3_recall: 0.5481 - val_output_3_true_negatives: 7565997.0000 - val_output_3_true_positives: 19287.0000 - val_output_3_false_negatives: 15900.0000 - val_output_3_false_positives: 3816.0000\n",
      "Epoch 10/20\n",
      "4607/4607 [==============================] - 586s 127ms/step - loss: 40.0202 - output_1_loss: 3.0028 - output_2_loss: 0.4260 - output_3_loss: 0.2037 - output_4_loss: 22.4689 - output_3_precision: 0.7663 - output_3_recall: 0.4321 - output_3_true_negatives: 185914704.0000 - output_3_true_positives: 347372.0000 - output_3_false_negatives: 456583.0000 - output_3_false_positives: 105958.0000 - val_loss: 27.0034 - val_output_1_loss: 1.5816 - val_output_2_loss: 0.3487 - val_output_3_loss: 0.1649 - val_output_4_loss: 17.0217 - val_output_3_precision: 0.8261 - val_output_3_recall: 0.5848 - val_output_3_true_negatives: 7565483.0000 - val_output_3_true_positives: 20576.0000 - val_output_3_false_negatives: 14611.0000 - val_output_3_false_positives: 4330.0000\n",
      "Epoch 11/20\n",
      "4607/4607 [==============================] - 599s 130ms/step - loss: 39.5999 - output_1_loss: 2.9640 - output_2_loss: 0.4285 - output_3_loss: 0.2018 - output_4_loss: 22.2340 - output_3_precision: 0.7713 - output_3_recall: 0.4412 - output_3_true_negatives: 185916080.0000 - output_3_true_positives: 354578.0000 - output_3_false_negatives: 449008.0000 - output_3_false_positives: 105146.0000 - val_loss: 26.6607 - val_output_1_loss: 1.5741 - val_output_2_loss: 0.3433 - val_output_3_loss: 0.1632 - val_output_4_loss: 16.7472 - val_output_3_precision: 0.8334 - val_output_3_recall: 0.5808 - val_output_3_true_negatives: 7565726.0000 - val_output_3_true_positives: 20438.0000 - val_output_3_false_negatives: 14749.0000 - val_output_3_false_positives: 4087.0000\n",
      "Epoch 12/20\n",
      "4607/4607 [==============================] - 595s 129ms/step - loss: 39.1491 - output_1_loss: 2.9272 - output_2_loss: 0.4222 - output_3_loss: 0.2001 - output_4_loss: 22.0021 - output_3_precision: 0.7750 - output_3_recall: 0.4484 - output_3_true_negatives: 185915408.0000 - output_3_true_positives: 360616.0000 - output_3_false_negatives: 443573.0000 - output_3_false_positives: 104714.0000 - val_loss: 26.5219 - val_output_1_loss: 1.5804 - val_output_2_loss: 0.3528 - val_output_3_loss: 0.1620 - val_output_4_loss: 16.5323 - val_output_3_precision: 0.8415 - val_output_3_recall: 0.5748 - val_output_3_true_negatives: 7566002.0000 - val_output_3_true_positives: 20227.0000 - val_output_3_false_negatives: 14960.0000 - val_output_3_false_positives: 3811.0000\n",
      "Epoch 13/20\n",
      "4607/4607 [==============================] - 581s 126ms/step - loss: 38.6988 - output_1_loss: 2.9020 - output_2_loss: 0.4280 - output_3_loss: 0.1963 - output_4_loss: 21.6561 - output_3_precision: 0.7773 - output_3_recall: 0.4573 - output_3_true_negatives: 185915344.0000 - output_3_true_positives: 367542.0000 - output_3_false_negatives: 436164.0000 - output_3_false_positives: 105331.0000 - val_loss: 25.8800 - val_output_1_loss: 1.5378 - val_output_2_loss: 0.3403 - val_output_3_loss: 0.1585 - val_output_4_loss: 16.1725 - val_output_3_precision: 0.8359 - val_output_3_recall: 0.6092 - val_output_3_true_negatives: 7565604.0000 - val_output_3_true_positives: 21437.0000 - val_output_3_false_negatives: 13750.0000 - val_output_3_false_positives: 4209.0000\n",
      "Epoch 14/20\n",
      "4607/4607 [==============================] - 588s 128ms/step - loss: 38.5509 - output_1_loss: 2.9122 - output_2_loss: 0.4230 - output_3_loss: 0.1959 - output_4_loss: 21.4832 - output_3_precision: 0.7796 - output_3_recall: 0.4630 - output_3_true_negatives: 185915392.0000 - output_3_true_positives: 372148.0000 - output_3_false_negatives: 431573.0000 - output_3_false_positives: 105216.0000 - val_loss: 25.7314 - val_output_1_loss: 1.5210 - val_output_2_loss: 0.3427 - val_output_3_loss: 0.1574 - val_output_4_loss: 16.0985 - val_output_3_precision: 0.8424 - val_output_3_recall: 0.6011 - val_output_3_true_negatives: 7565856.0000 - val_output_3_true_positives: 21150.0000 - val_output_3_false_negatives: 14037.0000 - val_output_3_false_positives: 3957.0000\n",
      "Epoch 15/20\n",
      "4607/4607 [==============================] - 606s 132ms/step - loss: 38.1917 - output_1_loss: 2.8711 - output_2_loss: 0.4260 - output_3_loss: 0.1947 - output_4_loss: 21.3169 - output_3_precision: 0.7837 - output_3_recall: 0.4704 - output_3_true_negatives: 185915968.0000 - output_3_true_positives: 378218.0000 - output_3_false_negatives: 425878.0000 - output_3_false_positives: 104357.0000 - val_loss: 24.3334 - val_output_1_loss: 1.4409 - val_output_2_loss: 0.3364 - val_output_3_loss: 0.1488 - val_output_4_loss: 15.1492 - val_output_3_precision: 0.8548 - val_output_3_recall: 0.6206 - val_output_3_true_negatives: 7566103.0000 - val_output_3_true_positives: 21836.0000 - val_output_3_false_negatives: 13351.0000 - val_output_3_false_positives: 3710.0000\n",
      "Epoch 16/20\n",
      "4607/4607 [==============================] - 573s 124ms/step - loss: 37.8929 - output_1_loss: 2.8549 - output_2_loss: 0.4204 - output_3_loss: 0.1922 - output_4_loss: 21.1322 - output_3_precision: 0.7854 - output_3_recall: 0.4763 - output_3_true_negatives: 185915904.0000 - output_3_true_positives: 382945.0000 - output_3_false_negatives: 421058.0000 - output_3_false_positives: 104658.0000 - val_loss: 24.5258 - val_output_1_loss: 1.4701 - val_output_2_loss: 0.3406 - val_output_3_loss: 0.1487 - val_output_4_loss: 15.1750 - val_output_3_precision: 0.8388 - val_output_3_recall: 0.6466 - val_output_3_true_negatives: 7565440.0000 - val_output_3_true_positives: 22753.0000 - val_output_3_false_negatives: 12434.0000 - val_output_3_false_positives: 4373.0000\n",
      "Epoch 17/20\n",
      "4607/4607 [==============================] - 580s 126ms/step - loss: 67.4684 - output_1_loss: 3.0609 - output_2_loss: 5.7811 - output_3_loss: 0.2066 - output_4_loss: 22.8452 - output_3_precision: 0.7746 - output_3_recall: 0.4311 - output_3_true_negatives: 185919840.0000 - output_3_true_positives: 346597.0000 - output_3_false_negatives: 457361.0000 - output_3_false_positives: 100851.0000 - val_loss: 32.7803 - val_output_1_loss: 2.0538 - val_output_2_loss: 0.4027 - val_output_3_loss: 0.1893 - val_output_4_loss: 20.1191 - val_output_3_precision: 0.8066 - val_output_3_recall: 0.4981 - val_output_3_true_negatives: 7565610.0000 - val_output_3_true_positives: 17525.0000 - val_output_3_false_negatives: 17662.0000 - val_output_3_false_positives: 4203.0000\n",
      "Epoch 18/20\n",
      "4607/4607 [==============================] - 594s 129ms/step - loss: 40.9264 - output_1_loss: 3.0827 - output_2_loss: 0.4565 - output_3_loss: 0.2051 - output_4_loss: 22.8202 - output_3_precision: 0.7690 - output_3_recall: 0.4280 - output_3_true_negatives: 185917184.0000 - output_3_true_positives: 343970.0000 - output_3_false_negatives: 459685.0000 - output_3_false_positives: 103348.0000 - val_loss: 24.9685 - val_output_1_loss: 1.4454 - val_output_2_loss: 0.3490 - val_output_3_loss: 0.1523 - val_output_4_loss: 15.6917 - val_output_3_precision: 0.8495 - val_output_3_recall: 0.6152 - val_output_3_true_negatives: 7565979.0000 - val_output_3_true_positives: 21646.0000 - val_output_3_false_negatives: 13541.0000 - val_output_3_false_positives: 3834.0000\n",
      "Epoch 19/20\n",
      "4607/4607 [==============================] - 621s 135ms/step - loss: 37.3160 - output_1_loss: 2.8155 - output_2_loss: 0.4030 - output_3_loss: 0.1901 - output_4_loss: 20.8430 - output_3_precision: 0.7914 - output_3_recall: 0.4855 - output_3_true_negatives: 185917248.0000 - output_3_true_positives: 390454.0000 - output_3_false_negatives: 413720.0000 - output_3_false_positives: 102930.0000 - val_loss: 22.4243 - val_output_1_loss: 1.2738 - val_output_2_loss: 0.3290 - val_output_3_loss: 0.1395 - val_output_4_loss: 14.1314 - val_output_3_precision: 0.8517 - val_output_3_recall: 0.6822 - val_output_3_true_negatives: 7565632.0000 - val_output_3_true_positives: 24006.0000 - val_output_3_false_negatives: 11181.0000 - val_output_3_false_positives: 4181.0000\n",
      "Epoch 20/20\n",
      "4607/4607 [==============================] - 618s 134ms/step - loss: 36.7807 - output_1_loss: 2.7790 - output_2_loss: 0.4048 - output_3_loss: 0.1871 - output_4_loss: 20.4876 - output_3_precision: 0.7943 - output_3_recall: 0.4968 - output_3_true_negatives: 185916736.0000 - output_3_true_positives: 399499.0000 - output_3_false_negatives: 404639.0000 - output_3_false_positives: 103446.0000 - val_loss: 22.9562 - val_output_1_loss: 1.3600 - val_output_2_loss: 0.3257 - val_output_3_loss: 0.1411 - val_output_4_loss: 14.2456 - val_output_3_precision: 0.8577 - val_output_3_recall: 0.6644 - val_output_3_true_negatives: 7565935.0000 - val_output_3_true_positives: 23377.0000 - val_output_3_false_negatives: 11810.0000 - val_output_3_false_positives: 3878.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"/home/sergio/Documents/json_experiments\")\n",
    "import json\n",
    "#json.dumps(str(a))\n",
    "with open('history_finetuning_5521_20_40_epoch_nadam_0dot00001_mse_exp_mse_3anchors_full_obj.json', 'w') as fp:\n",
    "    json.dump(str(history.history), fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/sergio/Documents/weights_saved/pesos_finetuning_5521_20_40_epoch_nadam_0dot00001_mse_exp_mse_3anchors_full_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTINUACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4607/4607 [==============================] - 611s 133ms/step - loss: 37.1441 - output_1_loss: 2.8176 - output_2_loss: 0.4211 - output_3_loss: 0.1879 - output_4_loss: 20.5749 - output_3_precision: 0.7932 - output_3_recall: 0.4935 - output_3_true_negatives: 185917248.0000 - output_3_true_positives: 396625.0000 - output_3_false_negatives: 407078.0000 - output_3_false_positives: 103418.0000 - val_loss: 23.1081 - val_output_1_loss: 1.3790 - val_output_2_loss: 0.3281 - val_output_3_loss: 0.1400 - val_output_4_loss: 14.2927 - val_output_3_precision: 0.8689 - val_output_3_recall: 0.6508 - val_output_3_true_negatives: 7566359.0000 - val_output_3_true_positives: 22901.0000 - val_output_3_false_negatives: 12286.0000 - val_output_3_false_positives: 3454.0000\n",
      "Epoch 2/20\n",
      "4607/4607 [==============================] - 618s 134ms/step - loss: 36.5317 - output_1_loss: 2.7698 - output_2_loss: 0.4008 - output_3_loss: 0.1855 - output_4_loss: 20.3080 - output_3_precision: 0.7966 - output_3_recall: 0.5015 - output_3_true_negatives: 185917632.0000 - output_3_true_positives: 403149.0000 - output_3_false_negatives: 400704.0000 - output_3_false_positives: 102965.0000 - val_loss: 22.5485 - val_output_1_loss: 1.3761 - val_output_2_loss: 0.3284 - val_output_3_loss: 0.1363 - val_output_4_loss: 13.7535 - val_output_3_precision: 0.8679 - val_output_3_recall: 0.6706 - val_output_3_true_negatives: 7566221.0000 - val_output_3_true_positives: 23597.0000 - val_output_3_false_negatives: 11590.0000 - val_output_3_false_positives: 3592.0000\n",
      "Epoch 3/20\n",
      "4607/4607 [==============================] - 605s 131ms/step - loss: 36.6947 - output_1_loss: 2.7946 - output_2_loss: 0.4199 - output_3_loss: 0.1847 - output_4_loss: 20.2527 - output_3_precision: 0.7974 - output_3_recall: 0.5039 - output_3_true_negatives: 185917840.0000 - output_3_true_positives: 405129.0000 - output_3_false_negatives: 398862.0000 - output_3_false_positives: 102918.0000 - val_loss: 22.0310 - val_output_1_loss: 1.3197 - val_output_2_loss: 0.3236 - val_output_3_loss: 0.1341 - val_output_4_loss: 13.5461 - val_output_3_precision: 0.8680 - val_output_3_recall: 0.6799 - val_output_3_true_negatives: 7566175.0000 - val_output_3_true_positives: 23924.0000 - val_output_3_false_negatives: 11263.0000 - val_output_3_false_positives: 3638.0000\n",
      "Epoch 4/20\n",
      "4607/4607 [==============================] - 611s 133ms/step - loss: 36.4924 - output_1_loss: 2.7972 - output_2_loss: 0.4055 - output_3_loss: 0.1836 - output_4_loss: 20.1119 - output_3_precision: 0.7996 - output_3_recall: 0.5078 - output_3_true_negatives: 185917952.0000 - output_3_true_positives: 408248.0000 - output_3_false_negatives: 395665.0000 - output_3_false_positives: 102301.0000 - val_loss: 21.6262 - val_output_1_loss: 1.3282 - val_output_2_loss: 0.3210 - val_output_3_loss: 0.1311 - val_output_4_loss: 13.1183 - val_output_3_precision: 0.8681 - val_output_3_recall: 0.6902 - val_output_3_true_negatives: 7566122.0000 - val_output_3_true_positives: 24286.0000 - val_output_3_false_negatives: 10901.0000 - val_output_3_false_positives: 3691.0000\n",
      "Epoch 5/20\n",
      "4607/4607 [==============================] - 618s 134ms/step - loss: 35.9226 - output_1_loss: 2.7325 - output_2_loss: 0.4144 - output_3_loss: 0.1817 - output_4_loss: 19.8246 - output_3_precision: 0.8027 - output_3_recall: 0.5159 - output_3_true_negatives: 185918784.0000 - output_3_true_positives: 414757.0000 - output_3_false_negatives: 389153.0000 - output_3_false_positives: 101928.0000 - val_loss: 21.5797 - val_output_1_loss: 1.3332 - val_output_2_loss: 0.3234 - val_output_3_loss: 0.1299 - val_output_4_loss: 13.0369 - val_output_3_precision: 0.8615 - val_output_3_recall: 0.7051 - val_output_3_true_negatives: 7565824.0000 - val_output_3_true_positives: 24809.0000 - val_output_3_false_negatives: 10378.0000 - val_output_3_false_positives: 3989.0000\n",
      "Epoch 6/20\n",
      "4607/4607 [==============================] - 621s 135ms/step - loss: 35.8406 - output_1_loss: 2.7381 - output_2_loss: 0.4071 - output_3_loss: 0.1800 - output_4_loss: 19.7547 - output_3_precision: 0.8037 - output_3_recall: 0.5195 - output_3_true_negatives: 185918624.0000 - output_3_true_positives: 417730.0000 - output_3_false_negatives: 386321.0000 - output_3_false_positives: 102031.0000 - val_loss: 21.2311 - val_output_1_loss: 1.3130 - val_output_2_loss: 0.3179 - val_output_3_loss: 0.1277 - val_output_4_loss: 12.8213 - val_output_3_precision: 0.8838 - val_output_3_recall: 0.6914 - val_output_3_true_negatives: 7566613.0000 - val_output_3_true_positives: 24329.0000 - val_output_3_false_negatives: 10858.0000 - val_output_3_false_positives: 3200.0000\n",
      "Epoch 7/20\n",
      "4607/4607 [==============================] - 621s 135ms/step - loss: 35.9295 - output_1_loss: 2.7731 - output_2_loss: 0.3989 - output_3_loss: 0.1804 - output_4_loss: 19.7086 - output_3_precision: 0.8062 - output_3_recall: 0.5216 - output_3_true_negatives: 185919808.0000 - output_3_true_positives: 419291.0000 - output_3_false_negatives: 384505.0000 - output_3_false_positives: 100760.0000 - val_loss: 21.0282 - val_output_1_loss: 1.2913 - val_output_2_loss: 0.3218 - val_output_3_loss: 0.1259 - val_output_4_loss: 12.7107 - val_output_3_precision: 0.8674 - val_output_3_recall: 0.7243 - val_output_3_true_negatives: 7565916.0000 - val_output_3_true_positives: 25487.0000 - val_output_3_false_negatives: 9700.0000 - val_output_3_false_positives: 3897.0000\n",
      "Epoch 8/20\n",
      "4607/4607 [==============================] - 620s 135ms/step - loss: 35.5198 - output_1_loss: 2.7364 - output_2_loss: 0.4047 - output_3_loss: 0.1777 - output_4_loss: 19.4589 - output_3_precision: 0.8078 - output_3_recall: 0.5272 - output_3_true_negatives: 185919936.0000 - output_3_true_positives: 423792.0000 - output_3_false_negatives: 380049.0000 - output_3_false_positives: 100804.0000 - val_loss: 20.4279 - val_output_1_loss: 1.2516 - val_output_2_loss: 0.3170 - val_output_3_loss: 0.1223 - val_output_4_loss: 12.3402 - val_output_3_precision: 0.8686 - val_output_3_recall: 0.7297 - val_output_3_true_negatives: 7565929.0000 - val_output_3_true_positives: 25676.0000 - val_output_3_false_negatives: 9511.0000 - val_output_3_false_positives: 3884.0000\n",
      "Epoch 9/20\n",
      "4607/4607 [==============================] - 612s 133ms/step - loss: 35.1597 - output_1_loss: 2.7064 - output_2_loss: 0.4012 - output_3_loss: 0.1769 - output_4_loss: 19.2679 - output_3_precision: 0.8103 - output_3_recall: 0.5338 - output_3_true_negatives: 185920528.0000 - output_3_true_positives: 429186.0000 - output_3_false_negatives: 374766.0000 - output_3_false_positives: 100458.0000 - val_loss: 20.0499 - val_output_1_loss: 1.2591 - val_output_2_loss: 0.3087 - val_output_3_loss: 0.1191 - val_output_4_loss: 11.9727 - val_output_3_precision: 0.8788 - val_output_3_recall: 0.7243 - val_output_3_true_negatives: 7566297.0000 - val_output_3_true_positives: 25487.0000 - val_output_3_false_negatives: 9700.0000 - val_output_3_false_positives: 3516.0000\n",
      "Epoch 10/20\n",
      "4607/4607 [==============================] - 607s 132ms/step - loss: 35.0667 - output_1_loss: 2.6981 - output_2_loss: 0.4046 - output_3_loss: 0.1756 - output_4_loss: 19.2018 - output_3_precision: 0.8128 - output_3_recall: 0.5383 - output_3_true_negatives: 185920512.0000 - output_3_true_positives: 432818.0000 - output_3_false_negatives: 371296.0000 - output_3_false_positives: 99661.0000 - val_loss: 19.7756 - val_output_1_loss: 1.2238 - val_output_2_loss: 0.3144 - val_output_3_loss: 0.1178 - val_output_4_loss: 11.8494 - val_output_3_precision: 0.8770 - val_output_3_recall: 0.7382 - val_output_3_true_negatives: 7566170.0000 - val_output_3_true_positives: 25976.0000 - val_output_3_false_negatives: 9211.0000 - val_output_3_false_positives: 3643.0000\n",
      "Epoch 11/20\n",
      "4607/4607 [==============================] - 607s 132ms/step - loss: 34.8612 - output_1_loss: 2.6989 - output_2_loss: 0.3944 - output_3_loss: 0.1745 - output_4_loss: 19.0456 - output_3_precision: 0.8156 - output_3_recall: 0.5408 - output_3_true_negatives: 185922496.0000 - output_3_true_positives: 434697.0000 - output_3_false_negatives: 369051.0000 - output_3_false_positives: 98306.0000 - val_loss: 19.6651 - val_output_1_loss: 1.2430 - val_output_2_loss: 0.3139 - val_output_3_loss: 0.1167 - val_output_4_loss: 11.6471 - val_output_3_precision: 0.8743 - val_output_3_recall: 0.7361 - val_output_3_true_negatives: 7566089.0000 - val_output_3_true_positives: 25900.0000 - val_output_3_false_negatives: 9287.0000 - val_output_3_false_positives: 3724.0000\n",
      "Epoch 12/20\n",
      "4607/4607 [==============================] - 609s 132ms/step - loss: 34.6303 - output_1_loss: 2.6835 - output_2_loss: 0.3901 - output_3_loss: 0.1732 - output_4_loss: 18.9161 - output_3_precision: 0.8160 - output_3_recall: 0.5462 - output_3_true_negatives: 185921184.0000 - output_3_true_positives: 439203.0000 - output_3_false_negatives: 364920.0000 - output_3_false_positives: 99007.0000 - val_loss: 19.3307 - val_output_1_loss: 1.2005 - val_output_2_loss: 0.3128 - val_output_3_loss: 0.1144 - val_output_4_loss: 11.5353 - val_output_3_precision: 0.8903 - val_output_3_recall: 0.7308 - val_output_3_true_negatives: 7566645.0000 - val_output_3_true_positives: 25715.0000 - val_output_3_false_negatives: 9472.0000 - val_output_3_false_positives: 3168.0000\n",
      "Epoch 13/20\n",
      "4607/4607 [==============================] - 622s 135ms/step - loss: 34.7714 - output_1_loss: 2.6808 - output_2_loss: 0.4217 - output_3_loss: 0.1730 - output_4_loss: 18.9132 - output_3_precision: 0.8173 - output_3_recall: 0.5471 - output_3_true_negatives: 185922608.0000 - output_3_true_positives: 439809.0000 - output_3_false_negatives: 364038.0000 - output_3_false_positives: 98301.0000 - val_loss: 19.2296 - val_output_1_loss: 1.1963 - val_output_2_loss: 0.3129 - val_output_3_loss: 0.1144 - val_output_4_loss: 11.4551 - val_output_3_precision: 0.8794 - val_output_3_recall: 0.7490 - val_output_3_true_negatives: 7566199.0000 - val_output_3_true_positives: 26356.0000 - val_output_3_false_negatives: 8831.0000 - val_output_3_false_positives: 3614.0000\n",
      "Epoch 14/20\n",
      "4607/4607 [==============================] - 624s 136ms/step - loss: 34.0595 - output_1_loss: 2.6383 - output_2_loss: 0.3886 - output_3_loss: 0.1698 - output_4_loss: 18.5858 - output_3_precision: 0.8199 - output_3_recall: 0.5556 - output_3_true_negatives: 185922784.0000 - output_3_true_positives: 446683.0000 - output_3_false_negatives: 357302.0000 - output_3_false_positives: 98122.0000 - val_loss: 18.7683 - val_output_1_loss: 1.1696 - val_output_2_loss: 0.3085 - val_output_3_loss: 0.1112 - val_output_4_loss: 11.1551 - val_output_3_precision: 0.8779 - val_output_3_recall: 0.7678 - val_output_3_true_negatives: 7566057.0000 - val_output_3_true_positives: 27018.0000 - val_output_3_false_negatives: 8169.0000 - val_output_3_false_positives: 3756.0000\n",
      "Epoch 15/20\n",
      "4607/4607 [==============================] - 616s 134ms/step - loss: 34.0095 - output_1_loss: 2.6228 - output_2_loss: 0.3936 - output_3_loss: 0.1696 - output_4_loss: 18.5883 - output_3_precision: 0.8228 - output_3_recall: 0.5575 - output_3_true_negatives: 185924288.0000 - output_3_true_positives: 448112.0000 - output_3_false_negatives: 355672.0000 - output_3_false_positives: 96497.0000 - val_loss: 18.9126 - val_output_1_loss: 1.2072 - val_output_2_loss: 0.3084 - val_output_3_loss: 0.1112 - val_output_4_loss: 11.1120 - val_output_3_precision: 0.8812 - val_output_3_recall: 0.7679 - val_output_3_true_negatives: 7566169.0000 - val_output_3_true_positives: 27020.0000 - val_output_3_false_negatives: 8167.0000 - val_output_3_false_positives: 3644.0000\n",
      "Epoch 16/20\n",
      "4607/4607 [==============================] - 596s 129ms/step - loss: 33.7953 - output_1_loss: 2.6171 - output_2_loss: 0.3954 - output_3_loss: 0.1685 - output_4_loss: 18.3960 - output_3_precision: 0.8242 - output_3_recall: 0.5613 - output_3_true_negatives: 185923840.0000 - output_3_true_positives: 451459.0000 - output_3_false_negatives: 352850.0000 - output_3_false_positives: 96285.0000 - val_loss: 18.5401 - val_output_1_loss: 1.1790 - val_output_2_loss: 0.3063 - val_output_3_loss: 0.1091 - val_output_4_loss: 10.8952 - val_output_3_precision: 0.9030 - val_output_3_recall: 0.7456 - val_output_3_true_negatives: 7566994.0000 - val_output_3_true_positives: 26235.0000 - val_output_3_false_negatives: 8952.0000 - val_output_3_false_positives: 2819.0000\n",
      "Epoch 17/20\n",
      "4607/4607 [==============================] - 540s 117ms/step - loss: 33.7360 - output_1_loss: 2.6284 - output_2_loss: 0.3777 - output_3_loss: 0.1678 - output_4_loss: 18.3700 - output_3_precision: 0.8240 - output_3_recall: 0.5630 - output_3_true_negatives: 185923264.0000 - output_3_true_positives: 452736.0000 - output_3_false_negatives: 351363.0000 - output_3_false_positives: 96686.0000 - val_loss: 18.1492 - val_output_1_loss: 1.1597 - val_output_2_loss: 0.3042 - val_output_3_loss: 0.1061 - val_output_4_loss: 10.6176 - val_output_3_precision: 0.8978 - val_output_3_recall: 0.7737 - val_output_3_true_negatives: 7566713.0000 - val_output_3_true_positives: 27223.0000 - val_output_3_false_negatives: 7964.0000 - val_output_3_false_positives: 3100.0000\n",
      "Epoch 18/20\n",
      "4607/4607 [==============================] - 575s 125ms/step - loss: 34.0736 - output_1_loss: 2.6567 - output_2_loss: 0.4114 - output_3_loss: 0.1680 - output_4_loss: 18.3971 - output_3_precision: 0.8249 - output_3_recall: 0.5620 - output_3_true_negatives: 185924608.0000 - output_3_true_positives: 451805.0000 - output_3_false_negatives: 352111.0000 - output_3_false_positives: 95889.0000 - val_loss: 17.7126 - val_output_1_loss: 1.1179 - val_output_2_loss: 0.3020 - val_output_3_loss: 0.1035 - val_output_4_loss: 10.4063 - val_output_3_precision: 0.8804 - val_output_3_recall: 0.8030 - val_output_3_true_negatives: 7565974.0000 - val_output_3_true_positives: 28255.0000 - val_output_3_false_negatives: 6932.0000 - val_output_3_false_positives: 3839.0000\n",
      "Epoch 19/20\n",
      "4607/4607 [==============================] - 612s 133ms/step - loss: 33.3340 - output_1_loss: 2.6150 - output_2_loss: 0.3782 - output_3_loss: 0.1654 - output_4_loss: 18.0371 - output_3_precision: 0.8299 - output_3_recall: 0.5731 - output_3_true_negatives: 185926672.0000 - output_3_true_positives: 460646.0000 - output_3_false_negatives: 343114.0000 - output_3_false_positives: 94385.0000 - val_loss: 17.6910 - val_output_1_loss: 1.1561 - val_output_2_loss: 0.3153 - val_output_3_loss: 0.1020 - val_output_4_loss: 10.1303 - val_output_3_precision: 0.8940 - val_output_3_recall: 0.7869 - val_output_3_true_negatives: 7566530.0000 - val_output_3_true_positives: 27690.0000 - val_output_3_false_negatives: 7497.0000 - val_output_3_false_positives: 3283.0000\n",
      "Epoch 20/20\n",
      "4607/4607 [==============================] - 622s 135ms/step - loss: 33.5361 - output_1_loss: 2.6282 - output_2_loss: 0.3923 - output_3_loss: 0.1654 - output_4_loss: 18.1024 - output_3_precision: 0.8286 - output_3_recall: 0.5711 - output_3_true_negatives: 185925888.0000 - output_3_true_positives: 459088.0000 - output_3_false_negatives: 344708.0000 - output_3_false_positives: 94954.0000 - val_loss: 18.0056 - val_output_1_loss: 1.1363 - val_output_2_loss: 0.3104 - val_output_3_loss: 0.1049 - val_output_4_loss: 10.5622 - val_output_3_precision: 0.8861 - val_output_3_recall: 0.7811 - val_output_3_true_negatives: 7566281.0000 - val_output_3_true_positives: 27485.0000 - val_output_3_false_negatives: 7702.0000 - val_output_3_false_positives: 3532.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"/home/sergio/Documents/json_experiments\")\n",
    "import json\n",
    "#json.dumps(str(a))\n",
    "with open('history_finetuning_5521_40_60_epoch_nadam_0dot00001_mse_exp_mse_3anchors_full_obj.json', 'w') as fp:\n",
    "    json.dump(str(history.history), fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/sergio/Documents/weights_saved/pesos_finetuning_5521_40_60_epoch_nadam_0dot00001_mse_exp_mse_3anchors_full_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

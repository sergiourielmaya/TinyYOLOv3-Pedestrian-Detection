{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection\")\n",
    "\n",
    "from YOLOblocks import TinyYOLOv3#,YOLOLoss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "#from tensorflow.python.tools import freeze_graph\n",
    "#from skimage.io import imread,imshow\n",
    "#from skimage.transform import resize \n",
    "import time\n",
    "#from tensorflow.compat.v1.image import decode_image\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_description = {\n",
    "    'bboxes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'num_real_boxes':tf.io.FixedLenFeature([], tf.int64),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_matrix_tf(box_arr1, box_arr2):\n",
    "    \n",
    "    box_arr1 = box_arr1 -tf.tile(box_arr1[:,:2],[1,2])\n",
    "    #print(box_arr1)\n",
    "    x11, y11, x12, y12 = tf.split(box_arr1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = tf.split(box_arr2, 4, axis=1)\n",
    "    xA = tf.maximum(x11, tf.transpose(x21))\n",
    "    yA = tf.maximum(y11, tf.transpose(y21))\n",
    "    xB = tf.minimum(x12, tf.transpose(x22))\n",
    "    yB = tf.minimum(y12, tf.transpose(y22))\n",
    "    interArea = tf.maximum((xB - xA + 1e-9), 0) * tf.maximum((yB - yA + 1e-9), 0)\n",
    "    boxAArea = (x12 - x11 + 1e-9) * (y12 - y11 + 1e-9)\n",
    "    boxBArea = (x22 - x21 + 1e-9) * (y22 - y21 + 1e-9)\n",
    "    iou = interArea / (boxAArea + tf.transpose(boxBArea) - interArea)\n",
    "    return iou,tf.argmax(iou,axis=1)#[:,tf.newaxis]\n",
    "\n",
    "\n",
    "def fill_yolo_output(boxes,grid_size,num_anchors,which_anchor_box,which_anchor_box_index):\n",
    "    #print(boxes.shape)\n",
    "    #noobj_mask = tf.ones((1,grid_size*grid_size*num_anchors))\n",
    "    #print(noobj_mask.shape)\n",
    "    \n",
    "    x_min,y_min,x_max,y_max =tf.split(boxes,4,axis=1)\n",
    "\n",
    "    #Transforma las coordenadas de (xmin,ymin,xmax,ymax) --> (xcenter,ycenter,width,height)\n",
    "    width = x_max-x_min\n",
    "    height = y_max-y_min\n",
    "    x_global =x_min + tf.math.divide(x_max - x_min,2)\n",
    "    y_global =y_min + tf.math.divide(y_max - y_min,2)\n",
    "    \n",
    "    \n",
    "    x_min_anchor,y_min_anchor,x_max_anchor,y_max_anchor =tf.split(which_anchor_box,4,axis=1)\n",
    "    \n",
    "    width_anchor = x_max_anchor-x_min_anchor\n",
    "    height_anchor = y_max_anchor-y_min_anchor\n",
    "    x_global_anchor =x_min_anchor + tf.math.divide(x_max_anchor - x_min_anchor,2)\n",
    "    y_global_anchor =y_min_anchor + tf.math.divide(y_max_anchor - y_min_anchor,2)   \n",
    "\n",
    "    \n",
    "    #print(\"el x original\",x_global)\n",
    "    #print(\"el y original\",y_global)\n",
    "    #print(\"el w original\",width)\n",
    "    #print(\"el h original\",height)\n",
    "    \n",
    "    #porción de la imagen que hay en cada celda\n",
    "    pixel_per_grid = tf.math.divide(1.,grid_size)\n",
    "    #print(pixel_per_grid)\n",
    "    \n",
    "    #Obtenemos la coordenada de la celda donde están los boundingboxes\n",
    "    offset_grid_x = x_global//pixel_per_grid\n",
    "    offset_grid_y = y_global//pixel_per_grid\n",
    "    \n",
    "    #Obtenemos el el centro locacon referencia  al celda encontrada previamente\n",
    "    x_local =tf.math.floormod(x_global,pixel_per_grid)\n",
    "    y_local =tf.math.floormod(y_global,pixel_per_grid)\n",
    "    #print(x_local,y_local)\n",
    "    \n",
    "    #Valores tx e ty del groudtruth\n",
    "    tx = tf.math.log(x_local + 1e-07/(1-x_local))\n",
    "    ty = tf.math.log(y_local+1e-07/(1-y_local))\n",
    "    tw = tf.math.log(tf.math.divide(width+1e-07,width_anchor))\n",
    "    th = tf.math.log(tf.math.divide(height+1e-07,height_anchor))\n",
    "    tobj_mask = tf.ones_like(tx)\n",
    "    tobj = tf.concat([tobj_mask,tobj_mask],axis=0)\n",
    "    \n",
    "    #tnoobj = tf.zeros_like(tx)    \n",
    "    #tobj = tf.ones((grid_size*grid_size*num_anchors,1))\n",
    "    #tnoobj = tf.zeros((grid_size*grid_size*num_anchors,1))\n",
    "    #print(\"Lo que la red debe predecir\",tx.numpy(),ty.numpy(),tw.numpy(),th.numpy())\n",
    "    #x_global = (offset_grid_x * pixel_per_grid) + tf.math.sigmoid(tx)\n",
    "    #y_global = (offset_grid_y * pixel_per_grid) + tf.math.sigmoid(ty)\n",
    "    #w = width_anchor*tf.math.exp(tw)\n",
    "    #h = height_anchor*tf.math.exp(th)\n",
    "    #print(\"obtnemos el x_real\",x_global)\n",
    "    #print(\"obtenemos el y_real\",y_global)\n",
    "    #print(\"obtenemos el w real\",w)\n",
    "    #print(\"obtenemos el h real\",h)\n",
    "    \n",
    "    \n",
    "    #print(which_anchor_box_index)\n",
    "    residuo = tf.math.floormod(which_anchor_box_index,2)[:,tf.newaxis]\n",
    "    coord = tf.cast(2*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    \n",
    "    coord_objectness = tf.cast(2*(offset_grid_y*grid_size + offset_grid_x),dtype=tf.int64)\n",
    "    coord_objectness2 = coord_objectness+1\n",
    "    coord_objectess_global = tf.concat([coord_objectness,coord_objectness2],axis=0)\n",
    "    \n",
    "    output_position = residuo+coord\n",
    "    print(\"tipo de aoutput_positivon\",output_position)\n",
    "    \n",
    "    print(output_position)\n",
    "    \n",
    "    dense_shape = grid_size*grid_size*num_anchors\n",
    "    tx_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tx[:,0], dense_shape=[dense_shape]))\n",
    "    ty_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=ty[:,0], dense_shape=[dense_shape]))\n",
    "    tw_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tw[:,0], dense_shape=[dense_shape]))\n",
    "    th_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=th[:,0], dense_shape=[dense_shape]))\n",
    "    obj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tobj_mask[:,0], dense_shape=[dense_shape]))\n",
    "    objectness_vector = tf.sparse.reorder(tf.sparse.SparseTensor(indices=coord_objectess_global, values=tobj[:,0], dense_shape=[dense_shape]))\n",
    "    #noobj_mask = tf.sparse.reorder(tf.sparse.SparseTensor(indices=output_position, values=tnoobj[:,0], dense_shape=[dense_shape]))\n",
    "    #obj_mask =tx_vector=ty_vector=tw_vector=th_vector = tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "    \n",
    "    tx_vector_dense = tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=False, name=\"Dense_tx\")\n",
    "    ty_vector_dense = tf.sparse.to_dense(ty_vector, default_value=0, validate_indices=False, name=\"Dense_ty\")\n",
    "    tw_vector_dense = tf.sparse.to_dense(tw_vector, default_value=0, validate_indices=False, name=\"Dense_tw\")\n",
    "    th_vector_dense = tf.sparse.to_dense(th_vector, default_value=0, validate_indices=False, name=\"Dense_th\")\n",
    "    obj_mask_dense =  tf.sparse.to_dense(obj_mask, default_value=0, validate_indices=False, name=\"Dense_obj\")\n",
    "    #noobj_mask_dense = 1-obj_mask_dense\n",
    "    objectness_vector_dense =  tf.sparse.to_dense(objectness_vector, default_value=0, validate_indices=False)\n",
    "    \n",
    "    #noobj_mask_dense= tf.sparse.to_dense(noobj_mask, default_value=1, validate_indices=False, name=\"Dense_noobj\")\n",
    "    ##print(tx_vector.to_dense)\n",
    "    #print(tf.sparse.to_dense(tx_vector, default_value=0, validate_indices=True, name=None)\n",
    "    #tx_vector=tx_vector[[3,2],]\n",
    "    #tx_vector[output_position[:,0]] = tx\n",
    "    #print(\"coordenada de la salida:\",output_position)\n",
    "    \n",
    "    #return ((tx_vector_dense,ty_vector_dense,obj_mask_dense),(tw_vector_dense,th_vector_dense,obj_mask_dense),(objectness),(objectness))\n",
    "    \n",
    "    return tx_vector_dense,ty_vector_dense,tw_vector_dense,th_vector_dense,obj_mask_dense,objectness_vector_dense\n",
    "\n",
    "def build_targets(image,image_bboxes,num_real_boxes,anchor_boxes):\n",
    "    \n",
    "    images_bboxes_original = image_bboxes\n",
    "    #Obtenemos los boduing boxes que son reales\n",
    "    image_bboxes = image_bboxes[:num_real_boxes,:]\n",
    "    #print(\"Bouding boxes de la imagen\",image_bboxes)\n",
    "    #Obteneos  la matriz de IoU , y el índice del anchor box que dió mejor resultado\n",
    "    \n",
    "    image_bboxes = tf.math.divide(image_bboxes,416)\n",
    "    iou_matrix,which_anchor_box_index = get_iou_matrix_tf(image_bboxes,anchor_boxes)\n",
    "    \n",
    "    print(which_anchor_box_index)\n",
    "\n",
    "    #Indices de los bouding boxes que irian en cada salida, index_best_ yolo nos dice que bouding boxes de la imagen van a la salida YOLO1,\n",
    "    #porque su mejor IoU fue con los dos anchor boxes mas grandes\n",
    "    index_best_yolo1 = tf.where(which_anchor_box_index>=2)[:,0]\n",
    "    index_best_yolo2 = tf.where(which_anchor_box_index<2)[:,0]\n",
    "    index_best_anchor_yolo1 = tf.gather(which_anchor_box_index,index_best_yolo1,axis=0)\n",
    "    index_best_anchor_yolo2 = tf.gather(which_anchor_box_index,index_best_yolo2,axis=0)\n",
    "    \n",
    "    print(index_best_yolo1)\n",
    "    print(index_best_anchor_yolo1)\n",
    "\n",
    "    print(index_best_yolo2)\n",
    "    print(index_best_anchor_yolo2)\n",
    "\n",
    "    \n",
    "    best_bboxes_yolo1 = tf.gather(image_bboxes,index_best_yolo1,axis =0)\n",
    "    best_anchors_yolo1 = tf.gather(anchor_boxes,index_best_anchor_yolo1, axis =0) #LOs dos anchor boxes grandes corrsponden a YOLO\n",
    "    best_bboxes_yolo2 = tf.gather(image_bboxes,index_best_yolo2,axis =0)\n",
    "    best_anchors_yolo2 = tf.gather(anchor_boxes,index_best_anchor_yolo2, axis =0) #Los dos anchor boxes pequeños corresponden a YOLO2\n",
    "    \n",
    "    \n",
    "    if best_anchors_yolo1.shape[0] !=0:\n",
    "        tx_vector_yolo1,ty_vector_yolo1,tw_vector_yolo1,th_vector_yolo1,obj_mask_yolo1,obj_vector_yolo1= fill_yolo_output(best_bboxes_yolo1,13,2,best_anchors_yolo1,index_best_anchor_yolo1)\n",
    "    else:\n",
    "        tx_vector_yolo1=ty_vector_yolo1=tw_vector_yolo1=th_vector_yolo1=obj_mask_yolo1= obj_vector_yolo1=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo1 = tf.ones((1,13*13*num_anchors))\n",
    "    \n",
    "    if best_anchors_yolo2.shape[0] != 0:\n",
    "        tx_vector_yolo2,ty_vector_yolo2,tw_vector_yolo2,th_vector_yolo2,obj_mask_yolo2,obj_vector_yolo2 = fill_yolo_output(best_bboxes_yolo2,26,2,best_anchors_yolo2,index_best_anchor_yolo2)\n",
    "    else:\n",
    "        tx_vector_yolo2=ty_vector_yolo2=tw_vector_yolo2=th_vector_yolo2=obj_mask_yolo2 = obj_vector_yolo2=tf.zeros((1,grid_size*grid_size*num_anchors))\n",
    "        #noobj_mask_yolo2 = tf.ones((1,26*26*num_anchors))\n",
    "        \n",
    "    tx_vector = tf.concat([tx_vector_yolo1,tx_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    ty_vector = tf.concat([ty_vector_yolo1,ty_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    tw_vector = tf.concat([tw_vector_yolo1,tw_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    th_vector = tf.concat([th_vector_yolo1,th_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_mask = tf.concat([obj_mask_yolo1,obj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    #noobj_mask = tf.concat([noobj_mask_yolo1,noobj_mask_yolo2],axis=0)[:,tf.newaxis]\n",
    "    obj_vector = tf.concat([obj_vector_yolo1,obj_vector_yolo2],axis=0)[:,tf.newaxis]\n",
    "    \n",
    "    #output = tf.concat([tx_vector,ty_vector,tw_vector,th_vector,obj_mask,noobj_mask,obj_vector],axis=1)\n",
    "    #images_bboxes_original\n",
    "    #return image,output\n",
    "    return tf.cast(image,tf.float32),(tf.concat([tx_vector,ty_vector,obj_mask],axis=1),tf.concat([tw_vector,th_vector,obj_mask],axis=1),(obj_vector),(obj_vector))\n",
    "\n",
    "def imgaug_data_augmentation(image,bboxes,num_real_boxes):\n",
    "    im_shape = image.shape\n",
    "    bbs = BoundingBoxesOnImage.from_xyxy_array(bboxes*416, shape=(416,416))\n",
    "    \n",
    "    policy = np.random.randint(5)\n",
    "    \n",
    "    #policy = 2\n",
    "    if policy == 0:\n",
    "        \n",
    "        p = np.random.random()\n",
    "        if p<0.6:\n",
    "            aug = iaa.TranslateX(px=(-60, 60),cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "        p = np.random.random()\n",
    "        if p<0.8:\n",
    "            aug = iaa.HistogramEqualization()\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "    \n",
    "    elif policy==1:\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<0.2:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p<0.8:\n",
    "            square_size = np.random.randint(48)\n",
    "            aug = iaa.Cutout(nb_iterations=1, size=square_size/416, squared=True)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    elif policy==2:\n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.ShearY(shear=(int(-0.06*416), int(0.06*416)), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "        p=np.random.random()\n",
    "        if p<=1:\n",
    "            aug = iaa.TranslateY(px=(int(-0.18*416), int(0.18*416)),cval=128)\n",
    "            for i in bbs.to_xyxy_array(np.int32)[:num_real_boxes,:]:\n",
    "                bbox = image[i[1]:i[3],i[0]:i[2]]\n",
    "                bbox_augmented = aug(image=bbox)\n",
    "                image[i[1]:i[3],i[0]:i[2]] = bbox_augmented\n",
    "            \n",
    "    elif policy==3:\n",
    "        p=np.random.random()\n",
    "        if p<=0.6:    \n",
    "            aug = iaa.Rotate(rotate=(-30, 30), order=1, cval=128)\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs_aug.remove_out_of_image().clip_out_of_image()\n",
    "        \n",
    "        p=np.random.random()\n",
    "        if p>=1:\n",
    "            aug = iaa.MultiplySaturation((0.54, 1.54))\n",
    "            image, bbs = aug(image=image, bounding_boxes=bbs)\n",
    "            #bbs.remove_out_of_image().clip_out_of_image()\n",
    "            \n",
    "    bbs.remove_out_of_image()\n",
    "    \n",
    "    return image,np.clip(bbs.to_xyxy_array(np.float32),1,415),num_real_boxes\n",
    "    \n",
    "    \n",
    "def preprocessing(example_proto):\n",
    "    image_features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image = tf.image.decode_jpeg(image_features['image_raw'],channels = 3)\n",
    "    image = tf.cast(tf.image.resize(image,size=(416,416)), tf.uint8)\n",
    "    bboxes =  tf.io.parse_tensor(image_features['bboxes'], out_type=tf.float32)\n",
    "    \n",
    "    num_real_boxes = image_features['num_real_boxes']\n",
    "    return image,bboxes,num_real_boxes\n",
    "\n",
    "    \n",
    "@tf.function(input_signature=[tf.TensorSpec((416,416,3), tf.uint8),tf.TensorSpec((None,4), tf.float32),tf.TensorSpec((), tf.int64)]) \n",
    "def tf_numpy_albumentations_real(image,bboxes,num_real_boxes):\n",
    "    \n",
    "    boxes_shape = bboxes.shape\n",
    "    im_shape = image.shape\n",
    "\n",
    "    image,bboxes,num_real_boxes = tf.numpy_function(imgaug_data_augmentation,[image,bboxes,num_real_boxes],Tout =[tf.uint8,tf.float32,tf.int64])\n",
    " \n",
    "    image.set_shape(im_shape)\n",
    "    bboxes.set_shape(boxes_shape)\n",
    "    \n",
    "    #print(\"Imagen data type\",image.dtype)\n",
    "    #print(\"Bboxes data type\",bboxes.dtype)   \n",
    "\n",
    "    return image,bboxes,num_real_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", shape=(None,), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"ArgMax:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"strided_slice_3:0\", shape=(None,), dtype=int64)\n",
      "Tensor(\"GatherV2_1:0\", shape=(None,), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_18:0\", shape=(None, 1), dtype=int64)\n",
      "tipo de aoutput_positivon Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n",
      "Tensor(\"add_30:0\", shape=(None, 1), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#USANDO TF.IMAGE MODULE\n",
    "anchors =tf.constant(np.array([[0,0,0.015,0.037],[0,0,0.043,0.104],[0,0,0.11,0.278],[0,0,0.351,0.66]]),dtype=tf.float32)\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_val_tfr\")\n",
    "filenames = os. listdir()\n",
    "raw_image_dataset_val =tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "os.chdir(\"/home/sergio/Documents/pedestrian_dataset_train_tfr\")\n",
    "#.shuffle(70000)\n",
    "train_dataset = raw_image_dataset.map(preprocessing,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(tf_numpy_albumentations_real,num_parallel_calls=8)\n",
    "train_dataset = train_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "train_dataset = train_dataset.batch(8)\n",
    "\n",
    "val_dataset = raw_image_dataset_val.map(preprocessing,num_parallel_calls=8)\n",
    "val_dataset = val_dataset.map(tf_numpy_albumentations_real,num_parallel_calls=8)\n",
    "val_dataset = val_dataset.map(lambda x,y,z:build_targets(x,y,z,anchors),num_parallel_calls=8)\n",
    "val_dataset = val_dataset.batch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import Loss,BinaryCrossentropy,MeanSquaredError\n",
    "\n",
    "def loss_xy(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tx_true,ty_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tx_pred,ty_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_x = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tx_true,tx_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_y = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(ty_true,ty_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "    return loss_x+loss_y\n",
    "\n",
    "def loss_wh(y_true,y_pred):\n",
    "    \n",
    "    mse = MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)\n",
    "    \n",
    "    loss_w = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(tw_true,tw_pred)[:,:,tf.newaxis]),axis=1))\n",
    "    loss_h = tf.reduce_mean(tf.reduce_sum(obj_mask*(mse(th_true,th_pred)[:,:,tf.newaxis]),axis=1))\n",
    "\n",
    "\n",
    "    return loss_w+loss_h\n",
    "\n",
    "def loss_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    #tw_true,th_true,obj_mask = tf.split(y_true, [1,1,1], axis=-1)\n",
    "    #tw_pred,th_pred = tf.split(y_pred, [1,1], axis=-1)   \n",
    "    \n",
    "    loss_obj =tf.reduce_mean(tf.reduce_sum( y_true*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_obj\n",
    "\n",
    "def loss_no_objectness(y_true,y_pred):\n",
    "    bce = BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    \n",
    "    \n",
    "    loss_noobj =tf.reduce_mean(tf.reduce_sum((1-y_true)*bce(y_true,y_pred)[:,tf.newaxis],axis=1))\n",
    "    \n",
    "    return loss_noobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se redimensiona la salida de la CNN a: (None, 338, 5)\n",
      "Se redimensiona la salida de la CNN a: (None, 1352, 5)\n",
      "Pesos de la convolucion (432,)\n",
      "CONV SHAPE (16, 3, 3, 3)\n",
      "Pesos de la convolucion (4608,)\n",
      "CONV SHAPE (32, 16, 3, 3)\n",
      "Pesos de la convolucion (18432,)\n",
      "CONV SHAPE (64, 32, 3, 3)\n",
      "Pesos de la convolucion (73728,)\n",
      "CONV SHAPE (128, 64, 3, 3)\n",
      "Pesos de la convolucion (294912,)\n",
      "CONV SHAPE (256, 128, 3, 3)\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "Pesos de la convolucion (4718592,)\n",
      "CONV SHAPE (1024, 512, 3, 3)\n",
      "Pesos de la convolucion (262144,)\n",
      "CONV SHAPE (256, 1024, 1, 1)\n",
      "Pesos de la convolucion (1179648,)\n",
      "CONV SHAPE (512, 256, 3, 3)\n",
      "Pesos de la convolucion (130560,)\n",
      "CONV SHAPE (255, 512, 1, 1)\n",
      "Pesos de la convolucion (32768,)\n",
      "CONV SHAPE (128, 256, 1, 1)\n",
      "Pesos de la convolucion (884736,)\n",
      "CONV SHAPE (256, 384, 3, 3)\n",
      "Pesos de la convolucion (65280,)\n",
      "CONV SHAPE (255, 256, 1, 1)\n",
      "8858734\n"
     ]
    }
   ],
   "source": [
    "new_model = TinyYOLOv3(1,anchor_boxes=anchors,train=True,mode = \"finetuning\")\n",
    "new_model.build(batch_input_shape=(None,416,416,3))\n",
    "print(new_model.load_weights(\"/home/sergio/TinyYOLOv3-Pedestrian-Detection/yolov3-tiny.weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aacc2b4fcf39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    915\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (2 total):\n    * Tensor(\"inputs:0\", shape=(None, 416, 416, 3), dtype=float32)\n    * Tensor(\"training:0\", shape=(), dtype=bool)\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (2 total):\n    * TensorSpec(shape=(None, 416, 416, 3), dtype=tf.float32, name='inputs')\n    * False\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (2 total):\n    * TensorSpec(shape=(None, 416, 416, 3), dtype=tf.float32, name='inputs')\n    * True\n  Keyword arguments: {}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-eaea0dc69ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/sergio/Documents/models_saved/history_finetuning_4_0dot5_20_epoch_rmsprop_0dot001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   raise IOError(\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile)\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;31m# TODO(kathywu): Add saving/loading of optimizer, compiled losses and metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;31m# TODO(kathywu): Add code to load from objects that contain all endpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_internal\u001b[0;34m(export_dir, tags, loader_cls)\u001b[0m\n\u001b[1;32m    550\u001b[0m       loader = loader_cls(object_graph_proto,\n\u001b[1;32m    551\u001b[0m                           \u001b[0msaved_model_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                           export_dir)\n\u001b[0m\u001b[1;32m    553\u001b[0m       \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_info_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_finalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m           \u001b[0m_set_network_attributes_from_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Model is subclassed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m           \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0;31m# Add unconditional losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2657\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    772\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreturn_outputs_and_add_losses\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_arg_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_arg_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    495\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    496\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 497\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tesis/lib/python3.6/site-packages/tensorflow_core/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mrestored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         .format(_pretty_format_positional(args), kwargs,\n\u001b[1;32m    261\u001b[0m                 \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcrete_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \"\\n\\n\".join(signature_descriptions)))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mconcrete_function_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (2 total):\n    * Tensor(\"inputs:0\", shape=(None, 416, 416, 3), dtype=float32)\n    * Tensor(\"training:0\", shape=(), dtype=bool)\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 2 option(s):\n\nOption 1:\n  Positional arguments (2 total):\n    * TensorSpec(shape=(None, 416, 416, 3), dtype=tf.float32, name='inputs')\n    * False\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (2 total):\n    * TensorSpec(shape=(None, 416, 416, 3), dtype=tf.float32, name='inputs')\n    * True\n  Keyword arguments: {}"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('/home/sergio/Documents/models_saved/history_finetuning_4_0dot5_20_epoch_rmsprop_0dot001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

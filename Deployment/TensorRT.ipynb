{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = tf.keras.utils.get_file(\n",
    "    \"persons.jpg\",\n",
    "    \"https://www.saltwire.com/media/photologue/photos/cache/STJ-A01-28102019-RawlinsCrossPedestrians3_large.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = file\n",
    "img_raw = tf.image.decode_image(open(image, 'rb').read(), channels=3)\n",
    "img = tf.expand_dims(img_raw, 0)\n",
    "_,height,width,_ =img.shape\n",
    "img = tf.image.resize(img, (416, 416))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'saved_model_tensorrt_with_NMS/my_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p 'saved_model_tensorrt_int8/my_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparams = tf.experimental.tensorrt.ConversionParams(\\n    precision_mode='INT8',\\n    # Currently only one INT8 engine is supported in this mode.\\n    maximum_cached_engines=1,\\n    use_calibration=True)\\n\\nconverter = tf.experimental.tensorrt.Converter(\\n    input_saved_model_dir='saved_model/my_model', conversion_params=params)\\n\\n# Define a generator function that yields input data, and run INT8\\n# calibration with the data. All input data should have the same shape.\\n# At the end of convert(), the calibration stats (e.g. range information)\\n# will be saved and can be used to generate more TRT engines with different\\n# shapes. Also, one TRT engine will be generated (with the same shape as\\n# the calibration data) for save later.\\n\\ndef my_calibration_input_fn():\\n    for i in range(10):\\n        out1 = tf.random.uniform((1, 416, 416, 3),minval=0, maxval=1)\\n        yield img\\n\\nconverter.convert(calibration_input_fn=my_calibration_input_fn)\\n\\n# Save the TRT engine and the engines.\\nconverter.save('saved_model_tensorrt_int8/my_model')\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "params = tf.experimental.tensorrt.ConversionParams(\n",
    "    precision_mode='INT8',\n",
    "    # Currently only one INT8 engine is supported in this mode.\n",
    "    maximum_cached_engines=1,\n",
    "    use_calibration=True)\n",
    "\n",
    "converter = tf.experimental.tensorrt.Converter(\n",
    "    input_saved_model_dir='saved_model/my_model', conversion_params=params)\n",
    "\n",
    "# Define a generator function that yields input data, and run INT8\n",
    "# calibration with the data. All input data should have the same shape.\n",
    "# At the end of convert(), the calibration stats (e.g. range information)\n",
    "# will be saved and can be used to generate more TRT engines with different\n",
    "# shapes. Also, one TRT engine will be generated (with the same shape as\n",
    "# the calibration data) for save later.\n",
    "\n",
    "def my_calibration_input_fn():\n",
    "    for i in range(10):\n",
    "        out1 = tf.random.uniform((1, 416, 416, 3),minval=0, maxval=1)\n",
    "        yield img\n",
    "\n",
    "converter.convert(calibration_input_fn=my_calibration_input_fn)\n",
    "\n",
    "# Save the TRT engine and the engines.\n",
    "converter.save('saved_model_tensorrt_int8/my_model')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (6, 0, 1)\n",
      "INFO:tensorflow:Loaded TensorRT version: (6, 0, 1)\n",
      "INFO:tensorflow:Could not find TRTEngineOp_2 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_3 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_4 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_1 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "INFO:tensorflow:Could not find TRTEngineOp_5 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model_tensorrt_with_NMS/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "params = tf.experimental.tensorrt.ConversionParams(\n",
    "    precision_mode='FP16')\n",
    "converter = tf.experimental.tensorrt.Converter(\n",
    "    input_saved_model_dir='saved_model_with_NMS/my_model', conversion_params=params)\n",
    "converter.convert()\n",
    "converter.save('saved_model_tensorrt_with_NMS/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nparams = tf.experimental.tensorrt.ConversionParams(\\n    precision_mode='FP16')\\nconverter = tf.experimental.tensorrt.Converter(\\n    input_saved_model_dir='saved_model/my_model', conversion_params=params)\\nconverter.convert()\\n\\n\\n# Define a generator function that yields input data, and use it to execute\\n# the graph to build TRT engines.\\n# With TensorRT 5.1, different engines will be built (and saved later) for\\n# different input shapes to the TRTEngineOp.\\ndef my_input_fn():\\n    for i in range(10):\\n        out1 = tf.random.normal((8,416, 416, 3))\\n        yield img\\n\\nconverter.build(input_fn=my_input_fn)  # Generate corresponding TRT engines\\nconverter.save('saved_model_tensorrt/my_model')  # Generated engines will be saved.\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "params = tf.experimental.tensorrt.ConversionParams(\n",
    "    precision_mode='FP16')\n",
    "converter = tf.experimental.tensorrt.Converter(\n",
    "    input_saved_model_dir='saved_model/my_model', conversion_params=params)\n",
    "converter.convert()\n",
    "\n",
    "\n",
    "# Define a generator function that yields input data, and use it to execute\n",
    "# the graph to build TRT engines.\n",
    "# With TensorRT 5.1, different engines will be built (and saved later) for\n",
    "# different input shapes to the TRTEngineOp.\n",
    "def my_input_fn():\n",
    "    for i in range(10):\n",
    "        out1 = tf.random.normal((8,416, 416, 3))\n",
    "        yield img\n",
    "\n",
    "converter.build(input_fn=my_input_fn)  # Generate corresponding TRT engines\n",
    "converter.save('saved_model_tensorrt/my_model')  # Generated engines will be saved.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

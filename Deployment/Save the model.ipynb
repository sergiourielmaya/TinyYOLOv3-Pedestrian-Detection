{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"/tf/home/sergio/Tesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/home/sergio/Tesis/TinyYOLOv3-Pedestrian-Detection/Deployment'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(root_path+\"/TinyYOLOv3-Pedestrian-Detection\")\n",
    "from YOLOblocks import TinyYOLOv3,BasicBlock,PredictionLayer#,YOLOLossBasicBlock\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.io import imread,imshow\n",
    "from skimage.transform import resize\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5e803e72b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors =[[0.02078,0.049],[0.0426,0.128],[0.08523,0.19356],[0.1506,0.4163],[0.27835,0.58651],[0.5632,0.78614]]\n",
    "model = TinyYOLOv3(1,anchor_boxes=anchors,train=False,mode = \"finetuning\",obj_threshold=0.4)\n",
    "model.build(batch_input_shape=(None,416,416,3))    \n",
    "model.load_weights(root_path+'/weights_saved/pesos_finetuning_5521_30_50_epoch_nadam_0dot00001_msle_exp_mse_3anchors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = tf.keras.utils.get_file(\n",
    "    \"persons.jpg\",\n",
    "    \"https://www.saltwire.com/media/photologue/photos/cache/STJ-A01-28102019-RawlinsCrossPedestrians3_large.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = file\n",
    "img_raw = tf.image.decode_image(open(image, 'rb').read(), channels=3)\n",
    "img = tf.expand_dims(img_raw, 0)\n",
    "_,height,width,_ =img.shape\n",
    "img = tf.image.resize(img, (416, 416))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: saved_model_with_NMS/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model_with_NMS/my_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"tiny_yol_ov3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "BasicBlock1 (BasicBlock)     multiple                  496       \n",
      "_________________________________________________________________\n",
      "BasicBlock2 (BasicBlock)     multiple                  4736      \n",
      "_________________________________________________________________\n",
      "BasicBlock3 (BasicBlock)     multiple                  18688     \n",
      "_________________________________________________________________\n",
      "BasicBlock4 (BasicBlock)     multiple                  74240     \n",
      "_________________________________________________________________\n",
      "BasicBlock5 (BasicBlock)     multiple                  295936    \n",
      "_________________________________________________________________\n",
      "BasicBlock6 (BasicBlock)     multiple                  1181696   \n",
      "_________________________________________________________________\n",
      "BasicBlock7 (BasicBlock)     multiple                  4722688   \n",
      "_________________________________________________________________\n",
      "BasicBlock8 (BasicBlock)     multiple                  263168    \n",
      "_________________________________________________________________\n",
      "BasicBlock9 (BasicBlock)     multiple                  1181696   \n",
      "_________________________________________________________________\n",
      "FinalBlock1 (BasicBlock)     multiple                  7695      \n",
      "_________________________________________________________________\n",
      "BasicBlock11 (BasicBlock)    multiple                  33280     \n",
      "_________________________________________________________________\n",
      "BasicBlock12 (BasicBlock)    multiple                  885760    \n",
      "_________________________________________________________________\n",
      "FinalBlock2 (BasicBlock)     multiple                  3855      \n",
      "_________________________________________________________________\n",
      "Concatenate (Concatenate)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "Upsampling (UpSampling2D)    multiple                  0         \n",
      "_________________________________________________________________\n",
      "Prediction1 (PredictionLayer multiple                  0         \n",
      "_________________________________________________________________\n",
      "Prediction2 (PredictionLayer multiple                  0         \n",
      "_________________________________________________________________\n",
      "Concatenate_BBOX (Concatenat multiple                  0         \n",
      "_________________________________________________________________\n",
      "nms_layer (NMSLayer)         multiple                  0         \n",
      "=================================================================\n",
      "Total params: 8,673,934\n",
      "Trainable params: 8,667,566\n",
      "Non-trainable params: 6,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model_with_NMS/my_model')\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = tf.keras.utils.get_file(\n",
    "    \"persons.jpg\",\n",
    "    \"https://www.saltwire.com/media/photologue/photos/cache/STJ-A01-28102019-RawlinsCrossPedestrians3_large.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = file\n",
    "img_raw = tf.image.decode_image(open(image, 'rb').read(), channels=3)\n",
    "img = tf.expand_dims(img_raw, 0)\n",
    "_,height,width,_ =img.shape\n",
    "img = tf.image.resize(img, (416, 416))/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.24873672 0.33036783 0.37678713 0.91031384]\n",
      " [0.47777706 0.2421627  0.611129   0.8420085 ]\n",
      " [0.6335489  0.28631282 0.7600512  0.7978145 ]\n",
      " [0.08708014 0.32900137 0.1485187  0.5255371 ]\n",
      " [0.4022988  0.25115263 0.5324107  0.83888245]\n",
      " [0.67619    0.15234086 0.8719264  0.78450406]], shape=(6, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ayuda= model(img)\n",
    "print(ayuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.24873674 0.33036786 0.37678713 0.9103138 ]\n",
      " [0.47777706 0.2421627  0.611129   0.8420085 ]\n",
      " [0.6335489  0.28631288 0.7600512  0.7978144 ]\n",
      " [0.08708014 0.32900137 0.1485187  0.5255371 ]\n",
      " [0.40229878 0.25115263 0.5324107  0.83888245]\n",
      " [0.6761901  0.15234086 0.87192637 0.78450406]], shape=(6, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ayuda2= new_model(img)\n",
    "print(ayuda2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2 ms ± 96.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.75 ms ± 1.03 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit new_model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
